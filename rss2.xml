<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DataLatte&#39;s IT Blog</title>
    <link>https://heung-bae-lee.github.io/</link>
    
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>DataLatte가 Data Science 공부를 하면서 정리해 놓는 블로그</description>
    <pubDate>Sat, 14 Dec 2019 06:55:23 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>추천시스템(Recommendation System)</title>
      <link>https://heung-bae-lee.github.io/2019/12/14/Recommendation_System_00/</link>
      <guid>https://heung-bae-lee.github.io/2019/12/14/Recommendation_System_00/</guid>
      <pubDate>Sat, 14 Dec 2019 02:34:02 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;1-추천-시스템-Recommendation-System-이란&quot;&gt;&lt;a href=&quot;#1-추천-시스템-Recommendation-System-이란&quot; class=&quot;headerlink&quot; title=&quot;1) 추천 시스템(Recommendation S
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h2 id="1-추천-시스템-Recommendation-System-이란"><a href="#1-추천-시스템-Recommendation-System-이란" class="headerlink" title="1) 추천 시스템(Recommendation System)이란?"></a>1) 추천 시스템(Recommendation System)이란?</h2><p><a href="https://ko.wikipedia.org/wiki/%EC%B6%94%EC%B2%9C_%EC%8B%9C%EC%8A%A4%ED%85%9C" target="_blank" rel="noopener">위키백과의 정의를 통해 먼저 정리해보자!</a></p><ul><li>정보 필터링 (IF) 기술의 일종</li><li>특정 사용자가 관심을 가질만한 정보 (영화, 음악, 책, 뉴스, 이미지, 웹 페이지 등)를 추천하는 것</li></ul><h2 id="ㄴ-종류-Different-Types-of-Recommendation-Engines"><a href="#ㄴ-종류-Different-Types-of-Recommendation-Engines" class="headerlink" title="ㄴ.종류(Different Types of Recommendation Engines) :"></a>ㄴ.종류(Different Types of Recommendation Engines) :</h2><h3 id="1-협업-필터링-기법-Collaborative-filtering"><a href="#1-협업-필터링-기법-Collaborative-filtering" class="headerlink" title="1) 협업 필터링 기법(Collaborative filtering)"></a>1) <code>협업 필터링 기법(Collaborative filtering)</code></h3><ul><li><p>기본적인 가정이 <code>과거에 동의한 사람들이 미래에도 동의하고 그들이 과거에 좋아했던 것들을 좋아할 것이라는 가정</code>을 바탕으로 <code>다른 사용자와의 비슷함에 기초를 두고 사용자들이 무엇을 좋아할 지를 예측하는 것</code>에 기초에 두고 있다. Linkedin, facebook과 같은 SNS는 collaboprative filtering을 친구 추천 등에 사용한다.</p></li><li><p>가장 큰 장점인 machine analyzable content에 의존하고 있지 않다는 점으로 인해 정확하게 <code>item 그 자체를 이해하지 않고도 영화와 같은 복잡한 item들을 추천 할 수 있다.</code></p></li><li><p>주로 사용되는 알고리즘 : <code>KNN, Pearson Correlation</code></p><ul><li>모델을 만들 때, feature는 Explicit하거나 Implicit한 data collection 사이에서 만들어진다.</li><li>Explicit data collection의 예<ul><li>사용자에게 item을 평가하게하기, 검색하게 하기, 가장 선호하는 것과 가장 덜 선호하는 것을 순위매기게 하기 등</li></ul></li><li>Implicit data collection의 예<ul><li>사용자가 본 item을 관찰하고 분석하기, 사용자가 구매한 item을 기록하기, 사용자의 SNS를 분석하고 비슷한 likes와 dislike를 찾아내기!</li></ul></li></ul></li></ul><p><a href="/image/Collaborative_filtering.png">Collaborative filtering</a>    </p><h3 id="2-컨텐츠-기반-필터링-Content-based-filtering"><a href="#2-컨텐츠-기반-필터링-Content-based-filtering" class="headerlink" title="2) 컨텐츠 기반 필터링(Content-based filtering)"></a>2) <code>컨텐츠 기반 필터링(Content-based filtering)</code></h3><ul><li><p><code>Keyword</code>(item을 설명(describe)하는데 사용함.), <code>Profile</code>(사용자가 좋아하는 type의 item을 가리키게(indicate) 만들어짐.)을 통해 <code>과거에 사용자자가 좋아했던 것들 (또는 현재 보고 있는 것들)과 비슷한 items을 추천하려고 한다</code>. 다양한 후보 items는 사용자에 의해 평가되는(rated) items와 비교되고 그 중 best-matching items를 추천한다. Pandora Radio는 첫 seed와 같이 사용자에 의해 제공된 노래와 비슷한 특징의 음악을 재생해 주는 content-based recommendation System이다.</p></li><li><p>이 접근법은 집합적 정보로부터 원하는 내용이나 관련된 내용을 가져오는 <code>Inforamtion retrieval</code>과 필요없는 정보를 제거하는 <code>Information filtering</code>에 뿌리를 두고 있다. Items의 특징(Keyword)을 끌어내기 위해 <code>TF-IDF(Term frequency-inverse document frequency)</code>를 사용한다</p></li><li><p>User의 profil을 만들기 위해서, 그 시스템은 대게 두가지 정보에 집중한다.</p><ul><li>1) 사용자의 선호의 model</li><li><p>2) 추천시스템과 사용자의 상호작용 정보(history)</p></li><li><p>기본적으로 이런 방법들은 시스템 안에서 item에 특성을 부여하면서 item profile(이산적 feature와 attributes)을 사용한다. 그 시스템은 item 특성의 <code>weighted vector을 기반으로 한 사용자의 content-based profile</code>을 만든다. <code>Weights</code>는 <code>사용자에게 각각의 feature의 중요도</code>를 나타내고 개별적으로 점수 매겨진(rated) content vector로 부터 다양한 방법으로 계산될 수 있다. 사용자가 좋아할 것 같 확률을 계산하기 위해 복잡한 방법들(베이지안 분류, 클러스터 분석, 결정트리, 그리고 인공 신경망 네트워크왁 같은 머신러닝 기술을 사용하는 반면에, 간단한 접근법들은 그 점수 매겨진 item vector의 평균 값을 사용한다.</p></li><li><p>보통 ‘좋아요’와 ‘싫어요’와 같은 형태로 사용자로부터 직접적인 피드백은 특정한 속성(attribute)의 중요도에 대한 더 높거나 낮은 weight를 할당하는데 사용될 수 있다.</p></li></ul></li><li><p><code>Content-based filtering의 중요한 문제점</code>은, <code>하나의 content source에 관련된 사용자들 행동으로부터 사용자 선호도를 배울 수 있고 다른 content 종류(type)에 대해서도 배운 사용자 선호도들을 적용시킬 수 있는지에 대한 여부이다.</code> 그 시스템이 다른 서비스의 다른 종류의 content를 추천할 수 있는 것보다 사용자가 이미 사용한 것과 같은 종류의 content를 추천하는 것에 한정돼 있다면 해당 추천 시스템의 가치는 상당히 낮을 것이다. 예를 들어, news browsing에 기반한 추천 뉴스 기사는 유용하지만, news browsing에 기반해 추천될 수 있는 다른 서비스의 음악, 비디오, 제품 토론에서 더 유용하다.</p></li></ul><p><img src="/image/Content_Based_Filtering.png" alt="Content_Based_Filtering"></p><h3 id="참고-TF-IDF"><a href="#참고-TF-IDF" class="headerlink" title="참고) TF-IDF"></a>참고) TF-IDF</h3><ul><li><p>정보검색과 텍스트 마이닝에서 이용하는 가중치로, 여러 문서로 이루어진 문서군이 있을 때 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지를 나타내는 통계적 수치이다. 문서의 핵심어를 추출하거나 검색엔진에서 검색 결과의 순위를 결정하거나,문서들 사이의 비슷한 정도를 구하는 등의 용도로 사용할 수 있다.</p></li><li><p>IDF 값은 문서군의 성격에 따라 결정된다. 예를 들어, ‘원자’라는 낱말은 일반적으로 문서들 사이에서는 잘 나오지 않기 때문에 IDF 값이 높아지고 문서의 핵심어가 될 수 있지만, 원자에 대한 문서를 모아놓은 문서군의 경우 이 낱말은 상투어가 되어 각 문서들을 세분화하여 구분할 수 있는 다른 낱말들이 높은 가중치를 얻게 된다.</p></li><li><p><code>특정 문서 내에서 단어 빈도가 높을수록, 그리고 전체 문서들 중 그 단어를 포함한 문서가 적을수록  TF-IDF값이 높아진다. 따라서 이 값을 이용하면 모든 문서에 흔하게 나타나는 단어를 걸러내는 효과를 얻을 수 있다. IDF의 로그 함수값은 항상 1이상이므로, IDF값과 TF-IDF값을 항상 0 이상이 된다. 특정 단어를 포함하는 문서들이 많을 수록 로그 함수 안의 값이 1에 가까워지게 되고, 이 경우 IDF값과 TF-ID값은 0에 가까워지게 된다.</code></p></li></ul><script type="math/tex; mode=display">TF-IDF = TF \times IDF</script><ul><li><p><code>TF(Term Frequency, 단어 빈도)</code></p><ul><li><code>특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값</code></li><li>산출 방식<ul><li>ㄴ. TF :<script type="math/tex; mode=display">tf(t, d) = f(t, d) (f(t, d) : 문서 d 내에서 단어 t의 총 빈도)</script></li><li>ㄴ. Boolean TF :<script type="math/tex; mode=display">tf(t, d) = t가 d에 한 번이라도 나타나면 1, 아니명 0</script></li><li>ㄴ. log scale TF :<script type="math/tex; mode=display">tf(t, d) = \log(f(t, d) +1)</script></li><li>ㄴ. 증가 빈도 TF :<ul><li>일반적으로는 문서의 길이가 상대적으로 길 경우, 단어 빈도값을 조정하기 위해 사용<script type="math/tex; mode=display">tf(t, d) =  0.5 + \frac{0.5 \times f(t, d)}{max{f(w, d) : w \in d}} = 0.5 + \frac{0.5 \times target 단어에 대한 TF}{동일 문서(문장)내에서의 최빈단어의 빈도수}</script></li></ul></li></ul></li></ul></li><li><p><code>IDF(Inverse Document Frequency, 역문서 빈도)</code></p><ul><li><p>TF 값이 높을 수록 문서에서 중요하다고 생각될 수도 있지만 단순히 흔하게 등장하는 것일 수도 있다. 이값을 DF(Document Frequency, 문서 빈도)라고한다. 영어문장에서 예를 들자면 가령 I, you 같은 단어들을 예로 들 수 있을 것이다. <code>DF의 역수를 IDF(Inverse Document Frequency, 역문서 빈도)</code>라고 한다. <code>한 단어가 문서 집합 전체에서 얼마나 공통적으로 나타나는지를 나타내는 값</code></p></li><li><p>IDF 값은 문서군의 성격에 따라 결정된다. 예를 들어, ‘원자’라는 낱말은 일반적으로 문서들 사이에서는 잘 나오지 않기 때문에 IDF 값이 높아지고 문서의 핵심어가 될 수 있지만, 원자에 대한 문서를 모아놓은 문서군의 경우 이 낱말은 상투어가 되어 각 문서들을 세분화하여 구분할 수 있는 다른 낱말들이 높은 가중치를 얻게 된다.</p></li><li><p>산출 방식</p><ul><li>$ \mid D \mid$ : 문서 집합 D의 크기, 또는 전체 문서의 수</li><li>$ \mid d \in D : t \in d  \mid$ : 단어 t가 포함된 문서의 수(즉, $tf(t,0) \neq 0$). <code>단어가 전체 말뭉치(Corpus)안에 존재하지 않을 경우 이는 분모가  0이 되는 결과를 가져온다. 이를 방지하기 위해</code> $1 +  \mid d \in D : t \in d  \mid $로 쓰는 것이 일반적이다.<script type="math/tex; mode=display">idf(t, D) = \log \frac{ \mid D  \mid}{ \mid d \in D : tin d  \mid} =  \log \frac{전체 문서의 수}{해당 Target단어를 포함한 문서의 수}</script></li></ul></li></ul></li></ul><h3 id="3-Hybrid-Recommendation-Systems"><a href="#3-Hybrid-Recommendation-Systems" class="headerlink" title="3) Hybrid Recommendation Systems"></a>3) <code>Hybrid Recommendation Systems</code></h3><ul><li><p>위의 2가지 Recommendation System들은 각각의 장점과 단점이 존재함을 살펴보았다. 그래서 최근 연구는 <code>Collaborative filtering과 content-based filtering을 섞은 Hybrid 접근법</code>이 몇몇의 상황(<code>Cold start(충분한 정보가 없어서 필요한 정보를 얻지 못하는 것)) Sparsity</code>)에서 <code>더 효과적</code>일 수 있다고 설명한다.</p></li><li><p><code>Hybrid 추천 시스템</code>이란 용어는 아래의 각 시스템별 단점들을 보완하기 위해 <code>다중의 추천 기술을 함께 섞는 어떠한 추천 시스템</code>을 의미하며 다중의 추천 기술이 내포하고 있는 의미는 동일한 기술을 여러개 겹치는 것도 포함된다.</p></li></ul><div class="table-container"><table><thead><tr><th>Collaborative</th><th>이 시스템은 다른 사용자들과 items에 대한 profiles을 평가하는 정보만 사용하면서 추천을 한다.  이 시스템은 현재의 사용자나 items과 비슷한 평가 기록(history)와 함께 비슷한(peer) 사용자  또는 items을 배치하고, 이 근접이웃(neighborhood)를 이요해서 추천을 만든다. 사용자 기반과  item기반의 가장 가까운 이웃 알고리즘은 cold-start문제를 해결하기 위해 합쳐질 수 있고 추천  결과를 향상시킬 수 있다.</th></tr></thead><tbody><tr><td>Content-based</td><td>이 시스템은 사용자가 그들에게 준 평가와 제품들과 관련된 특징이라는 두가지 Sources로부터 추천을  만든다. Content-based 추천자는 추천을 user-specific 분류 문제처럼 다루고 제품의 특징에  기반한 사용자의 좋아요와 싫어요의 분류자를 학습한다.</td></tr><tr><td>Demographic</td><td>Demographic(인구 통계학적) 추천은 사용자의 인구통계학적 정보(profile)를 기반으로 추천을  제공한다. 추천된 제품은 그 영역의 사용자들의 평가들을 합침으로써 다른 인구통계학적 영역을 위해  만들어 질 수 있다.</td></tr><tr><td>Knowledge-based</td><td>이 추천자는 사용자의 선호와 요구(needs)에 대한 추론을 기반으로 한 제품을 제안한다.  이 지식(knowledge)는 때때로 얼마나 특정한 제품 특징이 사용자의 요구를 충족시키는  지에 대한 뚜렷한 기능적(functional) 지식을 포함한다.</td></tr></tbody></table></div><ul><li>Netflix는 Hybrid 추천 시스템의 좋은 예이다. 사용자가 높게 평가했던(Content-based)영화와 비슷한 feature를 띄는 영화를 추천하고, 비슷한 사용자(collaborate)들의 검색 습관과 시청을 비교함으로서 추천을 한다.</li></ul><p><img src="/image/Hybrid_Recommendation.png" alt="Hybrid Recommendation"></p><h3 id="정확도를-넘어서"><a href="#정확도를-넘어서" class="headerlink" title="정확도를 넘어서"></a>정확도를 넘어서</h3><p>전형적으로, 추천 시스템에 대한 연구는 가장 정확한 추천 알고리즘을 찾는 것에 관심을 둔다. 하지만, 많은 중요한 요소들이 있다.</p><ul><li><p><code>Diversity</code></p><ul><li>사용자들은 자신이 선택한 Item과 유사성이 높은 intra-list에 포함된 다른 아티스들을 보이는 다양성을 갖춘 추천 시스템에 더 만족하는 경향을 보인다.</li></ul></li><li><p><code>Recommender persistence</code></p><ul><li>어떤 상황에서, 추천시스템이 그 이전의 추천과 동일한 추천을 다시 보여주거나 사용자가 다시 items을 평가하게 하는 것이 더 효과적이다.</li></ul></li><li><p><code>Privacy</code></p><ul><li>추천 시스템은 대게 privacy 문제를 해결해야 한다. 왜냐하면 사용자들은 민감한 정보를 공개해야하기 때문이다. Collaborative filtering을 사용해 사용자의 Profiles을 만드는 것은 privacy의 관점에서 문제가 될 수 있다. 많은 유럽 국가들은 data privacy에 대한 강한 문화를 가지고 있고, 사용자의 profile을 만드는 어떠한 단계를 소개하려는 시도는 부정적인 사용자 반응을 초래할 수 있다. 실제로 Netflix는 데이터 대회를 통해 데이터를 공개했다가 비식별화된 데이터와 다른 데이터를 연결함을써 개인을 식별할 수 있게 됨을 확인했고, 고소까지 당했었다.</li></ul></li><li><p><a href="https://ko.wikipedia.org/wiki/%EC%B6%94%EC%B2%9C_%EC%8B%9C%EC%8A%A4%ED%85%9C" target="_blank" rel="noopener">그 이외의 주의사항</a></p></li></ul><h4 id="참고-문헌-및-사이트"><a href="#참고-문헌-및-사이트" class="headerlink" title="참고 문헌 및 사이트"></a>참고 문헌 및 사이트</h4><ul><li><p>웹 사이트</p><ul><li><a href="https://www.fun-coding.org/recommend_basic1.html" target="_blank" rel="noopener">잔재미 코딩</a></li><li><a href="https://leebaro.tistory.com/category/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%28Machine%20Learning%29/%EC%B6%94%EC%B2%9C%20%EC%8B%9C%EC%8A%A4%ED%85%9C%28Recommendation%20System%29" target="_blank" rel="noopener">leebaro blog</a></li><li><a href="https://darkpgmr.tistory.com/106" target="_blank" rel="noopener">svd의 활용에 관한 darkpgmr님의 블로그</a></li><li><a href="https://bcho.tistory.com/1216" target="_blank" rel="noopener">NMF 알고리즘을 이용한 유사한 문서검색과 구현</a></li><li><a href="http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/" target="_blank" rel="noopener">Python을 이용한 행렬의 분해 예제</a></li><li><a href="https://tv.naver.com/v/2297146" target="_blank" rel="noopener">naver 검색엔진 추천시스템 airs개발기(2017 Deview)</a></li><li><a href="http://datasqz.com/movie-names/movie-similar" target="_blank" rel="noopener">Movie recommendation system 예시</a></li><li><a href="http://sanghyukchun.github.io/73/" target="_blank" rel="noopener">sanghyukchun님의 github blog(Recommendation System)</a></li><li><a href="https://ebaytech.berlin/deep-learning-for-recommender-systems-48c786a20e1a" target="_blank" rel="noopener">추천시스템을 위한 Deep learning</a></li></ul></li><li><p>문헌</p><ul><li>Building Recommendation Engines</li><li>Recommender Systems in E-CommerceJ. Ben Schafer, Joseph Konstan, John Riedl</li><li>State of the Art Recommender System. Laurent Candillier, Kris Jack</li><li>Recommender Systems in E-Commerce. Sanjeevan Sivapalan, Alireza Sadeghian</li><li>A Survey of e-Commerce Recommender Systems Farida Karimova, PhD</li><li>Low-Rank Matrix Completion (2013) by Ryan Kennedy</li><li>Exact Matrix Completion via Convex Optimization Emmanuel J. Cand`es</li></ul></li></ul>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/12/14/Recommendation_System_00/#disqus_thread</comments>
    </item>
    
    <item>
      <title>API는 무엇인가?!?(1)</title>
      <link>https://heung-bae-lee.github.io/2019/12/13/data_engineering_03/</link>
      <guid>https://heung-bae-lee.github.io/2019/12/13/data_engineering_03/</guid>
      <pubDate>Fri, 13 Dec 2019 04:25:42 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;REST-API의-정의와-예제들&quot;&gt;&lt;a href=&quot;#REST-API의-정의와-예제들&quot; class=&quot;headerlink&quot; title=&quot;REST API의 정의와 예제들&quot;&gt;&lt;/a&gt;REST API의 정의와 예제들&lt;/h2&gt;&lt;h3 id=&quot;API-A
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h2 id="REST-API의-정의와-예제들"><a href="#REST-API의-정의와-예제들" class="headerlink" title="REST API의 정의와 예제들"></a>REST API의 정의와 예제들</h2><h3 id="API-Application-Programming-Interface"><a href="#API-Application-Programming-Interface" class="headerlink" title="API(Application Programming Interface)"></a>API(Application Programming Interface)</h3><ul><li>두 개의 시스템이 서로 상호 작용하기 위한 인터페이스<ul><li>데이터를 주고 받는 인터페이스</li><li>API라고 하면 보통 REST API를 지칭</li></ul></li></ul><p><img src="/image/Web_API.png" alt="Web_API"></p><ul><li>웹사이트는 HTTP(S)프로토콜을 사용하는 REST API 기반으로 구축</li></ul><h2 id="API-접근-권한"><a href="#API-접근-권한" class="headerlink" title="API 접근 권한"></a>API 접근 권한</h2><h3 id="Authentication-VS-Authorization"><a href="#Authentication-VS-Authorization" class="headerlink" title="Authentication VS Authorization"></a>Authentication VS Authorization</h3><ul><li>Authentication : Identity(정체)가 맞다는 증명</li><li>Authorization : API를 통한 어떠한 액션을 허용</li></ul><h5 id="API가-Authentication으로-하여도-어떠한-액션에-대해서는-Authorization을-혀용하지-않을-수-있음"><a href="#API가-Authentication으로-하여도-어떠한-액션에-대해서는-Authorization을-혀용하지-않을-수-있음" class="headerlink" title="API가 Authentication으로 하여도 어떠한 액션에 대해서는 Authorization을 혀용하지 않을 수 있음"></a><code>API가 Authentication으로 하여도 어떠한 액션에 대해서는 Authorization을 혀용하지 않을 수 있음</code></h5><h3 id="API의-필수는-첫째도-둘째도-Security"><a href="#API의-필수는-첫째도-둘째도-Security" class="headerlink" title="API의 필수는 첫째도 둘째도 Security"></a>API의 필수는 첫째도 둘째도 Security</h3><ul><li>어떠한 Security 방안이 없을 경우<ul><li>DELETE request를 통해서 다른 이용자의 정보를 지울 수도 있음</li><li>제 3자에게 데이터 유출로 이어질 수 있음</li><li>누가 API를 사용하는지, 어떤 정보를 가져가는지 트래킹 할 수가 없음</li></ul></li></ul><h3 id="API-Key란-무엇인가"><a href="#API-Key란-무엇인가" class="headerlink" title="API Key란 무엇인가?"></a>API Key란 무엇인가?</h3><ul><li>API Key란 보통 Request URL혹은 Request 헤더에 포함되는 긴 String</li></ul><h3 id="Basic-Auth"><a href="#Basic-Auth" class="headerlink" title="Basic Auth"></a>Basic Auth</h3><p><img src="/image/BAsic_Auth.png" alt="Basic Auth"></p><h3 id="OAuth-2-0"><a href="#OAuth-2-0" class="headerlink" title="OAuth 2.0"></a>OAuth 2.0</h3><ul><li>설명하자면 Web API는 우리가 직접 어떤 Action을 하는 것이기 때문에 해당 Web에만 접근 권한을 받으면 되지만, 그와는 다르게 어떤 Action을 취할 Web을 다른 앱에게 접근 권한을 주어 End User인 우리 대신 정보를 제공하게 해주는 방식이다. 예를 듬면 우리가 어떤 서비스를 가입하려고 할때 SNS로 가입이 가능하게 할 수 있는 접근 권한 방식이라고 할 수 있다.<br><img src="/image/OAuth2.png" alt="OAuth2.0"></li></ul><h2 id="Endpoints-amp-Methods"><a href="#Endpoints-amp-Methods" class="headerlink" title="Endpoints &amp; Methods"></a>Endpoints &amp; Methods</h2><ul><li><code>Resource</code>는 API를 통해 리턴된 정보이며, 하나의 <code>Resource</code> 안에 여러개의 Endpoints가 존재한다.<br><img src="/image/Endpoints_Method.png" alt="Endpoint_Method"></li></ul><p><img src="/image/Methods.png" alt="Methods 정의"></p><h2 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h2><ul><li>Parameters는 Endpoint를 통해 Requests 할때 같이 전달하는 옵션들<ul><li>Request Body안에 포함되는 Parameter들은 post 방식에서 주로 많이 사용한다.<br><img src="/image/" alt="4가지 Parameter 타입들"></li></ul></li></ul>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/12/13/data_engineering_03/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Basic ConvNN(VGG-16모방한 기본)구현</title>
      <link>https://heung-bae-lee.github.io/2019/12/13/deep_learning_05/</link>
      <guid>https://heung-bae-lee.github.io/2019/12/13/deep_learning_05/</guid>
      <pubDate>Fri, 13 Dec 2019 03:58:02 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Basic-ConvNN-구현&quot;&gt;&lt;a href=&quot;#Basic-ConvNN-구현&quot; class=&quot;headerlink&quot; title=&quot;Basic ConvNN 구현&quot;&gt;&lt;/a&gt;Basic ConvNN 구현&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;참고로 저는 mac을 
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h1 id="Basic-ConvNN-구현"><a href="#Basic-ConvNN-구현" class="headerlink" title="Basic ConvNN 구현"></a>Basic ConvNN 구현</h1><ul><li>참고로 저는 mac을 사용하기에 local에서말고 GPU를 사용허게끔 Google Colab을 사용하였다. 제가 구현한 방식은 tensorflow 2.0 version이므로(tf.function을 사용하느라) colab의 tensorflow의 version이 뭔지 먼저 확인했습니다. 1.15 version이어서 2.0으로 설치를 진행한 후 코드를 실행하였습니다. <code>참고로 2.0으로 설치하고 난 후에는 꼭 반드시 런타임을 재시작 해주셔야 업데이트 한 2.0 version으로 사용하실 수 있습니다.</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"><span class="built_in">print</span>(tf.__version__)</span><br></pre></td></tr></table></figure><h2 id="런타임-재시작-후"><a href="#런타임-재시작-후" class="headerlink" title="런타임 재시작 후"></a>런타임 재시작 후</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install tensorflow==2.0.0-beta1</span><br></pre></td></tr></table></figure><h2 id="기본-합성곱-신경망-구현"><a href="#기본-합성곱-신경망-구현" class="headerlink" title="기본 합성곱 신경망 구현"></a>기본 합성곱 신경망 구현</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br></pre></td></tr></table></figure><h2 id="하이퍼-파라미터"><a href="#하이퍼-파라미터" class="headerlink" title="하이퍼 파라미터"></a>하이퍼 파라미터</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EPOCHS = 10</span><br></pre></td></tr></table></figure><h3 id="참고로-conv-layer을-통과한-출력의-dimension을-계산하는-것은-다음과-같다"><a href="#참고로-conv-layer을-통과한-출력의-dimension을-계산하는-것은-다음과-같다" class="headerlink" title="참고로 conv layer을 통과한 출력의 dimension을 계산하는 것은 다음과 같다."></a>참고로 conv layer을 통과한 출력의 dimension을 계산하는 것은 다음과 같다.</h3><h4 id="padding-2N-1-kernel-size-Filter-size-로-N을-구한다"><a href="#padding-2N-1-kernel-size-Filter-size-로-N을-구한다" class="headerlink" title="padding : 2N+1 = kernel_size(Filter_size)로 N을 구한다."></a>padding : 2N+1 = kernel_size(Filter_size)로 N을 구한다.</h4><h4 id="output-dimension"><a href="#output-dimension" class="headerlink" title="output dimension :"></a>output dimension :</h4><script type="math/tex; mode=display">\frac{input\hspace{0.1cm} size + (padding\hspace{0.1cm} size * 2) - filter\hspace{0.1cm}size}{strid} + 1</script><h2 id="모델-정의"><a href="#모델-정의" class="headerlink" title="모델 정의"></a>모델 정의</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">class ConvNet(tf.keras.Model):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(ConvNet, self).__init__()</span><br><span class="line">        self.sequence = []</span><br><span class="line">        conv2d = tf.keras.layers.Conv2D</span><br><span class="line">        max_pool = tf.keras.layers.MaxPool2D</span><br><span class="line">        flatten =  tf.keras.layers.Flatten</span><br><span class="line">        <span class="comment"># filters = 16 (출력되는 channel의 수)</span></span><br><span class="line">        <span class="comment"># kernel_size = 3 * 3</span></span><br><span class="line">        <span class="comment"># padding의 default값인 'valid'는 zero-padding을 해주지 않음으로써 영상의 크기가 Conv layer를 통과함으로써 줄어들 수 있다.</span></span><br><span class="line">        <span class="comment"># 'same'은 zero-padding을 의미 여기서는 동일한 크기를 유지하기 위해</span></span><br><span class="line">        <span class="comment"># input data는 (28x28x1)을 갖는 MNIST이다.</span></span><br><span class="line">        <span class="comment"># VGG-16의 가장 큰 특징은 Pooling을 하기 전에 동일한 Conv Layer를 반복해서 사용하는 것이다.</span></span><br><span class="line">        self.sequence.append(conv2d(16, (3,3), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)) <span class="comment"># output dimension (28x28x16)</span></span><br><span class="line">        self.sequence.append(conv2d(16, (3,3), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)) <span class="comment"># output dimension (28x28x16)</span></span><br><span class="line">        <span class="comment"># 2x2 pooling을 한다. maxpooling을 이용하여 영상의 크기를 줄여준다.</span></span><br><span class="line">        self.sequence.append(max_pool((2,2))) <span class="comment"># output dimension (14x14x16)</span></span><br><span class="line"></span><br><span class="line">        self.sequence.append(conv2d(32, (3,3), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)) <span class="comment"># output dimension (14x14x32)</span></span><br><span class="line">        self.sequence.append(conv2d(32, (3,3), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)) <span class="comment"># output dimension (14x14x32)</span></span><br><span class="line">        self.sequence.append(max_pool((2,2))) <span class="comment"># output dimension (7x7x32)</span></span><br><span class="line"></span><br><span class="line">        self.sequence.append(conv2d(64, (3,3), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)) <span class="comment"># output dimension (7x7x64)</span></span><br><span class="line">        self.sequence.append(conv2d(64, (3,3), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)) <span class="comment"># output dimension (7x7x64)</span></span><br><span class="line"></span><br><span class="line">        self.sequence.append(flatten()) <span class="comment"># 1568x1</span></span><br><span class="line">        self.sequence.append(tf.keras.layers.Dense(2028, activation=<span class="string">'relu'</span>))</span><br><span class="line">        self.sequence.append(tf.keras.layers.Dense(10, activation=<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line">    def call(self, x, training=False, mask=None):</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.sequence:</span><br><span class="line">            x = layer(x)</span><br><span class="line">        <span class="built_in">return</span> x</span><br></pre></td></tr></table></figure><h2 id="학습-테스트-루프-정의"><a href="#학습-테스트-루프-정의" class="headerlink" title="학습, 테스트 루프 정의"></a>학습, 테스트 루프 정의</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Implement training loop</span></span><br><span class="line">@tf.function</span><br><span class="line">def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):</span><br><span class="line">    with tf.GradientTape() as tape:</span><br><span class="line">        predictions = model(images)</span><br><span class="line">        loss = loss_object(labels, predictions)</span><br><span class="line">    gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class="line"></span><br><span class="line">    optimizer.apply_gradients(zip(gradients, model.trainable_variables))</span><br><span class="line">    train_loss(loss)</span><br><span class="line">    train_accuracy(labels, predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Implement algorithm test</span></span><br><span class="line">@tf.function</span><br><span class="line">def test_step(model, images, labels, loss_object, test_loss, test_accuracy):</span><br><span class="line">    predictions = model(images)</span><br><span class="line"></span><br><span class="line">    t_loss = loss_object(labels, predictions)</span><br><span class="line">    test_loss(t_loss)</span><br><span class="line">    test_accuracy(labels, predictions)</span><br></pre></td></tr></table></figure><h2 id="데이터셋-준비"><a href="#데이터셋-준비" class="headerlink" title="데이터셋 준비"></a>데이터셋 준비</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line"><span class="comment"># 입력 영상이 총 8bit 즉, 0~255 사이의 값들로 이루어져 있으므로</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 0~1표현으로 바꿔준다.</span></span><br><span class="line">x_train, x_test = x_train / 255.0, x_test / 255.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 입력 영상 하나의 사이즈는 28x28이므로 channel을 하나 더 늘려 주어야한다.</span></span><br><span class="line"><span class="built_in">print</span>(x_train.shape)</span><br><span class="line"><span class="built_in">print</span>(x_train[0].shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># x_train : (NUM_SAMPLE, 28, 28) -&gt; (NUM_SAMPLE, 28, 28 , 1)</span></span><br><span class="line"><span class="comment"># ...은 해당 데이터 객체의 모든 axis를 표현하는 것이다.</span></span><br><span class="line"><span class="comment"># 위에서 255.0으로 나누어주게 되면 float64로 되므로 자료형을 float32로 해야 error가 없다.</span></span><br><span class="line"><span class="comment">## x_train[:,:,:, tf.newaxis]</span></span><br><span class="line">x_train = x_train[..., tf.newaxis].astype(np.float32)</span><br><span class="line">x_test = x_test[..., tf.newaxis].astype(np.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Numpy object나 Tensor로 부터 데이터셋을 구축할 수 있다.</span></span><br><span class="line">train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)</span><br><span class="line"><span class="comment"># test data는 suffle할 필요없다.</span></span><br><span class="line">test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)</span><br></pre></td></tr></table></figure><h2 id="학습-환경-정의"><a href="#학습-환경-정의" class="headerlink" title="학습 환경 정의"></a>학습 환경 정의</h2><h3 id="모델-생성-손실함수-최적화-알고리즘-평가지표-정의"><a href="#모델-생성-손실함수-최적화-알고리즘-평가지표-정의" class="headerlink" title="모델 생성, 손실함수, 최적화 알고리즘, 평가지표 정의"></a>모델 생성, 손실함수, 최적화 알고리즘, 평가지표 정의</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create model</span></span><br><span class="line">model = ConvNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define loss and optimizer</span></span><br><span class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class="line">optimizer = tf.keras.optimizers.Adam()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define performance metrics</span></span><br><span class="line">train_loss = tf.keras.metrics.Mean(name=<span class="string">'train_loss'</span>)</span><br><span class="line">train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">'train_accuracy'</span>)</span><br><span class="line"></span><br><span class="line">test_loss = tf.keras.metrics.Mean(name=<span class="string">'test_loss'</span>)</span><br><span class="line">test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">'test_accuracy'</span>)</span><br></pre></td></tr></table></figure><h2 id="학습-루프-동작"><a href="#학습-루프-동작" class="headerlink" title="학습 루프 동작"></a>학습 루프 동작</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCHS):</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> train_ds:</span><br><span class="line">        train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> test_images, test_labels <span class="keyword">in</span> test_ds:</span><br><span class="line">        test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)</span><br><span class="line"></span><br><span class="line">    template = <span class="string">'Epoch &#123;&#125;, Loss: &#123;&#125;, Accuracy: &#123;&#125;, Test Loss: &#123;&#125;, Test Accuracy: &#123;&#125;'</span></span><br><span class="line">    <span class="built_in">print</span>(template.format(epoch + 1,</span><br><span class="line">                          train_loss.result(),</span><br><span class="line">                          train_accuracy.result() * 100,</span><br><span class="line">                          test_loss.result(),</span><br><span class="line">                          test_accuracy.result() * 100))</span><br><span class="line">    <span class="comment"># reset_state는 새로운 값들을 받기 위해 하는 건가?</span></span><br><span class="line">    train_loss.reset_states()</span><br><span class="line">    train_accuracy.reset_states()</span><br><span class="line">    test_loss.reset_states()</span><br><span class="line">    test_accuracy.reset_states()</span><br></pre></td></tr></table></figure><p><img src="/image/basic_convNN_result.png" alt="result"></p>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/12/13/deep_learning_05/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Convolution Neural Network(1)</title>
      <link>https://heung-bae-lee.github.io/2019/12/10/deep_learning_04/</link>
      <guid>https://heung-bae-lee.github.io/2019/12/10/deep_learning_04/</guid>
      <pubDate>Tue, 10 Dec 2019 04:50:24 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;합성곱-연산과-이미지-필터&quot;&gt;&lt;a href=&quot;#합성곱-연산과-이미지-필터&quot; class=&quot;headerlink&quot; title=&quot;합성곱 연산과 이미지 필터&quot;&gt;&lt;/a&gt;합성곱 연산과 이미지 필터&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/image/analo
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h2 id="합성곱-연산과-이미지-필터"><a href="#합성곱-연산과-이미지-필터" class="headerlink" title="합성곱 연산과 이미지 필터"></a>합성곱 연산과 이미지 필터</h2><p><img src="/image/analog_signal.png" alt="아날로그 신호처리"></p><ul><li>아날로그 신호처리는 <code>선형이고 시불변인 시스템</code>에 의존해서 개발이 되게 되는데, Noise가 있는 입력이 들어왔을 때 넣어주면 Noise가 제거된 출력이 나오는 이런 시스템을 모두 LTI system이라고 부른다. <code>디지털 신호가 아닌 아날로그 신호로부터 LTI system이 정의</code>되어있다. 선형이라는 것은 대부분 알고 있듯이 선형대수에서 나오는 linearity를 만족시키면 되는 것이고, <code>시불변이라는 의미는 시간이 지나도 동일한 결과를 내보내준다는 의미이다.</code> 확률과정에서 step에 영향을 받지 않는다라고 보면 좋을 것 같다. 사람은 대표적으로 LTI 시스템이 아닌 시스템이다.</li></ul><p><img src="/image/Dirac_delta_function.png" alt="Dirac 델타 함수"></p><ul><li>수학적으로는 엄밀하진 않지만, 공학에선 많이 사용한다. 왼쪽의 삼각형을 모든 구간에 대해 전부해준다면 값은 1이 될 것이다. 여기서 $h\to\infty$가 되면, Dirac 델타 함수가 된다.<ul><li>시간 t=0만 임의의 값을 갖고, 나머지 구간은 0을 갖는다.</li><li>모든 구간에서 적분한 값이 1</li></ul></li></ul><p><img src="/image/impulse_response.png" alt="임펄스 응답"></p><p><img src="/image/convolution_operation.png" alt="합성곱 연산"></p><ul><li><code>convolution을 한다는 것은 임의의 두 함수 중 한 함수를 좌우로 뒤집고 이동시키면서 두함수의 곱을 적분하여 계산한다.</code></li></ul><p><img src="/image/conv_operation_and_LTI_system.png" alt="합성곱 연산과 LTI 시스템"></p><p><img src="/image/2_Dimension_2_channel.png" alt="이차원 신호와 흑백 이미지"></p><p><img src="/image/2_Dimension_color_image.png" alt="이차원 신호와 컬러 이미지"></p><p><img src="/image/image_conv.png" alt="영상의 합성곱 계산"><br><a href="http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html" target="_blank" rel="noopener">합성곱 계산 animation</a></p><p><img src="/image/noise_removal_filter.png" alt="잡음 제거 필터"></p><p><img src="/image/differentiation_filter.png" alt="미분 필터"></p><ul><li>vertical Sobel Filter가 왜 미분 필터이냐고 의문이 든다면, 1차원 신호를 data로 생각하고 앞서 했었던 수치 미분을 떠올려 보자. 그렇다면, 단숨에 이해가 갔을 것이다. 지금은 vertical Sobel Filter이므로 가로의 Edge는 추출하지 못한 것을 확인할 수 있다. 그에 반해 세로 성분들은 잘 검출된 것을 확인 할 수 있다. 만일 위의 필터를 90도 rotate해주게되면 가로로 미분하는 horizonal Sobel Filter가 되어 위의 결과와는 반대의 결과를 보여줄 것이다.</li></ul><h2 id="합성곱-계층"><a href="#합성곱-계층" class="headerlink" title="합성곱 계층"></a>합성곱 계층</h2><p><img src="/image/product_to_conv.png" alt="곱에서 합성곱으로"></p><ul><li><code>입력</code>이 이제는 <code>영상</code>으로 여러개 들어오게 되어 각각의 입력층의 뉴런 하나 하나가 <code>channel</code>이라고 불린다. <code>필터 가중치</code>는 보통 <code>3x3, 5x5, 7x7등을 주로 사용</code>한다. 2D signal과 2D signal을 곱(<code>element-wise product or Hadamard product</code>)해야하므로 <code>합성곱</code>을 사용한다.  </li></ul><p><img src="/image/FC_Layer_conv.png" alt="전결합 계층"></p><p><img src="/image/Conv_layer.png" alt="합성곱 계층"></p><ul><li>$kernel_{Height} \times kernel_{Width} \times channel_{in} \times channel_{out}$ 만큼의 parameter가 필요하다. filter는 $Channel_{in} \times Chaeel_{out}$개 만큼 있을 것이다.</li></ul><p><img src="/image/Conv_Layer_meaning.png" alt="합성곱 계층의 의미"></p><ul><li>kernel(Filter)에 나타나는 모양과 유사한 모양을 한 위치가 높은 값으로 나타나게 된다.</li></ul><h2 id="기본적인-합성곱-신경망"><a href="#기본적인-합성곱-신경망" class="headerlink" title="기본적인 합성곱 신경망"></a>기본적인 합성곱 신경망</h2><p><img src="/image/basic_conv_structure.png" alt="합성곱 신경망의 기본 구조"></p><p><img src="/image/Conv_Layer_feature_map.png" alt="합성곱 계층"></p><ul><li>stride요소를 넣지 않으면, 합성곱 계층에서는 영상의 크기는 그대로이며, <code>영상의 채널 수</code>가 달라진다.</li><li><code>kernel(filter)가 돌아다니면서 포착하는 형태이기 때문에 공간적인 특징</code>이 있고, 따라서 <code>Feature Map</code>이라고 한다.</li></ul><p><img src="/image/Pooling_Layer.png" alt="풀링 계층"></p><p><img src="/image/Pooling_Layers.png" alt="Pooling Layers"></p><ul><li>classification에서는 Max Pooling이 주로 잘 먹힌다!</li></ul><p><img src="/image/Flatten.png" alt="평탄화"><br>-<code>Convolutional Layer와 FC Layer를 연결해주기 위해 필요하다</code></p><p><img src="/image/FC_Layer_why.png" alt="전결합 계층"></p><p><img src="/image/why_use_this_structure_conv.png" alt="그러면 왜 이런 구조를 쓰나?"></p><ul><li><p>먼저, 맨 처음 언급했던 머신러닝과 딥러닝의 가장 큰 차이는 사람이 feature를 넣어주느냐 그렇지 않느냐의 차이라고 했다. 크게 보면 위의 그래프에서 합성곱 계층과 활성함수의 과정을 N번 반복하는 것은 shallowNN의 input으로 넣어 줄 Feature를 뽑는 과정이라고 직관적으로 이해할 수 있다.</p></li><li><p>앞의 합성곱 계층에서 activation function 까지를 계속해서 <code>진행 할수록 Feature Map의 크기(width와 height)는 Kernel과 Pooling에 의해서 줄어들고 channel(depth)는 늘어나게 될 것이다. 또한 처음부터 끝까지 동일한 크기의 kernel(Filter)을 사용한다고 가정한다면, 영상에서 더 넓은 영역을 커버하는 효과를 주는 것과 동일하다.</code></p></li></ul><p><img src="/image/Receptive_Field.png" alt="Receptive Field"></p><ul><li><code>그래서 Feature Map을 한번 뽑을 때마다 Pooling을 해주면서 처음에는 좁은 영역을 점점 더 넓은 영역을 본다. 점점 더 넓은 영역을 본다는 의미는 Pooling을 함으로써 결국에는 더 넓은 범위를 대표하는 값들을 가진 2-D Matrix인 Feature Map이 될 것이기 때문이다.</code></li></ul><p><img src="/image/LeNet_5.png" alt="LeNet-5"></p><ul><li>98년도의 르쿤 교수님의 LeNet-5는 pooling 대신 subsampling을 사용하여 같은 Feature Map의 크기를 줄여주었다.</li></ul><p><img src="/image/VGG_16.png" alt="VGG-16"></p><h2 id="합성곱-신경망의-심화-이해"><a href="#합성곱-신경망의-심화-이해" class="headerlink" title="합성곱 신경망의 심화 이해"></a>합성곱 신경망의 심화 이해</h2><p><img src="/image/importance_of_conv.png" alt="합성곱 게층의 필요성"></p><ul><li>간단히 생각하면 $kernel_{height} \times kernel_{width} \times Channel_{in} \times Channel_{out}$ 만큼 어마어마하게 많은 Parameter가 필요하므로 계산해야 할 Parameter가 상대적으로 적은 FC Layer로 하는 것이 더 좋은 방법이지 않을까라고 생각하시는 분들이 있을 것이다. 허나, 그것은 잘못된 생각이다. <code>Convolutional Layer를 사용하기 때문에 우리가 Image를 처리할 수 있는 것이다. FC Layer를 사용하게 되면 오히려 계산해야 할 Parameter의 개수가 어마어마하게 늘어난다.</code>$(Height_{in} \times Width_{in} \times Channel_{in}) \times (Height_{out} \times Width_{out} \times C_{out})$ 얼핏 보기엔 비슷해보이겠지만, 예를 들어보자. 입력으로 RGB channel을 갖는 1024 * 1024 image를 받는다면, FC Layer를 사용한다면, $(1024 \times 1024 \times 16) \times (1024 \times 1024 \times 32)$이지만 Convolutional Layer를 사용하고 $3 \times 3$ kernel을 사용한다면 $(3 \times 3 \times 16 \times 32)$로 훨씬 적은 연산을 한다. 이러한 이유로 우리가 영상을 입력으로 하는 것은 절대로 FC Layer를 통해 해결할 수 없다.</li></ul><p><img src="/image/mathmatical_expression_of_FC_Layer_00.png" alt="전결합 계층의 수학적 표현"></p><p><img src="/image/mathmatical_expression_of_Conv_Layer_00.png" alt="합성곱 계층의 수학적 표현"></p><ul><li>위에서 W는 kernel들을 $C_{in} \times C_{out}$ Matrix로 이루어진 tensor이다. 즉, $W_{i,j}$들이 각각의 kernel을 나타내고 $X_{i}$와 convolution operation을 해주므로 편향은 FC Layer와 동일하게 channel 1개마다 1개씩 존재한다.</li></ul><p><img src="/image/importance_of_Padding.png" alt="Padding의 필요성"></p><p><img src="/image/Padding.png" alt="Padding"></p><ul><li>위의 그림의 예를 보면 kernel size가 $3 = 2N+1$이므로 입력에 상하좌우 1개의 Zero-Padding을 해준 것이다.</li></ul><p><img src="/image/Stride.png" alt="Stride"></p><ul><li>Stride를 하는 것은 결과를 미리 Convolution을 Full로 다 연산을 한 다음에 하나씩 Subsample하는 것과 동일한 결과를 가져온다. 그러므로 다 연산한 후에 subsampling을 하면 연산은 다하지만 결국엔 버리는 값이 생기기 때문에 Stride를 사용한다.</li></ul><p><img src="/image/conv_layer_feature.png" alt="합성곱 계층의 특징"></p><ul><li>학습 초반에는 위쪽의 Feature Map들 처럼 좁은 범위의 Feature들을 추출하지만, 학습의 후반 부에는 넓은 범위의 Feature들을 학습한다.</li></ul><h2 id="Batch-Normalization-배치-정규화"><a href="#Batch-Normalization-배치-정규화" class="headerlink" title="Batch Normalization(배치 정규화)"></a>Batch Normalization(배치 정규화)</h2><p><img src="/image/vanilla_gradient_descent.png" alt="일반 경사 하강법(vanilla Gradient Descent)"></p><ul><li><code>일반 경사 하강법의 경우, Gradient를 한번 업데이트 하기 위해 모든 학습 데이터를 사용한다.</code> 하지만 데이터가 엄청나게 많다면?? 그렇다면 Gradient를 업데이트하는데 오랜시간이 소요될 것이다. 그렇다면 SGD는??!! Stochastic은???</li></ul><p><img src="/image/stochastic_gradient_descent.png" alt="확률적 경사 하강법(Stochastic Gradient Descent)"></p><p><img src="/image/minibatch_learning.png" alt="미니 배치 학습법"></p><ul><li>Epoch마다 데이터 순서를 섞어주기도 하는 이유는 random성을 더 강하게 해주기 위해서이다.</li></ul><p><img src="/image/internal_Covariate_Shift.png" alt="internal Covariate Shift"></p><ul><li><code>이런 현상을 해결하기 위한 것이 batch normalization이다.</code></li></ul><p><img src="/image/Batch_normalization.png" alt="배치 정규화(Batch Normalization)"></p><p><img src="/image/Training_Phase.png" alt="학습단계(Training Phase)"></p><ul><li><p>또한, 동일한 scale과 동일한 zero-mean을 가지게 되기 때문에 학습률 결정에 유리하다 말의 의미는 <code>학습을 할 때 더 scale이 큰 경우에는 학습이 많이 되고, scale이 작으면 학습이 적게 되는 문제가 발생할 수 있다. 학습률을 너무 크게 할 경우 Gradient가 크게 나오는 곳에 Gradient exploding이 발생할 수가 있고, 반대로 학습률을 너무 작게 할 경우 Gradient Vanishing이 발생되서 학습이 안되는 곳이 발생되는 문제가 있는데 Normalization을 해주게 되면 모든 각각의 계층들이 동일한 scale로 학습되기 때문에 학습률 결정에 유리하다는 것이다.</code><br>(미분을 할때 입력에 대해서 출력값이 커지게 되면, Gradient값도 커질 것이다.)</p></li><li><p>각각의 batch를 normalization하면, 말 그대로 normalization이 된 것이므로 모수가 $\mu=0, \sigma^2=1$인 gaussian distribution을 갖게 될 것이다. 그런데 activation함수는 LeRu를 사용한다면 0미만인 것들은 모조리 0값으로 반환될것이다. 이미 연산을 해놓은 값들을 연산 하기 전이 아닌 연산후에 0으로 만들어 의미 없게 만드는 것 보다 그렇게 0으로 반환되는 개수를 조절하기 위해 추가 스케일링 계수인 $\gamma$와 $\beta$를 만들고, 역전파 알고리즘으로 학습시켜준다.</p></li></ul><p><img src="/image/Inference_Phase.png" alt="추론 단계(Inference Phase)"></p><ul><li>학습과정에서 이동평균을 구해놓는데, 최근 N개에 대한 이동평균을 사용한다. <code>최근 N개만 사용하고 그 전에 것들은 자연스럽게 날라가기 때문에 최근 N개가 충분한 sample이 아닐 경우</code>$\mu$<code>,</code>$\sigma$<code>가 적절하지 않게 결정되는 문제가 있는데 이런 상황을 해결하는 것은 지수평균을 사용한다.</code></li></ul><h2 id="심화-합성곱-신경망"><a href="#심화-합성곱-신경망" class="headerlink" title="심화 합성곱 신경망"></a>심화 합성곱 신경망</h2><p><img src="/image/Conv_NN.png" alt="합성곱 신경망"></p><h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><p><img src="/image/GoogLeNet.png" alt="GoogLeNet(Inception)"></p><ul><li>2014년도에 GoogLeNet과 VGG-19가 나왔는데, GoogLeNet이 에러율이 좀 더 낮고 층이 더 깊은 것을 알 수 있다. GoogLeNet이 좀 더 복잡해서 VGG가 더 많이 알려져 있지만, 다양한 스킬들을 공부하려면 GoogLeNet을 조금 살펴보는 것도 좋을 것이다.</li></ul><p><img src="/image/sturcture_of_GoogLeNet.png" alt="GoogLeNet의 구조"></p><ul><li><code>Let&#39;s Go Deeper and Deeper라는 모토를 가지고 만들어진 것과 같이 좀더 hidden_layer가 깊어진 것을 알 수 있다.</code></li></ul><p><img src="/image/Inception_Module.png" alt="Inception 모듈(naive version)"></p><ul><li>1x1, 3x3, 5x5의 feature들을 다 나누어서 학습한다. <code>즉, 다양한 크기의 Filter들이 잘 학습된다. 또한 3x3 Max pooling 같은 경우는 convolution Layer를 거치지않고도 단순히 max pooling을 통한 후에도 다음 단계에서 의미있는 feature로 작동된다는 것을 보여주었다!!</code></li></ul><p><img src="/image/Inception_Module_01.png" alt="Inception 모듈(dimension reductions)"></p><ul><li>naive 한 Inception 모듈 구조에서 먼저 <code>단순히 1x1 conv를 통과시켜 동일한 channel 영역(Receptive Field)을 가져가면서도 channel을 줄여 연산량을 줄여 주는 구조인 Bottleneck를 구현</code>하고 있다.</li></ul><p><img src="/image/Bottle_neck_sturcture.png" alt="Bottleneck 구조"></p><p><img src="/image/extra_clssifier.png" alt="추가 분류기 사용"></p><ul><li>맨 마지막 출력층에서만 inference를 한다면 Input에 가까운 층일수록 점점 더 Vanishing Gradient문제로 인해 학습이 저하 될 것을 우려하여 중간 feature들로도 classification을 하도록 하였다.</li></ul><h4 id="GoogLeNet-중간-요약"><a href="#GoogLeNet-중간-요약" class="headerlink" title="GoogLeNet 중간 요약"></a>GoogLeNet 중간 요약</h4><ul><li>Inception 구조</li><li>Battleneck 구조</li><li>중간 중간에 inference</li></ul><h3 id="Residual-Network"><a href="#Residual-Network" class="headerlink" title="Residual Network"></a>Residual Network</h3><p><img src="/image/ResNet.png" alt="Residual Network(ResNet)"></p><ul><li>이제는 거의 일반적이고, 기본구조로 많이 사용하는 구조이다.</li></ul><p><img src="/image/structure_of ResNet.png" alt="ResNet의 구조"></p><p><img src="/image/Skip_connection.png" alt="Skip Connection"></p><ul><li>왼쪽 구조에서 표현가능한 것은 오른쪽 구조인 Residual 구조에서도 표현 가능함이 증명 되어 있다. 직관적으로 봤을때는 Feature를 뽑아서 이전 Feature와 더한 다는 것이 잘 이해가 안갈 수 도 있겠지만, 이런식으로 했을때도 좌측의 일반적인 Conv Layer의 구조와 수학적으로 동치를 이룬다는 것을 알고 있자.</li></ul><p><img src="/image/Identity_Mapping.png" alt="Identity Mapping"></p><p><img src="/image/Pre_activation_00.png" alt="Pre-Activation_00"></p><ul><li>맨 왼쪽이 Original ResidualNN의 구조이고 가운데가 Pre-Activation을 사용하는 구조이다.  </li></ul><p><img src="/image/Pre_activation_01.png" alt="Pre-Activation_01"></p><h2 id="Densely-Connected-ConvNets-DenseNet"><a href="#Densely-Connected-ConvNets-DenseNet" class="headerlink" title="Densely Connected ConvNets(DenseNet)"></a>Densely Connected ConvNets(DenseNet)</h2><p><img src="/image/DenseNet.png" alt="Densely Connected ConvNets"></p><ul><li>간단히 말하자면, 모든 Layer들이 다 연결되어 있는 구조라고 할 수 있다.</li></ul><p><img src="/image/structure_of_DenseNet.png" alt="DenseNet 구조"></p><ul><li><p>처음에 일반적인 Conv Layer를 통해 Feature Map을 만들고 그런 뒤에 Dense Block을 이용해서 다른 모든 Conv Layer들과 Dense하게 연결시켜준다. 그 다음 Conv Layer를 이용해서 channel 개수를 조정해주고, Max Pooling을 이용해서 영상크기를 줄여준다. 이런 과정을 여러번 반복해서 Feature를 추출한 후, 맨 마지막은 FC Layer로 구성해주었다.</p></li><li><p><code>위의 구조에서 Dense Block들이 residual block으로 바뀐다면 ResNet인 것이다. Pre-Activation구조를 사용한다는 것이 ResNet을 계승하고 있는다는 것을 알 수 있는 명확한 내용이다.</code></p></li></ul><p><img src="/image/Dense_Block.png" alt="Dense Block"></p><p><img src="/image/Bottle_neck_structure.png" alt="Bottleneck 구조"></p><p><img src="/image/practice_of_DenseNet.png" alt="DensNet의 구현"></p>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/12/10/deep_learning_04/#disqus_thread</comments>
    </item>
    
    <item>
      <title>data engineering basic(SQL Basic)</title>
      <link>https://heung-bae-lee.github.io/2019/12/10/data_engineering_02/</link>
      <guid>https://heung-bae-lee.github.io/2019/12/10/data_engineering_02/</guid>
      <pubDate>Tue, 10 Dec 2019 02:23:24 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;SQL-Structured-Query-Language&quot;&gt;&lt;a href=&quot;#SQL-Structured-Query-Language&quot; class=&quot;headerlink&quot; title=&quot;SQL(Structured Query Language)&quot;&gt;&lt;/
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h1 id="SQL-Structured-Query-Language"><a href="#SQL-Structured-Query-Language" class="headerlink" title="SQL(Structured Query Language)"></a>SQL(Structured Query Language)</h1><h3 id="DB-Database"><a href="#DB-Database" class="headerlink" title="DB (Database)"></a>DB (Database)</h3><ul><li>데이터를 통합하여 관리하는 데이터의 집합</li></ul><h3 id="DBMS-Database-Management-system"><a href="#DBMS-Database-Management-system" class="headerlink" title="DBMS (Database Management system)"></a>DBMS (Database Management system)</h3><ul><li>DB를 관리하는 미들웨어 시스템을 의미</li></ul><h3 id="Database-분류"><a href="#Database-분류" class="headerlink" title="Database 분류"></a>Database 분류</h3><div class="table-container"><table><thead><tr><th style="text-align:center">RDBMS(Relational Database Management System)</th><th style="text-align:center">NoSQL</th></tr></thead><tbody><tr><td style="text-align:center">- 데이터 테이블 사이에 키값으로 관계를 가지고 있는 데이터베이스        ex) Oracle, Mysql, Postgresql, Sqlite -데이터 사이의관계 설정으로 최적화된 스키마를 설계 가능</td><td style="text-align:center">- 데이터 테이블 사이에 관계가 없이 저장하는 데이터베이스  - 데이터 사이의 관계가 없으므로 복잡성이 줄고 많은 데이터를 저장 가능</td></tr></tbody></table></div><h3 id="RDBMS"><a href="#RDBMS" class="headerlink" title="RDBMS"></a>RDBMS</h3><p><img src="/image/RDBMS.png" alt="RDBMS"></p><ul><li><p>table</p><ul><li>행(row)과 열(column)로 이루어져 있는 데이터 베이스를 이루는 기본 단위</li><li>Storage Engine<ul><li>MyISAM : full text index 지원, table 단위 lock, select가 빠름, 구조 단순</li><li>InnoDB : transaction 지원, row 단위 lock, 자원을 많이 사용, 구조 복잡</li></ul></li></ul></li><li><p>Column</p><ul><li>테이블의 세로축 데이터</li><li>Field, Attribute 라고도 불림</li></ul></li><li><p>Row</p><ul><li>테이블의 가로축 데이터</li><li>Tuple, Recode 라고도 불림</li></ul></li><li><p>Value</p><ul><li>행(row)과 열(column)에 포함되어있는 데이터</li></ul></li><li><p>Key</p><ul><li>행(row)의 식별자로 사용</li></ul></li><li><p>Relationship<br><img src="/image/relationship.png" alt="relationship"></p></li><li><p>Schema</p><ul><li>스키마(schema)는 데이터 베이스의 구조를 만드는 디자인<br><img src="/image/schema.png" alt="Schema"></li></ul></li></ul><h3 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h3><ul><li>NoSQL(Not Only SQL)<ul><li>RDBMS의 의존적인 관계가 갖는 한계를 극복하기 위해 만들어진 데이터베이스</li><li>확장성이 좋음<ul><li>데이터 분산처리 용이</li></ul></li><li>데이터 저장이 유연함<ul><li>RDMBS와 다르게 구조의 변경이 불필요</li></ul></li><li>Schema 및 Join이 없음<ul><li>Join 기능이 없으므로 각각의 테이블만 사용가능</li><li>collection 별로 관계가 없기 때문에 모든 데이터가 들어있어야 하므로 RDBMS보다 저장공간이 더 필요</li><li>저장되는 데이터는 Key-value 형태의 JSON 포멧을 사용</li></ul></li><li>select는 RDBMS보다 느리지만 insert가 빨라 대용량 데이터 베이스에 많이 사용</li><li>트랜젝션(transaction)이 지원되지 않음(<code>동시수정에 대한 신뢰성이 지원되지 않음</code>)</li></ul></li></ul><p><img src="/image/NoSQL.png" alt="NoSQL"></p><p><img src="/image/DB_ranking.png" alt="DB 순위"><br><a href="https://db-engines.com/en/ranking_trend" target="_blank" rel="noopener">https://db-engines.com/en/ranking_trend</a></p><h2 id="Install-MySQL-for-Mac-OS"><a href="#Install-MySQL-for-Mac-OS" class="headerlink" title="Install MySQL(for Mac OS)"></a>Install MySQL(for Mac OS)</h2><ul><li>주의) 2가지 방법을 소개하지만, <code>Python에서 MySQL을 활용할 User들에게는 1번 방법으로 설치를 해야한다는 것을 알려드립니다!!!</code></li><li><code>brew(1번방법)로 설치해야 python의 mysql client를 사용할수 있습니다.</code></li></ul><h3 id="방법-1"><a href="#방법-1" class="headerlink" title="방법 1)"></a>방법 1)</h3><ul><li>reference<ul><li><a href="https://gist.github.com/operatino/392614486ce4421063b9dece4dfe6c21" target="_blank" rel="noopener">https://gist.github.com/operatino/392614486ce4421063b9dece4dfe6c21</a></li></ul></li></ul><h4 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ brew install mysql@version_num</span><br><span class="line">$ brew tap homebrew/services $ brew services start mysql@version_num</span><br><span class="line">$ brew services list</span><br><span class="line">$ brew link mysql@version_num --force</span><br><span class="line">$ mysql -V</span><br></pre></td></tr></table></figure><h4 id="앞으로-SQL-접속시-사용할-Password"><a href="#앞으로-SQL-접속시-사용할-Password" class="headerlink" title="앞으로 SQL 접속시 사용할 Password!!"></a>앞으로 SQL 접속시 사용할 Password!!</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mysqladmin -u root password <span class="string">'yourpassword'</span></span><br></pre></td></tr></table></figure><h4 id="Connect-mysql-server"><a href="#Connect-mysql-server" class="headerlink" title="Connect mysql server"></a>Connect mysql server</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -u root -p</span><br></pre></td></tr></table></figure><h3 id="방법-2-dmg-파일-받아서-install"><a href="#방법-2-dmg-파일-받아서-install" class="headerlink" title="방법 2) dmg 파일 받아서 install"></a>방법 2) dmg 파일 받아서 install</h3><ul><li><p>step 1) <a href="https://dev.mysql.com/downloads/mysql/5.7.html#downloads" target="_blank" rel="noopener">https://dev.mysql.com/downloads/mysql/5.7.html#downloads</a>에서 <code>DMG 파일 다운로드</code></p></li><li><p>step 2) 다운 받은 DMG 파일을 실행</p><ul><li><code>설치 중간에 임시 패스워드를 기억</code></li></ul></li></ul><p><img src="/image/MySQL_installer.png" alt="MySQL installer"></p><ul><li>step 3) 시스템 환경설정에 가면 MySQL이 설치 된것을 확인</li></ul><h3 id="MySQL-서버의-인스턴스를-정지-및-실행-초기화-제거등을-할수-있다"><a href="#MySQL-서버의-인스턴스를-정지-및-실행-초기화-제거등을-할수-있다" class="headerlink" title="MySQL 서버의 인스턴스를 정지 및 실행, 초기화, 제거등을 할수 있다."></a>MySQL 서버의 인스턴스를 정지 및 실행, 초기화, 제거등을 할수 있다.</h3><ul><li>Start MySQL Server 버튼을 클릭하여 실행</li></ul><h4 id="아래의-경로로-이동"><a href="#아래의-경로로-이동" class="headerlink" title="아래의 경로로 이동"></a>아래의 경로로 이동</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cd /usr/local/mysql/bin</span><br></pre></td></tr></table></figure><h4 id="Mysql-서버에-접속"><a href="#Mysql-서버에-접속" class="headerlink" title="Mysql 서버에 접속"></a>Mysql 서버에 접속</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ./mysql -p</span><br></pre></td></tr></table></figure><h4 id="Password-관리자-권한으로-실행을-위한-PC의-패스워드"><a href="#Password-관리자-권한으로-실행을-위한-PC의-패스워드" class="headerlink" title="Password: (관리자 권한으로 실행을 위한 PC의 패스워드)"></a>Password: (관리자 권한으로 실행을 위한 PC의 패스워드)</h4><h4 id="Enter-password-임시로-발급받은-DB의-패스워드-입력"><a href="#Enter-password-임시로-발급받은-DB의-패스워드-입력" class="headerlink" title="Enter password: (임시로 발급받은 DB의 패스워드 입력)"></a>Enter password: (임시로 발급받은 DB의 패스워드 입력)</h4><ul><li>아래의 mysql 프롬프트가 나오면 정상!! 설치 완료!!<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure></li></ul><h4 id="패스워드-변경-qwer1234-로-변경할-경우"><a href="#패스워드-변경-qwer1234-로-변경할-경우" class="headerlink" title="패스워드 변경 ( qwer1234 로 변경할 경우 )"></a>패스워드 변경 ( qwer1234 로 변경할 경우 )</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;qwer1234&apos;;</span><br><span class="line">mysql&gt; FLUSH PRIVILEGES; mysql&gt; quit;</span><br></pre></td></tr></table></figure><h4 id="변경한-패스워드로-다시-로그인"><a href="#변경한-패스워드로-다시-로그인" class="headerlink" title="변경한 패스워드로 다시 로그인"></a>변경한 패스워드로 다시 로그인</h4><h2 id="Mysql-Basic-Command"><a href="#Mysql-Basic-Command" class="headerlink" title="Mysql Basic Command"></a>Mysql Basic Command</h2><h3 id="system"><a href="#system" class="headerlink" title="system"></a>system</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mysql명령어 리스트 확인</span></span><br><span class="line">mysql&gt; <span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 현재 상태 보기</span></span><br><span class="line">mysql&gt; status</span><br><span class="line"></span><br><span class="line"><span class="comment"># mysql 접속 종료</span></span><br><span class="line">mysql&gt; <span class="built_in">exit</span></span><br><span class="line">mysql&gt; quit</span><br><span class="line"></span><br><span class="line"><span class="comment"># 패스워드 변경 ( qwer1234 로 변경하는 경우 )</span></span><br><span class="line">mysql&gt; ALTER USER <span class="string">'root'</span>@<span class="string">'localhost'</span> IDENTIFIED BY <span class="string">'qwer1234'</span></span><br><span class="line">2.2 Database</span><br></pre></td></tr></table></figure><h3 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DB 목록 보기</span></span><br><span class="line">mysql&gt; show databases;</span><br><span class="line"></span><br><span class="line"><span class="comment"># DB 만들기 ( DB이름을 test라고 하려면 )</span></span><br><span class="line">mysql&gt; create database <span class="built_in">test</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># DB 접속하기 ( DB 이름 test )</span></span><br><span class="line">mysql&gt; use <span class="built_in">test</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 현재 접속중인 DB 확인하기</span></span><br><span class="line">mysql&gt; select database();</span><br><span class="line"></span><br><span class="line"><span class="comment"># DB 지우기</span></span><br><span class="line">mysql&gt; drop database <span class="built_in">test</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># DB 삭제 확인</span></span><br><span class="line">mysql&gt; show databases;</span><br></pre></td></tr></table></figure><h3 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 테이블 만들기</span></span><br><span class="line"><span class="comment"># 문자열 name 20자, age 숫자 3자 컬럼이 있는 테이블이 생성</span></span><br><span class="line">mysql&gt; create table user ( name char(20), age int(3) );</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테이블 목록 확인</span></span><br><span class="line">mysql&gt; show tables;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테이블 구조 확인</span></span><br><span class="line">mysql&gt; desc user;</span><br><span class="line">mysql&gt; describe user;</span><br><span class="line">mysql&gt; explain user;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테이블 이름 바꾸기(another로 바꾸기)</span></span><br><span class="line">mysql&gt; rename table user to another;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 테이블 이름 바뀐것 확인 mysql&gt; show tables;</span></span><br><span class="line"><span class="comment"># 테이블에 데이터 추가하기</span></span><br><span class="line">mysql&gt; insert into another(name, age) values(<span class="string">"alice"</span>, 23);</span><br><span class="line">mysql&gt; insert into another(name, age) values(<span class="string">"peter"</span>, 30);</span><br><span class="line"></span><br><span class="line"><span class="comment"># 추가된 데이터 확인하기</span></span><br><span class="line">mysql&gt; select * from anther;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테이블 지우기</span></span><br><span class="line">mysql&gt; drop table anther;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테이블 삭제된것 확인</span></span><br><span class="line">mysql&gt; show tables;</span><br></pre></td></tr></table></figure><h2 id="Database-Management-Application-for-Mac-OS"><a href="#Database-Management-Application-for-Mac-OS" class="headerlink" title="Database Management Application for Mac OS"></a>Database Management Application for Mac OS</h2><h4 id="step-1-Install-Sequel-Pro"><a href="#step-1-Install-Sequel-Pro" class="headerlink" title="step 1) Install Sequel Pro"></a>step 1) Install Sequel Pro</h4><ul><li><a href="https://www.sequelpro.com/" target="_blank" rel="noopener">https://www.sequelpro.com/</a> 경로에서 sequelpro를 다운 받아서 설치</li></ul><h3 id="step-2-Connect-Database-Server"><a href="#step-2-Connect-Database-Server" class="headerlink" title="step 2) Connect Database Server"></a>step 2) Connect Database Server</h3><ul><li>아래와 같이 Host, Username, Password를 설정하여 연결<br><img src="/image/Connection_DB_Server.png" alt="Connection_DB_Server"></li></ul><h2 id="Sample-Database-Download"><a href="#Sample-Database-Download" class="headerlink" title="Sample Database Download"></a>Sample Database Download</h2><ul><li><a href="https://dev.mysql.com/doc/index-other.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/index-other.html</a>링크에서 Sample database 를 다운<ul><li>혹시라도 앞으로 저의 블로그를 보시면서 따라해보실 분들은 world database, sakila database 를 다운받아 주세요.</li></ul></li></ul><p><img src="/image/example_db.png" alt="example_db"></p><ul><li>sql 파일 추가<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/mysql/bin 디렉토리에서 아래와 같이 실행하면 sql 파일을 import - import 하기 전에 world 데이터 베이스가 있어야 함</span><br><span class="line">$ sudo ./mysql -p world &lt; (sql 파일 경로)</span><br><span class="line">- brew로 설치한 경우 아래와 같이 추가</span><br><span class="line">$ mysql -u root -p world &lt; (sql 파일 경로)</span><br></pre></td></tr></table></figure></li></ul>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/12/10/data_engineering_02/#disqus_thread</comments>
    </item>
    
    <item>
      <title>data engineering basic(Unix환경 및 커맨드)</title>
      <link>https://heung-bae-lee.github.io/2019/12/09/data_engineering_01/</link>
      <guid>https://heung-bae-lee.github.io/2019/12/09/data_engineering_01/</guid>
      <pubDate>Mon, 09 Dec 2019 08:48:07 GMT</pubDate>
      <description>
      
        
        
          &lt;h3 id=&quot;Pipes-and-Filters&quot;&gt;&lt;a href=&quot;#Pipes-and-Filters&quot; class=&quot;headerlink&quot; title=&quot;Pipes and Filters&quot;&gt;&lt;/a&gt;Pipes and Filters&lt;/h3&gt;&lt;p&gt;cat : 해당 파
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h3 id="Pipes-and-Filters"><a href="#Pipes-and-Filters" class="headerlink" title="Pipes and Filters"></a>Pipes and Filters</h3><p>cat : 해당 파일 전체를 print<br>head : 해당 파일 앞의 10줄 정도를 print<br>tail : 해당 파일 뒤의 20줄 정도를 print</p><p>command &gt; file : 기존의 파일 내용은 지우고 현재 command한 결과 파일에 저장<br>command &gt;&gt; file : 기존의 파일에 덮붙여서 결과를 저장(python append같은 느낌!)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example.py를 python3로 run하고 그 결과를 result.txt파일로 저장</span></span><br><span class="line">python3 example.py &gt; result.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># example.py를 python3로 run하고 그 결과를 result.txt파일에 덮붙여서 저장</span></span><br><span class="line">python3 example.py &gt;&gt; result.txt</span><br></pre></td></tr></table></figure><h3 id="Shell-script"><a href="#Shell-script" class="headerlink" title="Shell script"></a>Shell script</h3><ul><li><p><code>terminal에서 바로 명령어를 여러개 사용하고 싶을때 shell script를 사용하면 된다.</code></p></li><li><p>예를들어 아래의 example.py를 실행시켜 위에서 command를 한번에 실행시키고 싶다면 다음과 같이 먼저 example.py를 작성한 후에 command.sh 파일에는 command들을 작성한 후에 shell script 파일을 run하면 된다.</p></li></ul><h4 id="example-py"><a href="#example-py" class="headerlink" title="example.py"></a>example.py</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    <span class="comment"># command 뒤에 따라오는 첫번째 글자를 print</span></span><br><span class="line">    <span class="built_in">print</span>(sys.argv[1])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h4 id="command-sh"><a href="#command-sh" class="headerlink" title="command.sh"></a>command.sh</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">python3 example.py 1 &gt; result.txt</span><br><span class="line">python3 example.py 2 &gt;&gt; result.txt</span><br><span class="line">head result.txt</span><br><span class="line">rm -rf result.txt example.py</span><br></pre></td></tr></table></figure><h4 id="terminal창"><a href="#terminal창" class="headerlink" title="terminal창"></a>terminal창</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#권한을 설정</span></span><br><span class="line">chmod +x command.sh</span><br><span class="line">./command.sh</span><br></pre></td></tr></table></figure><h4 id="보통은-우리가-deploy-sh라는-파일로-만들어-그-안에서-작업을-한다-예를-들어서"><a href="#보통은-우리가-deploy-sh라는-파일로-만들어-그-안에서-작업을-한다-예를-들어서" class="headerlink" title="보통은 우리가 deploy.sh라는 파일로 만들어 그 안에서 작업을 한다. 예를 들어서,"></a>보통은 우리가 deploy.sh라는 파일로 만들어 그 안에서 작업을 한다. 예를 들어서,</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># zip형식으로 되어있는 모든(*)파일을 삭제해라</span></span><br><span class="line">rm *.zip</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모든 파일을 lisztfever라는 이름으로 압축해라. -r 옵션은 파일이 있을 수 있으므로 붙여준다.</span></span><br><span class="line">zip lisztfever.zip -r *</span><br><span class="line"></span><br><span class="line"><span class="comment"># aws s3라는 storage에 s3://areha/lisztfever/lisztfever.zip 에 해당 path의 파일을 삭제</span></span><br><span class="line">aws s3 rm s3://areha/lisztfever/lisztfever.zip</span><br><span class="line"></span><br><span class="line"><span class="comment"># s3에게 다시 copy해라</span></span><br><span class="line">aws s3 cp ./listzfever.zip s3://areha/lisztfever/listzfever.zip</span><br><span class="line"></span><br><span class="line"><span class="comment"># aws lambda function을 update해라.</span></span><br><span class="line">aws lambda update-function-code --<span class="keyword">function</span>-name listzfever --s3-buket areha --s3-key listzfever/listzfever.zip</span><br></pre></td></tr></table></figure><h2 id="AWS-Cloud-Service"><a href="#AWS-Cloud-Service" class="headerlink" title="AWS Cloud Service"></a>AWS Cloud Service</h2><p>먼저, <code>IAM</code>(Identity and Access Management)에 대해서 설명하겠다. <code>내가 누구이고 어떤 Access를 가지고 있는지를 관리하는 곳이라고 생각할 수 있다.</code> 여기서 새로운 User를 등록 할 수 있다.</p><p><img src="/image/IAM_00.png" alt="그림00"></p><ul><li>위의 Add User를 통해서 새로운 User를 등록해보자.</li></ul><p><img src="/image/IAM_01.png" alt="그림01"></p><ul><li>Access type은 우리가 AWS cli를 통해서도 관리하므로 첫번째인 Programmatic access로 설정한다.</li></ul><p><img src="/image/IAM_02.png" alt="그림02"></p><ul><li><p>Permission을 주는 방식에 대한 설정하는 부분이다.</p><ul><li><p>Add user to group : 한 Project를 여러명이 같이 진행하여 여러명이 관리할 경우 사용.</p></li><li><p>Copy permissions from existing user : 말 그대로 이미 존재하는 user의 permission들 중 하나를 선택하여 Copy할 경우 사용</p></li><li><p>Attach existing policies directly : AWS에 존재하는 정책들 중 하나를 선택하여 바로 사용하는 경우 사용</p></li></ul></li><li><p>예전에 있던 계정이 만료된걸 모르고 있다가 결제를 안해버려서…. ㅠㅠㅠ 새롭게 만든 계정으로 하느라 등록된 User들이 없다. 그러므로 3번째 설정으로 들어가서 모든 최상위 permission을 갖는 AdministratorAccess를 주었다.</p></li><li><p>다음으로 넘어가게 되면, tag를 설정하게 되는데, 우선 넘어가겠다.(이 부분은 나중에 설정할 것이다.)</p></li></ul><p><img src="/image/IAM_03.png" alt="그림03"></p><ul><li>앞에서 설정한 사항들을 확인하고, Create User를 누르게 되면 설정한대로 User를 생성하게 되는 것이다.</li></ul><p><img src="/image/IAM_03.png" alt="그림04"></p><ul><li>Access key ID, Secret access key가 생성되어 나오는데, <code>이 창이 닫히면, 볼수 없으므로 Download csv를 하는 것을 권장한다.</code></li></ul><ul><li>설치 프로그램을 실행한다. /usr/local/aws에 AWS CLI를 설치하고 /usr/local/bin 디렉터리에 symlink aws를 생성한다. <code>-b 옵션을 사용하여 symlink를 생성하면 사용자의 $PATH 변수에 설치 디렉터리를 지정할 필요가 없다. 이렇게 하면 모든 사용자가 임의 디렉터리에서 aws를 입력하여 AWS CLI를 호출 가능하게 한다.</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl <span class="string">"https://s3.amazonaws.com/aws-cli/awscli-bundle.zip"</span> -o <span class="string">"awscli-bundle.zip"</span></span><br><span class="line">unzip awscli-bundle.zip</span><br><span class="line">sudo ./awscli-bundle/install -i /usr/<span class="built_in">local</span>/aws -b /usr/<span class="built_in">local</span>/bin/aws</span><br></pre></td></tr></table></figure><ul><li>위의 설치가 다 끝나면, 이제 aws cli의 configure를 설정해 볼 것이다. 이를 통해 우리가 console에 접속하지 않고도 cli 환경에서도 aws를 조작할 수 있게 된다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">aws configure</span><br><span class="line">AWS Access Key ID [None]: Access key ID</span><br><span class="line">AWS Secret Access Key [None]: Secret access key</span><br><span class="line">Default region name [None]: ap-northeast-2</span><br><span class="line">Default output format [None]:</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/12/09/data_engineering_01/#disqus_thread</comments>
    </item>
    
    <item>
      <title>쉽게 배우는 경사하강 학습법</title>
      <link>https://heung-bae-lee.github.io/2019/12/08/deep_learning02/</link>
      <guid>https://heung-bae-lee.github.io/2019/12/08/deep_learning02/</guid>
      <pubDate>Sat, 07 Dec 2019 15:00:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;쉽게-배우는-경사하강-학습법&quot;&gt;&lt;a href=&quot;#쉽게-배우는-경사하강-학습법&quot; class=&quot;headerlink&quot; title=&quot;쉽게 배우는 경사하강 학습법&quot;&gt;&lt;/a&gt;쉽게 배우는 경사하강 학습법&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/image/s
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h2 id="쉽게-배우는-경사하강-학습법"><a href="#쉽게-배우는-경사하강-학습법" class="headerlink" title="쉽게 배우는 경사하강 학습법"></a>쉽게 배우는 경사하강 학습법</h2><p><img src="/image/supervised_learning_vs_unsupervised_learning.png" alt="지도 학습 vs 비지도 학습"></p><p><img src="/image/supervised_learning_of_human.png" alt="사람의 지도학습"></p><p><img src="/image/supervised_learning_of_machine.png" alt="머신러닝의 지도학습"></p><p><img src="/image/hyper_parameters.png" alt="학습 매개변수"></p><p><img src="/image/Loss_function.png" alt="손실 함수"></p><ul><li><code>어떤 손실 함수를 사용하느냐에 따라서 학습이 어떻게 이루어질 것인지, 그리고 학습을 할 때 정답의 형태를 결정하기 때문에 손실 함수는 중요하다!</code></li></ul><p><img src="/image/another_aspect_about_algorithm_learning.png" alt="알고리즘 학습을 달리 말하면"></p><ul><li>Traning Data를 Model에 입력해 우리가 학습시키고자 하는 Trainable Parameters를 얻게 되는데 <code>Trainable Parameters</code>들을 <code>inputs</code>으로 보고 <code>outputs</code>을 학습결과인 <code>Loss Function</code>으로 생각하면, <code>알고리즘 학습은 입력을 바꿔가면서, 출력값이 점점 작아지게 하는 것이라고 볼 수 있다.</code></li></ul><p><img src="/image/optimization_theory_and_algorithm_learning.png" alt="최적화 이론과 알고리즘 학습"></p><ul><li>결국 알고리즘 학습은 입력을 바꿔가면서, 출력값이 점점 작아지게 하는 것이라는 관점에서 <code>최적화 이론의 목표와 동일</code>하다는 사실을 알 수 있다.</li></ul><h2 id="경사-하강-학습법"><a href="#경사-하강-학습법" class="headerlink" title="경사 하강 학습법"></a>경사 하강 학습법</h2><p><img src="/image/Brute_Force.png" alt="무차별 대입법(Brute-Force)"></p><ul><li><code>무차별 대입법</code>은 범위를 알아야하고 범위를 안다해도 step을 촘촘히 조사해야 하므로 <code>계산 복잡도가 높다</code>. <code>적게 대입해 보고 답을 찾을 수 있는 방법을 생각하다 최적화 알고리즘이 발전 하게 되었다.</code></li></ul><p><img src="/image/Graadient_Descent.png" alt="경사하강법(Gradient Descent)"></p><p><img src="/image/Graadient_Descent_01.png" alt="경사하강법(Gradient Descent)"></p><p><img src="/image/selection_of_learning_rate.png" alt="학습률의 선택 00"></p><p><img src="/image/selection_of_learning_rate_01.png" alt="학습률의 선택 01"></p><p><img src="/image/selection_of_learning_rate_02.png" alt="학습률의 선택 02"></p><p><img src="/image/Convex_Function.png" alt="Convex Function"></p><p><img src="/image/Non_Convex_Function.png" alt="Non-convex Function"></p><h2 id="최적화-이론과-수학적-표현"><a href="#최적화-이론과-수학적-표현" class="headerlink" title="최적화 이론과 수학적 표현"></a>최적화 이론과 수학적 표현</h2><p><img src="/image/optimization_theory.png" alt="최적화 이론(Optimization Theory)"></p><p><img src="/image/analysis_and_numerical_method.png" alt="분석적 vs 수치적 방법"></p><ul><li>수치적 방법의 대표적인 방법이 경사하강법이다.</li></ul><p><img src="/image/global_and_local_solution.png" alt="Global vs local solution"></p><p><img src="/image/deep_learning_and_optimization_theory.png" alt="딥러닝과 최적화 이론"></p><h2 id="심화-경사-하강-학습법"><a href="#심화-경사-하강-학습법" class="headerlink" title="심화 경사 하강 학습법"></a>심화 경사 하강 학습법</h2><ul><li>경사하강 학습법의 단점들을 극복한 알고리즘에 대해서 알아보자.</li></ul><p><img src="/image/Non_convex_function_01.png" alt="Non_convex Finction"></p><p><img src="/image/Local_minimum.png" alt="Local Minimum"></p><p><img src="/image/Saddle_point.png" alt="Saddle Point"></p><ul><li>경사하강법은 안장점에서 기울기가 0이 되므로 벗어나지 못하게 되는 문제점이 있다.</li></ul><p><img src="/image/Momentum.png" alt="Momentum"></p><ul><li><p><code>이동 벡터가 이전 기울기에 영향을 받도록 하는 방법 이전의 속도에 영향을 받는 방법이라고 할 수 있다.</code></p></li><li><p>장점 : <code>Local minimum과 noise에 대처 가능</code></p></li><li><p>단점 : <code>경사하강법은 단순히</code>$x_{t-1}$<code>이동벡터(</code>$v_{t}$<code>)를 추가로 사용하므로, 경사 하강법 대비 2배의 메모리를 사용</code></p></li></ul><p><img src="/image/AdaGrad.png" alt="AdaGrad"></p><ul><li><p><code>변수별로 learning rate가 달라지게 조절한다.</code> 예를 들어서 $x=[x_{1}, x_{2}, x_{3},…,x_{n}]$이 존재할때 어떤 변수는 기울기를 크게 가져가고 어떤 변수는 기울기를 작게 가져갈 경우 <code>처음에 기울기를 크게 가져가지 못한다면 local minimum에 빠지기 쉬운 문제점이 있다.</code> 이런 문제점을 해결하고자 변수별로 learning rate를 다르게 가져가는 알고리즘인 Ada Grad 탄생된 것이다.</p></li><li><p>장점 : $g_{t}$가 누적되어 커진 것은 학습이 그만큼 많이 된 것이므로 <code>학습이 많이 변수는 학습율을 감소시켜, 다른 변수들이 잘 학습되도록 한다.</code></p></li><li><p>단점 : $g_{t}$ <code>가 계속해서 커져서 학습이 오래 진행되면 learning rate가 0ㅇ에 가까워지므로 더이상 학습이 이루어지지 않는 단점이 있다.</code></p></li></ul><p><img src="/image/RMSprop.png" alt="RMSProp"></p><ul><li>gradient의 크기를 제곱한 벡터(gradient벡터의 L2-norm)를 누적합을 해서 적게 학습되는 변수들을 더 학습시켜 주도록했지만 <code>epoch나 batchsize등 반복 시키는 parameter의 value가 높아질수록 오래 진행되어 누적합이 커지게 되면 더 이상 학습이 되지 않는 문제점을 개선한 방법</code>이다. 위의 식에서 $\gamma$<code>값은 0~1값을 갖게 되며, 이 값을 통해 이전의 gradient 누적합을 감소시키는 효과를 주면서 새로운 gradient의 값을 쫓아갈 수 있도록 개선하였다. 그러므로, 변수 간의 상대적인 학습율 차이는 유지하면서</code>$g_{t}$<code>가 무한정 커지지 않아 학습을 오래 할 수 있다.</code></li></ul><p><img src="/image/Adam.png" alt="Adam"></p><ul><li><code>RMSprop과 Momentum의 장점을 결합한 알고리즘이다. 대부분의 코드에 이 Adam optimization을 사용한다.</code></li></ul><h2 id="경사-하강법을-이용한-얕은-신경망-학습"><a href="#경사-하강법을-이용한-얕은-신경망-학습" class="headerlink" title="경사 하강법을 이용한 얕은 신경망 학습"></a>경사 하강법을 이용한 얕은 신경망 학습</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 경사 하강법을 이용한 얕은 신경망 학습</span></span><br><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment">## 하이퍼 파라미터 설정</span></span><br><span class="line">epochs = 1000</span><br><span class="line"></span><br><span class="line"><span class="comment">## 네트워크 구조 정의</span></span><br><span class="line"><span class="comment">### 얕은 신경망</span></span><br><span class="line"><span class="comment">#### 입력 계층 : 2, 은닉 계층 : 128 (Sigmoid activation), 출력 계층 : 10 (Softmax activation)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># keras의 모듈을 상속해서 Model을 구현</span></span><br><span class="line">class MyModel(tf.keras.Model):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        <span class="comment"># 상속을 한 경우에는 상속을 한 상위 class를 initialize하는 것을 잊어버리지 말자!</span></span><br><span class="line">        super(MyModel, self).__init__()</span><br><span class="line">        <span class="comment"># 아래의 input_dim을 적어줄 필요는 없다. 실제 데이터가 들어올때 정의 되기 떄문이다.</span></span><br><span class="line">        self.d1 = tf.keras.layers.Dense(128, input_dim=2, activation=<span class="string">"sigmoid"</span>)</span><br><span class="line">        self.d2 = tf.keras.layers.Dense(10, input_dim=128, activation=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Model이 실제 call이 될때 입력에서 출력으로 어떻게 연결이 될 것인지를 정의</span></span><br><span class="line">    def call(self, x, training=None, mask=None):</span><br><span class="line">        x = self.d1(x)</span><br><span class="line">        <span class="built_in">return</span> self.d2(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 학습 루프 정의</span></span><br><span class="line">@tf.function</span><br><span class="line"><span class="comment"># tensorflow의 Auto Graph를 통해 쉽게 구현가능하다.</span></span><br><span class="line"><span class="comment"># function 내의 python 문법으로 입력된 모든 tensor 연산들을 tf.function에 의해서</span></span><br><span class="line"><span class="comment"># 최적화된다.</span></span><br><span class="line">def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_metric):</span><br><span class="line">    <span class="comment"># Gradient를 계산하기위한</span></span><br><span class="line">    with tf.GradientTape() as tape:</span><br><span class="line">        predictions = model(inputs)</span><br><span class="line">        loss = loss_object(labels, predictions)</span><br><span class="line">    <span class="comment"># loss를 model의 trainable_variables(W,b)로 각각 미분해서 gradient를 구한것.</span></span><br><span class="line">    <span class="comment"># loss는 scalar이고, model.trainable_variables는 벡터이므로 결과 또한 벡터가 될 것이다.</span></span><br><span class="line">    gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 각 gradient와 trainable_variables들이 optimizer로 학습</span></span><br><span class="line">    optimizer.apply_gradients(zip(gradients, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loss를 종합</span></span><br><span class="line">    train_loss(loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># matric</span></span><br><span class="line">    train_metric(labels, predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 데이터셋 생성, 전처리</span></span><br><span class="line">np.random.seed(0)</span><br><span class="line"></span><br><span class="line">pts = []</span><br><span class="line">labels = []</span><br><span class="line"></span><br><span class="line">center_pts =  np.random.uniform(-8.0, 8.0, size=(10, 2))</span><br><span class="line"><span class="keyword">for</span> label, center_pt <span class="keyword">in</span> enumerate(center_pts):</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(100):</span><br><span class="line">        pts.append(center_pt + np.random.randn(*center_pt.shape))</span><br><span class="line">        labels.append(label)</span><br><span class="line"></span><br><span class="line"><span class="comment"># GPU를 사용하게 된다면 위의 MyModel class에서 initialize 할때</span></span><br><span class="line"><span class="comment"># Layer에 따로 dtype을 지정하지 않으면 float32로 설정되므로 동일하게 해주기 위해 type 재설정</span></span><br><span class="line">pts =  np.stack(pts, axis=0).astype(np.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이미 integer이므로 바꿀 필요가 없음.</span></span><br><span class="line">labels =  np.stack(labels, axis=0)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 위에서 만든 데이터를 train data set으로 변형</span></span><br><span class="line"><span class="comment"># train_ds는 iterable한 object가 된다.</span></span><br><span class="line"><span class="comment"># 1000개를 섞어 batch_size를 32개로 해서 구성해준다.</span></span><br><span class="line">train_ds =  tf.data.Dataset.from_tensor_slices((pts, labels)).shuffle(1000).batch(32)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pts.shape)</span><br><span class="line"><span class="built_in">print</span>(labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 모델 생성</span></span><br><span class="line">model = MyModel()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 손실 함수 및 최적화 알고리즘 설정</span></span><br><span class="line"><span class="comment">### CrossEntropy, Adam Optimizer</span></span><br><span class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class="line">optimizer = tf.keras.optimizers.Adam()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 평가 지표 설정</span></span><br><span class="line"><span class="comment">### Accuracy</span></span><br><span class="line">train_loss = tf.keras.metrics.Mean(name=<span class="string">'train_loss'</span>)</span><br><span class="line">train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">'train_accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 학습 루프</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line"></span><br><span class="line">    <span class="comment">#위에서 batch_size를 32로 했으므로 한번 실행시 32개씩 나옴.</span></span><br><span class="line">    <span class="keyword">for</span> x, label <span class="keyword">in</span> train_ds:</span><br><span class="line">        train_step(model, x, label, loss_object, optimizer, train_loss, train_accuracy)</span><br><span class="line"></span><br><span class="line">    template = <span class="string">'Epoch &#123;&#125;, Loss: &#123;&#125;, Accuracy: &#123;&#125;'</span></span><br><span class="line">    <span class="built_in">print</span>(template.format(epoch+1, train_loss.result(), train_accuracy.result()*100))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 데이터셋 및 학습 파라미터 저장</span></span><br><span class="line"><span class="comment"># 압축해서 여러개의 Numpy Object들을 저장할 수 있다.</span></span><br><span class="line">np.savez_compressed(<span class="string">'ch2_dataset.npz'</span>, inputs=pts, labels=labels)</span><br><span class="line"></span><br><span class="line">W_h, b_h = model.d1.get_weights()</span><br><span class="line">W_o, b_o = model.d2.get_weights()</span><br><span class="line"></span><br><span class="line"><span class="comment"># weight는 tensorflow에서 사용하고 있는 convention이랑</span></span><br><span class="line"><span class="comment"># shallowNN을 구현할 때 사용했던 convention이 좀 다르다.</span></span><br><span class="line">W_h = np.transpose(W_h)</span><br><span class="line">W_o = np.transpose(W_o)</span><br><span class="line"></span><br><span class="line">np.savez_compressed(<span class="string">'ch2_parameters.npz'</span>, W_h=W_h, b_h=b_h, W_o=W_o, b_o=b_o)</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/12/08/deep_learning02/#disqus_thread</comments>
    </item>
    
    <item>
      <title>심층 신경망의 구조</title>
      <link>https://heung-bae-lee.github.io/2019/12/08/deep_learning03/</link>
      <guid>https://heung-bae-lee.github.io/2019/12/08/deep_learning03/</guid>
      <pubDate>Sat, 07 Dec 2019 15:00:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;심층-신경망의-구조&quot;&gt;&lt;a href=&quot;#심층-신경망의-구조&quot; class=&quot;headerlink&quot; title=&quot;심층 신경망의 구조&quot;&gt;&lt;/a&gt;심층 신경망의 구조&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/image/Neuron_01.png&quot; alt=&quot;N
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h2 id="심층-신경망의-구조"><a href="#심층-신경망의-구조" class="headerlink" title="심층 신경망의 구조"></a>심층 신경망의 구조</h2><p><img src="/image/Neuron_01.png" alt="Neuron"></p><p><img src="/image/shallowNN_01.png" alt="shallow NN"></p><p><img src="/image/Deep_Neural_Network.png" alt="심층 신경망(Deep Neural Network)"></p><p><img src="/image/what_is_difference with_DNN.png" alt="심층신경망은 무엇이 다를까?"></p><ul><li><code>은닉 계층 추가 = 특징의 비선형 변환 추가!!</code></li></ul><h2 id="역전파-학습법의-개념"><a href="#역전파-학습법의-개념" class="headerlink" title="역전파 학습법의 개념"></a>역전파 학습법의 개념</h2><p><img src="/image/Algorithm_learning_and_differentiation.png" alt="알고리즘의 학습과 미분"></p><p><img src="/image/compute_function_with_dependency.png" alt="의존성이 있는 함수의 계산"></p><ul><li>y를 구하려면 x와 z를 알아야 하는데, x와 z에는 중복된 연산이 있어서 비효율적이다.</li></ul><p><img src="/image/Dynamic_Programming.png" alt="동적 계획법(Dynamic Programming)"></p><ul><li><code>처음 계산할 때 값을 저장해주어서 중복계산이 발생하지 않도록 해준다.</code></li></ul><p><img src="/image/chain_rule.png" alt="Chain rule"></p><p><img src="/image/differentiation_of_DNN.png" alt="심층 신경망의 미분(출력계층)"></p><p><img src="/image/differentiation_of_DNN_01.png" alt="심층 신경망의 미분(은닉계층1)"></p><p><img src="/image/differentiation_of_DNN_02.png" alt="심층 신경망의 미분(은닉계층2)"></p><p><img src="/image/Forward_inference.png" alt="순방향 전파(Forward Propagation)"></p><ul><li>학습을 마친 후 validation set이나 test set에 적용할 때는 더 이상 학습을 하지 않으므로 이 순방향 추론만을 사용한다.</li></ul><p><img src="/image/Back_Propagation.png" alt="역전파 학습법(Back-Propagation)"></p><h2 id="심층-신경망의-수학적-이해"><a href="#심층-신경망의-수학적-이해" class="headerlink" title="심층 신경망의 수학적 이해"></a>심층 신경망의 수학적 이해</h2><p><img src="/image/FC_Layer.png" alt="전결합 계층"></p><p><img src="/image/DNN_00.png" alt="심층 신경망"></p><h2 id="역전파-학습의-필요성"><a href="#역전파-학습의-필요성" class="headerlink" title="역전파 학습의 필요성"></a>역전파 학습의 필요성</h2><p><img src="/image/BlackBoxModel.png" alt="블랙박스 모델"></p><p><img src="/image/learning_BlackBoxModel.png" alt="블랙박스 모델의 학습"></p><p><img src="/image/Numerical_Gradient.png" alt="수치적 기울기(Numerical Gradient"></p><p><img src="/image/Numerical_Gradient_of_BlackBoxmodel.png" alt="블랙박스 모델의 수치적 기울기"></p><ul><li>(N+1번) 손실함수를 평가한다고 하는데 그 이유는 기준점이 되는 손실함수를 먼저 한번 계산하고 나머지 편미분시에 가각 N번 평가하기 때문이다.</li></ul><p><img src="/image/Numerical_Gradient_of_DNN.png" alt="심층 신경망의 수치적 기울기"></p><h2 id="합성함수와-연쇄-법칙"><a href="#합성함수와-연쇄-법칙" class="headerlink" title="합성함수와 연쇄 법칙"></a>합성함수와 연쇄 법칙</h2><p><img src="/image/chain_rule_01.png" alt="연쇄 법칙"></p><p><img src="/image/series_connection_of_two_function.png" alt="직렬 연결된 두 함수의 미분"></p><p><img src="/image/differentiation_and_chain_rule.png" alt="미분과 연쇄 법칙"></p><p><img src="/image/expansion_of_chain_rule.png" alt="연쇄법칙의 확장"></p><h2 id="역전파-학습법의-수식적-이해"><a href="#역전파-학습법의-수식적-이해" class="headerlink" title="역전파 학습법의 수식적 이해"></a>역전파 학습법의 수식적 이해</h2><p><img src="/image/DNN_aspect_of_composite function.png" alt="합성 함수로서의 심층 신경망"></p><p><img src="/image/DNN_aspect_of_learning.png" alt="학습관점에서 본 심층 신경망"></p><p><img src="/image/DNN_chain_rule.png" alt="심층신경망의 연쇄법칙"></p><ul><li><code>미분하고자 하는 경로 사이에 있는 모든 미분값을 알아야 원하는 미분을 구할 수 있다는 의미이다.</code></li></ul><p><img src="/image/FCLayer_differentiation.png" alt="전결합 계층의 미분(1)"></p><p><img src="/image/FCLayer_differentiation_01.png" alt="전결합 계층의 미분(2)"></p><p><img src="/image/differentiation_of_sigmoid_function.png" alt="Sigmoid 함수의 미분"></p><p><img src="/image/Back_Propagation_algorithm.png" alt="역전파 알고리즘"></p><ul><li><code>수치적 미분에서는 N+1번을 계산하여야 했지만, 역전파 알고리즘으로 인해 단 한번의 손실함수 평가로 미분을 구할 수 있다.</code></li></ul><h2 id="수치-미분을-이용한-심층-신경망-학습"><a href="#수치-미분을-이용한-심층-신경망-학습" class="headerlink" title="수치 미분을 이용한 심층 신경망 학습"></a>수치 미분을 이용한 심층 신경망 학습</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 수치 미분을 이용한 심층 신경망 학습</span></span><br><span class="line">import time</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment">## 유틸리티 함수</span></span><br><span class="line">epsilon = 0.0001</span><br><span class="line"></span><br><span class="line">def _t(x):</span><br><span class="line">    <span class="built_in">return</span> np.transpose(x)</span><br><span class="line"></span><br><span class="line">def _m(A, B):</span><br><span class="line">    <span class="built_in">return</span> np.matmul(A, B)</span><br><span class="line"></span><br><span class="line">def sigmoid(x):</span><br><span class="line">    <span class="built_in">return</span> 1 / (1 + np.exp(-x))</span><br><span class="line"></span><br><span class="line">def mean_squared_error(h, y):</span><br><span class="line">    <span class="built_in">return</span> 1 / 2 * np.mean(np.square(h - y))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 뉴런 구현</span></span><br><span class="line">class Neuron:</span><br><span class="line">    def __init__(self, W, b, a):</span><br><span class="line">        self.W = W</span><br><span class="line">        self.b = b</span><br><span class="line">        self.a = a</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Gradient</span></span><br><span class="line">        self.dW = np.zeros_like(self.W)</span><br><span class="line">        self.db = np.zeros_like(self.b)</span><br><span class="line"></span><br><span class="line">    def __call__(self, x):</span><br><span class="line">        <span class="built_in">return</span> self.a(_m(_t(self.W), x) + self.b) <span class="comment"># activation((W^T)x + b)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 심층신경망 구현</span></span><br><span class="line">class DNN:</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    hidden_depth : hidden_layer의 갯수</span></span><br><span class="line"><span class="string">    num_neuron : hidden_layer 하나당 neuron의 갯수</span></span><br><span class="line"><span class="string">    num_input : input_layer의 neuron의 갯수</span></span><br><span class="line"><span class="string">    num_output : output_layer의 neuron의 갯수</span></span><br><span class="line"><span class="string">    activation : activation funtion으로 사용할 함수</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    def __init__(self, hidden_depth, num_neuron, num_input, num_output, activation=sigmoid):</span><br><span class="line">        <span class="comment"># W, b initialize</span></span><br><span class="line">        def init_var(i, o):</span><br><span class="line">            <span class="built_in">return</span> np.random.normal(0.0, 0.01, (i, o)), np.zeros((o,))</span><br><span class="line"></span><br><span class="line">        self.sequence = list()</span><br><span class="line">        <span class="comment"># First hidden layer</span></span><br><span class="line">        W, b = init_var(num_input, num_neuron)</span><br><span class="line">        self.sequence.append(Neuron(W, b, activation))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Hidden layers</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(hidden_depth - 1):</span><br><span class="line">            W, b = init_var(num_neuron, num_neuron)</span><br><span class="line">            self.sequence.append(Neuron(W, b, activation))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Output layer</span></span><br><span class="line">        <span class="comment"># 단순히 심층신경망 구현 후에 수치미분을 사용한 역전파학습을 보이기 위한 코드이므로</span></span><br><span class="line">        <span class="comment"># Output layer의 activation function을 따로 바꾸지 않고 sigmoid로 사용하겠다.</span></span><br><span class="line">        W, b = init_var(num_neuron, num_output)</span><br><span class="line">        self.sequence.append(Neuron(W, b, activation))</span><br><span class="line"></span><br><span class="line">    def __call__(self, x):</span><br><span class="line">        <span class="comment"># layer를 call하는 것은 결국 위에서 정의한 Neuron의 call이 될 것이고</span></span><br><span class="line">        <span class="comment"># x는 activation((W^T)x + b)이 될 것이다.</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.sequence:</span><br><span class="line">            x = layer(x)</span><br><span class="line">        <span class="built_in">return</span> x</span><br><span class="line"></span><br><span class="line">    def calc_gradient(self, x, y, loss_func):</span><br><span class="line">        def get_new_sequence(layer_index, new_neuron):</span><br><span class="line">        <span class="comment"># 특정한 변수하나(weight나 bias)만 변화를 줘서 그 때 loss가 얼마나 변하는지를 보고</span></span><br><span class="line">        <span class="comment"># numerical gradient를 계산하려하기 때문에 변화된 변수가 있는 새로운 Sequence가 필요하다.</span></span><br><span class="line">            new_sequence = list()</span><br><span class="line">            <span class="keyword">for</span> i, layer <span class="keyword">in</span> enumerate(self.sequence):</span><br><span class="line">                <span class="keyword">if</span> i == layer_index:</span><br><span class="line">                    new_sequence.append(new_neuron)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    new_sequence.append(layer)</span><br><span class="line">            <span class="built_in">return</span> new_sequence</span><br><span class="line"></span><br><span class="line">        def eval_sequence(x, sequence):</span><br><span class="line">            <span class="keyword">for</span> layer <span class="keyword">in</span> sequence:</span><br><span class="line">                x = layer(x)</span><br><span class="line">            <span class="built_in">return</span> x</span><br><span class="line"></span><br><span class="line">        loss = loss_func(self(x), y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> layer_id, layer <span class="keyword">in</span> enumerate(self.sequence): <span class="comment"># iterate layer</span></span><br><span class="line">            <span class="keyword">for</span> w_i, w <span class="keyword">in</span> enumerate(layer.W): <span class="comment"># iterate W (row)</span></span><br><span class="line">                <span class="keyword">for</span> w_j, ww <span class="keyword">in</span> enumerate(w): <span class="comment"># iterate W (col)</span></span><br><span class="line">                    W = np.copy(layer.W)</span><br><span class="line">                    W[w_i][w_j] = ww + epsilon</span><br><span class="line"></span><br><span class="line">                    new_neuron = Neuron(W, layer.b, layer.a)</span><br><span class="line">                    new_seq = get_new_sequence(layer_id, new_neuron)</span><br><span class="line">                    h = eval_sequence(x, new_seq)</span><br><span class="line"></span><br><span class="line">                    num_grad = (loss_func(h, y) - loss) / epsilon  <span class="comment"># (f(x+eps) - f(x)) / epsilon</span></span><br><span class="line">                    layer.dW[w_i][w_j] = num_grad</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> b_i, bb <span class="keyword">in</span> enumerate(layer.b): <span class="comment"># iterate b</span></span><br><span class="line">                    b = np.copy(layer.b)</span><br><span class="line">                    b[b_i] = bb + epsilon</span><br><span class="line"></span><br><span class="line">                    new_neuron = Neuron(layer.W, b, layer.a)</span><br><span class="line">                    new_seq = get_new_sequence(layer_id, new_neuron)</span><br><span class="line">                    h = eval_sequence(x, new_seq)</span><br><span class="line"></span><br><span class="line">                    num_grad = (loss_func(h, y) - loss) / epsilon  <span class="comment"># (f(x+eps) - f(x)) / epsilon</span></span><br><span class="line">                    layer.db[b_i] = num_grad</span><br><span class="line">        <span class="comment"># gradient를 계산할 때 loss를 return해야 학습과정에 loss가 어떻게 되는지를 알 수 있기때문에 return 해준다.  </span></span><br><span class="line">        <span class="built_in">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment">## 경사하강법</span></span><br><span class="line">def gradient_descent(network, x, y, loss_obj, alpha=0.01):</span><br><span class="line">    loss = network.calc_gradient(x, y, loss_obj)</span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> network.sequence:</span><br><span class="line">        layer.W += -alpha * layer.dW</span><br><span class="line">        layer.b += -alpha * layer.db</span><br><span class="line">    <span class="built_in">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment">## 동작 테스트</span></span><br><span class="line">x = np.random.normal(0.0, 1.0, (10,))</span><br><span class="line">y = np.random.normal(0.0, 1.0, (2,))</span><br><span class="line"></span><br><span class="line">dnn = DNN(hidden_depth=5, num_neuron=32, num_input=10, num_output=2, activation=sigmoid)</span><br><span class="line"></span><br><span class="line">t = time.time()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(100):</span><br><span class="line">    loss = gradient_descent(dnn, x, y, mean_squared_error, 0.01)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'Epoch &#123;&#125;: Test loss &#123;&#125;'</span>.format(epoch, loss))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'&#123;&#125; seconds elapsed.'</span>.format(time.time() - t))</span><br></pre></td></tr></table></figure><h2 id="역전파-알고리즘을-이용한-심층-신경망-학습"><a href="#역전파-알고리즘을-이용한-심층-신경망-학습" class="headerlink" title="역전파 알고리즘을 이용한 심층 신경망 학습"></a>역전파 알고리즘을 이용한 심층 신경망 학습</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 역전파 학습을 이용한 심층 신경망 학습</span></span><br><span class="line">import time</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment">## 유틸리티 함수</span></span><br><span class="line">def _t(x):</span><br><span class="line">    <span class="built_in">return</span> np.transpose(x)</span><br><span class="line"></span><br><span class="line">def _m(A, B):</span><br><span class="line">    <span class="built_in">return</span> np.matmul(A, B)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Sigmoid 구현</span></span><br><span class="line">class Sigmoid:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        <span class="comment"># 곱의 형태로 나오게 되므로 처음에 1로해서 추후에 입력될 수치에 영향을 덜 주게 해준다.</span></span><br><span class="line">        self.last_o = 1</span><br><span class="line"></span><br><span class="line">    def __call__(self, x):</span><br><span class="line">        self.last_o =  1 / (1.0 + np.exp(-x))</span><br><span class="line">        <span class="built_in">return</span> self.last_o</span><br><span class="line"></span><br><span class="line">    def grad(self):</span><br><span class="line">        <span class="comment"># sigmoid(x) * (1- sigmoid(x))</span></span><br><span class="line">        <span class="built_in">return</span> self.last_o*(1-self.last_o)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Mean Squared Error 구현</span></span><br><span class="line">class MeanSquaredError:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        <span class="comment"># chain rule을 할 때 MSE로 부터 gradient를 계속해서 가져와야하므로 저장해놓기 위해</span></span><br><span class="line">        self.dh = 1</span><br><span class="line">        self.last_diff = 1</span><br><span class="line"></span><br><span class="line">    def __call__(self, h, y): <span class="comment"># 1/2 * mean((h - y)^2)</span></span><br><span class="line">            self.last_diff = h - y</span><br><span class="line">            <span class="built_in">return</span> 1 / 2 * np.mean(np.square(h - y))</span><br><span class="line"></span><br><span class="line">    def grad(self): <span class="comment"># h - y</span></span><br><span class="line">        <span class="built_in">return</span> self.last_diff</span><br><span class="line"></span><br><span class="line"><span class="comment">## 뉴런 구현</span></span><br><span class="line">class Neuron:</span><br><span class="line">    def __init__(self, W, b, a_obj):</span><br><span class="line">        self.W = W</span><br><span class="line">        self.b = b</span><br><span class="line">        <span class="comment"># activation이 이전과 다르게 class로 작성되었으므로 instanctiation을 해주어야한다.  </span></span><br><span class="line">        self.a = a_obj()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># gradient</span></span><br><span class="line">        self.dW = np.zeros_like(self.W)</span><br><span class="line">        self.db = np.zeros_like(self.b)</span><br><span class="line">        self.dh = np.zeros_like(_t(self.W))</span><br><span class="line"></span><br><span class="line">        <span class="comment">## 아래의 grad_W를 위해 저장해놓는다.</span></span><br><span class="line">        <span class="comment">## W로 미분했을 경우 이전 입력을 갖고 있어야 바로 사용할 수 있으므로</span></span><br><span class="line">        self.last_x = np.zeros((self.W.shape[0]))</span><br><span class="line">        self.last_h = np.zeros((self.W.shape[1]))</span><br><span class="line"></span><br><span class="line">    def __call__(self, x):</span><br><span class="line">        self.last_x = x</span><br><span class="line">        self.last_h = _m(_t(self.W), x) + self.b</span><br><span class="line">        <span class="built_in">return</span> self.a(self.last_h)</span><br><span class="line"></span><br><span class="line">    def grad(self): <span class="comment"># dy/dh = W</span></span><br><span class="line">        <span class="built_in">return</span> self.W * self.a.grad()</span><br><span class="line"></span><br><span class="line">    def grad_W(self, dh):</span><br><span class="line">        grad = np.ones_like(self.W)</span><br><span class="line">        grad_a = self.a.grad()</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(grad.shape[1]): <span class="comment"># dy/dw = x</span></span><br><span class="line">            grad[:, j] = dh[j] * grad_a[j] * self.last_x</span><br><span class="line">        <span class="built_in">return</span> grad</span><br><span class="line"></span><br><span class="line">    def grad_b(self, dh): <span class="comment"># dy/db = 1</span></span><br><span class="line">        <span class="built_in">return</span> dh * self.a.grad() * 1</span><br><span class="line"></span><br><span class="line"><span class="comment">## 심층신경망 구현</span></span><br><span class="line">class DNN:</span><br><span class="line">    def __init__(self, hidden_depth, num_neuron, input, output, activation=Sigmoid):</span><br><span class="line">        def init_var(i, o):</span><br><span class="line">            <span class="built_in">return</span> np.random.normal(0.0, 0.01, (i, o)), np.zeros((o,))</span><br><span class="line"></span><br><span class="line">        self.sequence = list()</span><br><span class="line">        <span class="comment"># First hidden layer</span></span><br><span class="line">        W, b = init_var(input, num_neuron)</span><br><span class="line">        self.sequence.append(Neuron(W, b, activation))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Hidden Layers</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> range(hidden_depth):</span><br><span class="line">            W, b = init_var(num_neuron, num_neuron)</span><br><span class="line">            self.sequence.append(Neuron(W, b, activation))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Output Layer</span></span><br><span class="line">        W, b = init_var(num_neuron, output)</span><br><span class="line">        self.sequence.append(Neuron(W, b, activation))</span><br><span class="line"></span><br><span class="line">    def __call__(self, x):</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.sequence:</span><br><span class="line">            x = layer(x)</span><br><span class="line">        <span class="built_in">return</span> x</span><br><span class="line"></span><br><span class="line">    def calc_gradient(self, loss_obj):</span><br><span class="line">        loss_obj.dh = loss_obj.grad()</span><br><span class="line">        <span class="comment"># for문에서 한번에 처리하기 위해서 loss object를 넣어준다.</span></span><br><span class="line">        self.sequence.append(loss_obj)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># back_propagation loop</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.sequence) -1, 0 , -1):</span><br><span class="line">            l1 = self.sequence[i]</span><br><span class="line">            l0 = self.sequence[i - 1]</span><br><span class="line"></span><br><span class="line">            l0.dh = _m(l0.grad(), l1.dh)</span><br><span class="line">            l0.dw = l0.grad_W(l1.dh)</span><br><span class="line">            l0.db = l0.grad_b(l1.dh)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># loss object가 들어 있으면 출력을 얻지 못하고 loss 만 얻게 될 것이기 때문이다.</span></span><br><span class="line">        self.sequence.remove(loss_obj)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 경사하강 학습법</span></span><br><span class="line">def gradient_descent(network, x, y, loss_obj, alpha=0.01):</span><br><span class="line">    loss = loss_obj(network(x), y)  <span class="comment"># Forward inference</span></span><br><span class="line">    network.calc_gradient(loss_obj)  <span class="comment"># Back-propagation</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> network.sequence:</span><br><span class="line">        layer.W += -alpha * layer.dW</span><br><span class="line">        layer.b += -alpha * layer.db</span><br><span class="line">    <span class="built_in">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment">## 동작 테스트</span></span><br><span class="line">x = np.random.normal(0.0, 1.0, (10,))</span><br><span class="line">y = np.random.normal(0.0, 1.0, (2,))</span><br><span class="line"></span><br><span class="line">t = time.time()</span><br><span class="line">dnn = DNN(hidden_depth=5, num_neuron=32, input=10, output=2, activation=Sigmoid)</span><br><span class="line">loss_obj = MeanSquaredError()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(100):</span><br><span class="line">    loss = gradient_descent(dnn, x, y, loss_obj, alpha=0.01)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'Epoch &#123;&#125;: Test loss &#123;&#125;'</span>.format(epoch, loss))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'&#123;&#125; seconds elapsed.'</span>.format(time.time() - t))</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/12/08/deep_learning03/#disqus_thread</comments>
    </item>
    
    <item>
      <title>가장 단순한 신경망을 통한 작동원리</title>
      <link>https://heung-bae-lee.github.io/2019/12/06/deep_learning01/</link>
      <guid>https://heung-bae-lee.github.io/2019/12/06/deep_learning01/</guid>
      <pubDate>Thu, 05 Dec 2019 15:00:00 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;img src=&quot;/image/Neuron.png&quot; alt=&quot;신경 세포&quot;&gt;&lt;br&gt;&lt;img src=&quot;/image/Graph_of_Neuron.png&quot; alt=&quot;Neuron의 그래프 표현&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Node가 단일 뉴런 연산을 의미한
        
      
      </description>
      
      
      <content:encoded><![CDATA[<p><img src="/image/Neuron.png" alt="신경 세포"><br><img src="/image/Graph_of_Neuron.png" alt="Neuron의 그래프 표현"></p><ul><li>Node가 단일 뉴런 연산을 의미한다고 했는데 여기서의 단일 뉴런 연산이란 input에 가중치를 곱하고 합계를 낸 후에 activation function까지 통과시키는 과정을 의미한다.</li></ul><p><img src="/image/Artificial_NN.png" alt="인공신경망"></p><p><img src="/image/Fully_connected_Layer.png" alt="Fully-Connected Layer(Dense Layer)"></p><p><img src="/image/ShallowNN.png" alt="얕은 신경망"></p><p><img src="/image/what_will_you_do_with_shallowNN.png" alt="얕은 신경망으로 무엇을 할 수 있을까?"></p><p><img src="/image/regression.png" alt="회귀"></p><p><img src="/image/classification.png" alt="분류"></p><p><img src="/image/regression_with_shallowNN.png" alt="얕은 신경망을 이용한 회귀"></p><p><img src="/image/binary_classification_with_shallowNN.png" alt="얕은 신경망을 이용한 이진분류"></p><p><img src="/image/Multi_classification_with_shallowNN.png" alt="얕은 신경망을 이용한 다중 클래스 분류"></p><p><img src="/image/mathmatical_expression_of_Neuron.png" alt="뉴런의 수학적 표현"></p><ul><li>위의 식에서 편향을 잊어버리지 말자!! 예를들면, 편향이 없다면 원점을 지나는 선만 표현할 수 있지만 <code>편향을 통해 원점을 지나지 않는 선들도 표현할 수 있게 할 수 있다.</code> 참고로 특별히 편향이 없는 경우도 있을 순 있다.</li></ul><p><img src="/image/mathmatical_expression_of_Fully_connecter_layer.png" alt="전결합 계층의 수학적 표현"></p><p><img src="/image/input_Layer.png" alt="입력 계층"></p><p><img src="/image/hidden_Layer.png" alt="은닉계층"></p><p><img src="/image/output_Layer.png" alt="출력계층"></p><h2 id="회귀-문제"><a href="#회귀-문제" class="headerlink" title="회귀 문제"></a>회귀 문제</h2><p><img src="/image/regression01.png" alt="회귀"></p><ul><li>어떤 입력이 들어왔을 떄 출력이 연속적인 값을 가질 때 Regression을 사용한다.</li></ul><p><img src="/image/simple_linear_regression.png" alt="단순 선형 회귀"><br><img src="/image/multi_linear_regression.png" alt="다중 선형 회귀"><br><img src="/image/aspect_of_geometry_about_multi_linear_regression.png" alt="다중 선형 회귀의 기하학적 해석"><br><img src="/image/shallowNN_and_regression_algorithm.png" alt="얕은 신경망과 회귀 알고리즘"><br><img src="/image/hidden_Layer_and_regression.png" alt="은닉 계층과 회귀"></p><h2 id="이진-분류-문제"><a href="#이진-분류-문제" class="headerlink" title="이진 분류 문제"></a>이진 분류 문제</h2><p><img src="/image/classification_01.png" alt="분류"><br><img src="/image/logistic_regression.png" alt="로지스틱 회귀"><br><img src="/image/sigmoid_function.png" alt="sigmoid function"><br><img src="/image/binary_cross_entropy.png" alt="교차 엔트로피 오차"><br><img src="/image/aspect_of_geometry _about_multi_logistic_regression.png" alt="다중 로지스틱 회귀의 기하학적 해석"><br><img src="/image/shallowNN_and_classification_algorithm.png" alt="얕은 신경망과 분류 알고리즘"><br><img src="/image/hidden_Layer_and_classification.png" alt="은닉계층과 분류"></p><h2 id="다중-분류-문제"><a href="#다중-분류-문제" class="headerlink" title="다중 분류 문제"></a>다중 분류 문제</h2><p><img src="/image/multi_classification.png" alt="다중 클래스 분류"></p><p><img src="/image/one_hot_encoding.png" alt="one-hot Encoding"><br><img src="/image/sparse_expression_of_one_hot_encoding.png" alt="one-hot Encoding의 희소 표현"><br><img src="/image/multi_classificatio_with_shallowNN.png" alt="얕은 신경망을 이용한 다중 클래스 분류"><br><img src="/image/how_do_shallowNN_compute_output.png" alt="어떻게 출력을 계산할 것인가?"><br><img src="/image/softmax_vs_sigmoid.png" alt="Softmax vs Sigmoid"><br><img src="/image/how_do_shallowNN_compare_Truth_with_outputs.png" alt="정답과 출력을 어떻게 비교할까?"><br><img src="/image/Cross_Entropy_Error.png" alt="Cross Entropy Error"></p><ul><li>Softmax의 분모에 의해서 다른 클래스에 대한 학습에도 영향을 준다는 의미이다. 분모는 다른 클래스로 예측한 확률또한 더해주기 때문이다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 얕은 신셩망을 이용한 다중 분류 문제</span></span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"><span class="comment">## 함수 구현</span></span><br><span class="line"><span class="comment"># Sigmoid 함수</span></span><br><span class="line"></span><br><span class="line">def sigmoid(x):</span><br><span class="line">    <span class="built_in">return</span> 1/(1+np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Softmax 함수</span></span><br><span class="line">def softmax(x):</span><br><span class="line">    <span class="built_in">return</span> np.exp(x)/np.sum(np.exp(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 네트워크 구조 정의</span></span><br><span class="line">class ShallowNN:</span><br><span class="line">    <span class="comment"># 아래의 W와 b에 적절한 값은 추후에 넣어주기 때문에 현재는 0으로 잡음</span></span><br><span class="line">    def __init__(self, num_input, num_hidden, num_output):</span><br><span class="line">        self.W_h = np.zeros((num_hidden, num_input), dtype=np.float32)</span><br><span class="line">        self.b_h = np.zeros((num_hidden, 1), dtype=np.float32)</span><br><span class="line"></span><br><span class="line">        self.W_o = np.zeros((num_output, num_hidden), dtype=np.float32)</span><br><span class="line">        self.b_o = np.zeros((num_output, 1), dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># NN의 연산을 call 형태로 해서 작성</span></span><br><span class="line">    def __call__(self, x):</span><br><span class="line">        h = sigmoid(np.matmul(self.W_h, x) + self.b_h)</span><br><span class="line">        <span class="built_in">return</span> softmax(np.matmul(self.W_o, h) + self.b_o)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터셋 불러오기</span></span><br><span class="line">dataset = np.load(<span class="string">'ch2_dataset.npz'</span>)</span><br><span class="line">inputs = dataset[<span class="string">'inputs'</span>]</span><br><span class="line">labels = dataset[<span class="string">'labels'</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(labels.shape)</span><br><span class="line"><span class="built_in">print</span>(inputs.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ShallowNN Model 생성</span></span><br><span class="line">model=ShallowNN(num_input=inputs.shape[1], num_hidden=128, num_output=10)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 사전에 학습된 파라미터 불러오기</span></span><br><span class="line">weights = np.load(<span class="string">'ch2_parameters.npz'</span>)</span><br><span class="line">model.W_h = weights[<span class="string">'W_h'</span>]</span><br><span class="line">model.b_h = weights[<span class="string">'b_h'</span>]</span><br><span class="line">model.W_o = weights[<span class="string">'W_o'</span>]</span><br><span class="line">model.b_o = weights[<span class="string">'b_o'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 결과 프린트</span></span><br><span class="line">outputs = []</span><br><span class="line"><span class="keyword">for</span> point, label <span class="keyword">in</span> zip(inputs, labels):</span><br><span class="line">    output = model(point)</span><br><span class="line">    outputs.append(np.argmax(output))</span><br><span class="line">    <span class="built_in">print</span>(np.argmax(output), label)</span><br><span class="line"></span><br><span class="line">outputs =  np.stack(outputs, axis=0)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 정답 클래스 scatter plot</span></span><br><span class="line">plt.figure()</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> range(10):</span><br><span class="line">    mask = labels == idx</span><br><span class="line">    plt.scatter(inputs[mask, 0], inputs[mask, 1])</span><br><span class="line">plt.title(<span class="string">'True Label'</span>)</span><br><span class="line"><span class="comment"># plt.grid()</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 출력 클래스 scatter plot</span></span><br><span class="line">plt.figure()</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> range(10):</span><br><span class="line">    mask = outputs == idx</span><br><span class="line">    plt.scatter(inputs[mask, 0], inputs[mask, 1])</span><br><span class="line">plt.title(<span class="string">'Model output'</span>)</span><br><span class="line"><span class="comment"># plt.grid()</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/12/06/deep_learning01/#disqus_thread</comments>
    </item>
    
    <item>
      <title>딥러닝이 무엇인가?</title>
      <link>https://heung-bae-lee.github.io/2019/12/05/deep_learning00/</link>
      <guid>https://heung-bae-lee.github.io/2019/12/05/deep_learning00/</guid>
      <pubDate>Wed, 04 Dec 2019 15:00:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;딥러닝의-이해&quot;&gt;&lt;a href=&quot;#딥러닝의-이해&quot; class=&quot;headerlink&quot; title=&quot;딥러닝의 이해&quot;&gt;&lt;/a&gt;딥러닝의 이해&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/image/deeplearning_vs_machinelearning_v
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h2 id="딥러닝의-이해"><a href="#딥러닝의-이해" class="headerlink" title="딥러닝의 이해"></a>딥러닝의 이해</h2><p><img src="/image/deeplearning_vs_machinelearning_vs_AI.png" alt="딥러닝 vs 기계학습 vs 인공지능"></p><p><img src="/image/deepleaaning_vs_bigdata.png" alt="딥러닝 vs 빅데이터"></p><p><img src="/image/why_deeplearning_is_so_special.png" alt="딥러닝은 왜 특별한가요?"></p><ul><li><p>기계학습의 경우에는 위의 고양이와 개를 구분하기 위해서 이진 분류기를 구현할 것인데, 이런 이진 분류기를 구현하기 위해서는 Feature Extractor가 필요하다. 여기서 말하는 Feature Extractor 란 구분에 용이한 특징을 추출하여 feature vector를 만드는 데 사용하는 것이다. 이렇게 잘 추출한 특징 벡터를 가지고 분류기를 개와 고양이를 구분한다. <code>특징 추출기를 통해 사람이 직접 Feature vector들을 만들고 Classifier 부분만 기계가 학습하는 방식이 Machine Learning이다.</code></p></li><li><p>반면에 딥러닝은 개와 고양이의 row data를 받아서 Feature Extractor가 네트워크 구조 내부에 포함되어 있다. <code>특징 추출도 컴퓨터가 하고 classifier 부분도 컴퓨터가 알아서 분류하므로 전체 네트워크 구조가 학습대상이 된다.</code></p></li></ul><p><img src="/image/what_will_you_do_with_deeplearning00.png" alt="딥러닝으로 무엇을 할 수 있나요?01"><br><img src="/image/what_will_you_do_with_deeplearning01.png" alt="딥러닝으로 무엇을 할 수 있나요?02"><br><img src="/image/what_will_you_do_with_deeplearning02.png" alt="딥러닝으로 무엇을 할 수 있나요?03"><br><img src="/image/deeplearning_consist_of.png" alt="딥러닝의 구성 요소"></p><p>딥러닝은 과거 몇번의 고비(XOR문제를 다층 퍼셉트론으로 극복, 기울기 소실문제는 심층믿음 신경망을 통해 극복)을 극복하고 현재는 많은 이들의 관심 속에 발전해가고 있다. 딥러닝의 대중화를 이끈 요소들을 다음 그림들에서 볼 수있다.<br><img src="/image/tensorflow_and_pytorch.png" alt="TensorFlow&amp;PyTorch"><br><img src="/image/Cloud_Platform.png" alt="딥러닝의대중화-Cloud Platform"><br><img src="/image/GPU.png" alt="딥러닝의대중화-GPU"><br><img src="/image/Cloud_Platform1.png" alt="딥러닝의대중화-Cloud Platform1"></p>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/12/05/deep_learning00/#disqus_thread</comments>
    </item>
    
    <item>
      <title>data engineering basic</title>
      <link>https://heung-bae-lee.github.io/2019/11/29/data_engineering_basic/</link>
      <guid>https://heung-bae-lee.github.io/2019/11/29/data_engineering_basic/</guid>
      <pubDate>Fri, 29 Nov 2019 10:57:36 GMT</pubDate>
      <description>
      
        
        
          &lt;h3 id=&quot;데이터-분석가와-엔지니어링-차이점&quot;&gt;&lt;a href=&quot;#데이터-분석가와-엔지니어링-차이점&quot; class=&quot;headerlink&quot; title=&quot;데이터 분석가와 엔지니어링 차이점&quot;&gt;&lt;/a&gt;데이터 분석가와 엔지니어링 차이점&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h3 id="데이터-분석가와-엔지니어링-차이점"><a href="#데이터-분석가와-엔지니어링-차이점" class="headerlink" title="데이터 분석가와 엔지니어링 차이점"></a>데이터 분석가와 엔지니어링 차이점</h3><ul><li>데이터 분석가는 갖춰진 데이터 시스템과 데이터를 통해서 다양한 분석을 하는 업무이며, 엔지니어링은 그와 다르게 비즈니스에 맞는 데이터를 추출하고 그에 따라 분석하는 환경을 만들어 나가는 업무라고 생각할 수 있을 것이다. 특히, 데이터 전처리나 추출, 정제를 담당하는 업무이다.</li></ul><h3 id="데이터-엔지니어링이-중요한-이유"><a href="#데이터-엔지니어링이-중요한-이유" class="headerlink" title="데이터 엔지니어링이 중요한 이유"></a>데이터 엔지니어링이 중요한 이유</h3><ul><li><code>비즈니스 모델과 가장 연관이 깊은 업무</code>이다. 왜냐하면 회사의 비즈니스 모델에 맞는 데이터를 가져와야하고 가져온 데이터를 통해 어떤 환경을 갖출 것인지, 그에따라 데이터 분석가들이 전략을 짤 때 기반을 갖출 수 있도록 해주려면 어떻게 해야할지가 중요하기 때문이다.<code>그래서 엔지니어링을 뽑을 경우 해당 비즈니스의 Knowledge가 어느 정도 있는 것이 좋을 거라고 생각이들고 실제로 그렇게 면접도 보는(?)것 같다.</code></li></ul><p><img src="/image/facebook.png" alt="페이스북"></p><p><img src="/image/ecommerce.png" alt="이커머스"></p><ul><li>페이스북은 User와 관련 세밀한 데이터가 중요했지만 e-commerce는 User 관련 데이터 보다는 마케팅, CRM, 물류 데이터가 상대적으로 더 중요할 수도 있다.</li></ul><h3 id="데이터-아키텍쳐시-고려사항"><a href="#데이터-아키텍쳐시-고려사항" class="headerlink" title="데이터 아키텍쳐시 고려사항"></a>데이터 아키텍쳐시 고려사항</h3><h4 id="1-비즈니스-모델-상-가장-중요한-데이터는-무엇인가"><a href="#1-비즈니스-모델-상-가장-중요한-데이터는-무엇인가" class="headerlink" title="1.비즈니스 모델 상 가장 중요한 데이터는 무엇인가?"></a>1.비즈니스 모델 상 가장 중요한 데이터는 무엇인가?</h4><ul><li>발생되는 데이터 양 대비 초점을 맞춰야 하는 데이터는 어떤 것인지 즉, <code>비용 대비 비즈니스 임팩트가 가장 높으 데이터를 확보하는 것이 제일 중요</code>하다.</li></ul><h4 id="2-Data-Governance"><a href="#2-Data-Governance" class="headerlink" title="2.Data Governance"></a>2.Data Governance</h4><p><img src="/image/datagovernece.png" alt="데이터 거버넌스"></p><h4 id="3-유연하고-변화-가능한-환경-구축"><a href="#3-유연하고-변화-가능한-환경-구축" class="headerlink" title="3.유연하고 변화 가능한 환경 구축"></a>3.유연하고 변화 가능한 환경 구축</h4><ul><li>특정 기술 및 솔루션에 얽매여져 있지 않고 새로운 테크를 빠르게 적용할 수 있는 아키텍쳐를 만드는 것<ul><li>생성되는 데이터의 형식이 변화할 수 있는 것처럼 그에 맞는 Tool들과 solution들도 빠르게 변화할 수 있는 시스템을 구축하는 것</li></ul></li></ul><h4 id="4-Real-Time-실시간-데이터-핸들링이-가능한-시스템"><a href="#4-Real-Time-실시간-데이터-핸들링이-가능한-시스템" class="headerlink" title="4. Real Time(실시간) 데이터 핸들링이 가능한 시스템"></a>4. Real Time(실시간) 데이터 핸들링이 가능한 시스템</h4><ul><li><p>밀리세컨 단위의 스트리밍 데이터가 됐건 하루에 한번 업데이트 되는 데이터든 데이터 아키텍쳐는 모든 스피드의 데이터를 핸들링 해야한다.</p><ul><li>Real Time Streaming Data Processing</li><li>Cronjob</li><li>Serverless Triggered Data Processing</li></ul></li></ul><h4 id="5-시큐리티"><a href="#5-시큐리티" class="headerlink" title="5. 시큐리티"></a>5. 시큐리티</h4><ul><li>내부와 외부 모든 곳에서부터 발생할 수 있는 위험요소들을 파악하여 <code>어떻게 데이터를 안전하게 관리할 수 있는지 아키텍쳐 안에 포함</code></li></ul><h4 id="6-셀프-서비스-환경-구축"><a href="#6-셀프-서비스-환경-구축" class="headerlink" title="6. 셀프 서비스 환경 구축"></a>6. 셀프 서비스 환경 구축</h4><ul><li>데이터 엔지니어 한명만 엑세스가 가능한 데이터 시스템은 확장성이 없는 데이터 분석 환경이다. 이런 환경에서는 예를 들어, 데이터 분석가들이라던지, 데이터 사이언티스트들, 비즈니스팀들 등 다른 사람들도 BI Tool, Query System for Analysis, Front-end application등 이 가능하게끔 <code>확장성이 있도록 환경을 구축하는 것이 중요하다.</code></li></ul><h3 id="데이터-시스템의-옵션들"><a href="#데이터-시스템의-옵션들" class="headerlink" title="데이터 시스템의 옵션들"></a>데이터 시스템의 옵션들</h3><h4 id="API시대"><a href="#API시대" class="headerlink" title="API시대"></a>API시대</h4><ul><li>현재 마케팅, CRM, ERP등 다양한 플랫폼 및 소프트웨어들은 API라는 송신방법을 통해 데이터를 주고 받을 수 있는 환경을 구축하여 생태계를 생성되어있다. 예를들면, facebook, google, Spotify같은 서비스들이 회사자체에 DB시스템을 구축하고 있는데, 이런 데이터들을 API를 통해 바로 DB에 엑세스해서 서비스를 제공할 수도 있고, 아니면 DB를 새로 생성해 거기에 받아서 저장해놓은 후 정제 및 분석 환경을 구축하여 다양한 서비스를 제공할 수 있다. 이런 환경에서 현재 많은 서비스들이 있으며, 새로운 서비스를 개발하는 입장에서는 필요한 여러가지 서비스들이 있는데, 일일이 다 만들수 없으므로 만들어져 있는 것들, 써드 파티라고 하는 서비스들을 이용하는 것이다. 이러한 서비스를 이용하는 데이터를 가지고도 또다른 분석환경을 구축해야 한다. ex) CaFe24(호스팅업체), facebook Ads,Google Ads(마케팅분야)</li></ul><h4 id="Relational-Databases"><a href="#Relational-Databases" class="headerlink" title="Relational Databases"></a>Relational Databases</h4><ul><li><p>데이터의 관계도를 기반으로 한 디지털 데이터베이스로 데이터의 저장을 목적으로 생겨났다.</p></li><li><p>SQL이라고 하는 스탠다드 방식을 통해 자료를 열람하고 유지한다.</p></li><li><p>현재 대부분의 서비스들이 가장 많이 쓰고 있는 데이터 시스템.</p></li></ul><h4 id="NoSQL-Databases"><a href="#NoSQL-Databases" class="headerlink" title="NoSQL Databases"></a>NoSQL Databases</h4><ul><li><p>관계형 데이터 베이스에서는 Schema 형식에 맞춰 데이터를 추출 및 저장했다면, <code>이제는 너무나 다양한 형식이 없는 데이터 부터 틀에 맞출 수 없는 데이터들이 생성되어 NoSQL이 대두되었다.</code> 예를 들면 메신저에서 많이 사용된다.</p></li><li><p>Not Only NoSQL</p></li><li><p>Unstructured, Schema Less Databases</p></li><li><p>Scale horizontally</p></li><li><p>Highly scalable</p></li></ul><h4 id="Haddop-Spark-Presto-등-빅데이터-처리"><a href="#Haddop-Spark-Presto-등-빅데이터-처리" class="headerlink" title="Haddop / Spark / Presto 등 빅데이터 처리"></a>Haddop / Spark / Presto 등 빅데이터 처리</h4><h5 id="Distribtion-Storage-System-MapReduce를-통한-병렬-처리-Spark"><a href="#Distribtion-Storage-System-MapReduce를-통한-병렬-처리-Spark" class="headerlink" title="Distribtion Storage System / MapReduce를 통한 병렬 처리 Spark"></a>Distribtion Storage System / MapReduce를 통한 병렬 처리 Spark</h5><ul><li><p><code>Hadoop의 진화된 버전으로 빅데이터 분석 환경에서 Real Time 데이터를 프로세싱하기에 더 최적</code></p></li><li><p>java, Python, Scala를 통한 API를 제공하여 Application 생성</p></li><li><p>SQL Query 환경을 서포트하여 분석가들에세 더 각광</p></li></ul><h4 id="서버리스-프레임워크"><a href="#서버리스-프레임워크" class="headerlink" title="서버리스 프레임워크"></a>서버리스 프레임워크</h4><ul><li><p>Triggered by http requests, database events, queuing services</p><ul><li>DB가 됐건, 어떤 server가 됐건 어떠한 하나의 가상 클라우드상에서 server가 필요하게 되는데, 서버를 생성하고 유지및 관리할 때 데이터가 발생하는 event가 발생할 때 Trigger가 되는 부분들을 처리하기 위해 사용한다.</li></ul></li><li><p>Pay as you User</p><ul><li>항상 Server를 띄워놓고 있지 않기 때문에 쓰는 만큼만 비용을 지불하기에 좋다.</li></ul></li><li><p>Form of functions</p><ul><li>하나의 Function이라고 생각하는 것이 좋다. 예를 들어서, 서버리스 프레임 워크를 통해서 어떠한 event가 들어왔을 경우, 어떤 것으로 Trigger가 됐을때, 어떠한 Algorithm을 실행시키는 function이라고 생각하면 된다.</li></ul></li><li><p>3rd Party 앱들 및 다양한 API를 통해 데이터를 수집 정제하는데 유용</p></li></ul><h3 id="데이터-파이프라인"><a href="#데이터-파이프라인" class="headerlink" title="데이터 파이프라인"></a>데이터 파이프라인</h3><h4 id="데이터-파이프라인-1"><a href="#데이터-파이프라인-1" class="headerlink" title="데이터 파이프라인"></a>데이터 파이프라인</h4><ul><li>데이터를 한 장소에서 다른 장소로 옮기는 것을 의미</li></ul><p>ex) API -&gt; DB, DB -&gt; DB, DB -&gt; BI Tool</p><h4 id="데이터-파이프라인이-필요한-경우"><a href="#데이터-파이프라인이-필요한-경우" class="headerlink" title="데이터 파이프라인이 필요한 경우"></a>데이터 파이프라인이 필요한 경우</h4><ul><li><p>1) <code>다양한 데이터 소스들로부터 많은 데이터를 생성하고 저장하는 서비스를 구축</code>할 경우 필요하다!</p></li><li><p>2) <code>데이터 사일로</code>: 마케팅, 어카운팅, 세일즈, 오퍼레이션 등 각 영역의 데이터가 서로 고립되어 있는 경우 (ex)대기업의 각 부서를 생각해보면 이해하기 쉬울 것이다.즉, 각각의 팀들이 따로 존재하여 공유가 어려운경우)</p></li><li><p>3) <code>실시간 혹은 높은 수준의 데이터 분석이 필요한 비즈니스 모델 ex)facebook등</code></p></li><li><p>4) <code>클라우드 환경으로 데이터 저장</code></p></li></ul><p><img src="/image/datapipeline.png" alt="데이터 파이프라인 예시"></p><h4 id="데이터-파이프라인-구축시-고려사항"><a href="#데이터-파이프라인-구축시-고려사항" class="headerlink" title="데이터 파이프라인 구축시 고려사항"></a>데이터 파이프라인 구축시 고려사항</h4><ul><li><p>Scalability : 데이터가 기하급수적으로 늘어났을때도 작동하는가?</p></li><li><p>Stability : 에러, 데이터플로우 등 다양한 모니터링 관리</p></li><li><p>Security : 데이터 이동간 보안에 대한 리스크는 무엇인가?</p></li></ul><h4 id="데이터-프로세싱-자동화란"><a href="#데이터-프로세싱-자동화란" class="headerlink" title="데이터 프로세싱 자동화란?"></a>데이터 프로세싱 자동화란?</h4><ul><li>데이터 프로세싱 자동화란 필요한 데이터를 <code>추출, 수집, 정제하는 프로세싱을 최소한의 사람 인풋으로 머신이 운영하는 것을 의미</code></li></ul><p>ex) Spotify 데이터를 하루에 한번 API를 통해서 클라우드 데이터베이스로 가져온다고 했을 때 매번 사람이 데이터 파이프라인을 작동하는 것이 아니라 Crontab 등 머신 스케쥴링을 통해 자동화</p><h4 id="자동화를-위해-고려할-사항"><a href="#자동화를-위해-고려할-사항" class="headerlink" title="자동화를 위해 고려할 사항"></a>자동화를 위해 고려할 사항</h4><ul><li><p>error가 뜨는 것이든, 추출을 했으면 분석을 한다던지 사람이 하면 순서나 여러가지 고랴를 할 수 있지만, 자동으로 헀을경우는 머신이 모르기 떄문에 다음과 같은 사항들을 고려해야한다.</p></li><li><p>1) 데이터 프로세싱 스텝들<br><img src="/image/dataprocessingstep.png" alt="데이터 프로세싱 스텝들"></p><ul><li>Spotify API에서 어떠한 데이터를 가져와야되고, 그 중에서 어떠한 것들은 걸러내고, 어떤 알고리즘을 돌리고, 그 후에 시각화를 한겠다는 말 그대로 프로세싱 스텝을 의미.</li></ul></li><li><p>2) 에러 핸들링 및 모니터링</p><ul><li>에러가 생성이 됐을때, 어떻게 반응을 하게끔할 것인지, 에러나 퍼포먼스 또는 데이터 추출이 얼마나 걸렸는지 같은 사항을 모니터링 할수 있게끔 구축해야한다.</li></ul></li></ul><p><img src="/image/erroeandhandling.png" alt="에러 핸들링 및 모니터링"></p><ul><li>exampl.log라는 파일에 다양한 로그들을 저장하는데, 그 생성된 로그들도 CloudWatch에도 생성되어 모니터링이 가능하다.</li></ul><ul><li>3) Trigger/ Scheduling<br><img src="/image/triggerandscheduling.png" alt="트리거&amp;스케줄링"><ul><li>다음 단계를 실행하기 위해 어떻게 Trigger가 되어서 실행을 시킬지, 하루에 한번 돌릴지, 아니면 한달에 한번 돌릴지 등에 관한 스케줄을 고려해야한다.</li></ul></li></ul><p><img src="/image/netflex.png" alt="넷플릭스 데이터 시스템 예시"></p><p><img src="/image/uberarchitecture.png" alt="우버 데이터 아키텍쳐"></p><h3 id="Spotify-프로젝트-데이터-아키텍쳐"><a href="#Spotify-프로젝트-데이터-아키텍쳐" class="headerlink" title="Spotify 프로젝트 데이터 아키텍쳐"></a>Spotify 프로젝트 데이터 아키텍쳐</h3><h4 id="Ad-hoc-VS-Automated"><a href="#Ad-hoc-VS-Automated" class="headerlink" title="Ad hoc VS Automated"></a>Ad hoc VS Automated</h4><ul><li><p>Ad hoc 분석 환경 구축은 서비스를 지속적으로 빠르게 변화시키기 위해 필수적인 요소</p><ul><li>Ad hoc 분석은 쉽게 말해 분석을 하고 싶을 때만 하는 것이다. 이런 <code>Ad hoc 분석이 필수적인 이유는 구축한 분석환경을 통해서 다양한 사람들이 분석을 할 수 있게끔해야 하기 때문</code>이다.</li></ul></li><li><p><code>이니셜 데이터 삽입, 데이터 Backfill 등을 위해 Ad hoc 데이터 프로세싱 시스템 구축 필요</code></p></li><li><p>Automated : 이벤트, 스케쥴 등 트리거를 통해 자동화 시스템 구축</p></li></ul><p><img src="/image/dataextractprocessing.png" alt="아티스트 관련 데이터 수집 프로세스"></p><p><img src="/image/dataanalysisenvirment.png" alt="데이터 분석 환경 구축"></p><p><img src="/image/servicerelationprocess.png" alt="서비스 관련 데이터 프로세스"></p>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/11/29/data_engineering_basic/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Requests 모듈 사용하기(HTTP 통신)</title>
      <link>https://heung-bae-lee.github.io/2019/09/28/Request/</link>
      <guid>https://heung-bae-lee.github.io/2019/09/28/Request/</guid>
      <pubDate>Sat, 28 Sep 2019 07:20:55 GMT</pubDate>
      <description>
      
        
        
          &lt;h3 id=&quot;Requests-모듈&quot;&gt;&lt;a href=&quot;#Requests-모듈&quot; class=&quot;headerlink&quot; title=&quot;Requests 모듈&quot;&gt;&lt;/a&gt;Requests 모듈&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;http request/response를 위한 모듈
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h3 id="Requests-모듈"><a href="#Requests-모듈" class="headerlink" title="Requests 모듈"></a>Requests 모듈</h3><ul><li>http request/response를 위한 모듈</li><li>HTTP method를 메소드 명으로 사용하여 request 요청 예)GET, POST</li><li>가장 우리가 흔하게 크롤링을 하는데 사용하는 방식이며, API만 알고 있다면 쉽게 사용할 수 있다!</li></ul>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/09/28/Request/#disqus_thread</comments>
    </item>
    
    <item>
      <title>웹 기본 지식 이해하기 01(chrome을 이용하여 웹페이지 분석하기)</title>
      <link>https://heung-bae-lee.github.io/2019/09/28/HTTP_method/</link>
      <guid>https://heung-bae-lee.github.io/2019/09/28/HTTP_method/</guid>
      <pubDate>Sat, 28 Sep 2019 05:52:18 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;HTTP&quot;&gt;&lt;a href=&quot;#HTTP&quot; class=&quot;headerlink&quot; title=&quot;HTTP&quot;&gt;&lt;/a&gt;HTTP&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;HyperText Transfer Protocol: HTML(HyperText Markup langu
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><ul><li>HyperText Transfer Protocol: HTML(HyperText Markup language) 문서 등의 리소스를 전송하는 프로토콜(규약)</li></ul><p><img src="/image/HTTP.png" alt="그림 00"></p><p>클라이언트에서 서버로 HTTP 요청을 하는데 이 요청 방식으로는 Get, Post, Put, delete, Option등이 있는데 이 중 크롤링에서 가장 많이 쓰이는 두가지(Get, Post)를 알아볼 것이다.</p><ul><li>GET 요청 : <code>데이터를 URL에 포함하여 전달이 가능하다. 그러므로 정보의 공유가 가능</code>하다. 공유가 가능하다는 의미는 가장 쉬운 예를 들자면 URL 클릭하면 그 정보를 담고있는 웹 페이지를 요청하여 우리의 웹 브라우져에 랜더링을 거쳐 보여주는 것이 가능하다는 의미이다.(주로 리소스 요청에 사용)<ul><li>ex)<code>https://search.naver.com/search.naver?sm=top hty&amp;fbm=1</code></li></ul></li></ul><ul><li>POST 요청 : 데이터를 Form data에 포함하여 전달 그래서 대부분 우리 눈에 안보이는 요청이다.(주로 로그인에 사용) 예를 들어 설명하자면, 먼저 로그인 페이지가 있다면, 참고로 이 로그인 페이지는 리소스를 요청하는 것이므로 GET 방식이고 로그인 페이지에서 로그인을 하는 행위를 할 경우 이 떄 사용된다.<ul><li>ex) <code>https://www.kangco.com/meber/member_check.asp</code></li></ul></li></ul><p>어떠한 방식으로 해당 웹 페이지가 서버에 요청을 하는지는 <code>개발자 도구의 Network 탭에서 특정 Name을 클릭 후 Request Method를 보면서 확인할 수 있다.</code></p><h3 id="HTML-element-이해하기-tag-attribute-value"><a href="#HTML-element-이해하기-tag-attribute-value" class="headerlink" title="HTML element 이해하기(tag, attribute, value)"></a>HTML element 이해하기(tag, attribute, value)</h3><ul><li><p>HTML(Hyper Text Markup Language)</p><ul><li>웹사이트를 생성하기 위한 언어로 문서와 문서가 링크로 연결되어 있고, tag를 사용하는 언어</li></ul></li><li><p>태그(Tag)란?</p><ul><li>HTML 문서의 기본 블락</li><li><code>&lt;태그명 속성1=&quot;속성값1&quot; 속성2=&quot;속성값2&quot;&gt;Value&lt;/태그명&gt;</code> (Value가 있는 경우)</li><li><code>&lt;태그명 속성1=&quot;속성값1&quot; 속성2=&quot;속성값2/&quot;&gt;</code> (Value가 없는 경우)</li></ul></li></ul><p>크롤링을 단 한번이라도 직접 해보신 분들은 우리가 원하는 값을 추출하기 위해서는 어느 정도의 HTML 지식이 있어야한다. 즉, Value를 추출하기 위해 해당 Value가 포함되어 있는 <code>tag의 구조를 알아야 한다는 것이다.</code> 위의 단순한 tag의 구조는 그런 관점에서 혹시라도 HTML의 구조를 모르시분들을 위해 간단히 설명하고 넘어가는 것이다.</p><h3 id="Requests-모듈"><a href="#Requests-모듈" class="headerlink" title="Requests 모듈"></a>Requests 모듈</h3><ul><li>http request/response를 위한 모듈</li><li>HTTP method를 메소드 명으로 사용하여 request 요청 예)GET, POST</li><li>가장 우리가 흔하게 크롤링을 하는데 사용하는 방식이며, API만 알고 있다면 쉽게 사용할 수 있다!</li></ul>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/09/28/HTTP_method/#disqus_thread</comments>
    </item>
    
    <item>
      <title>colab &amp; Kaggle 연동 및 기초 사용법</title>
      <link>https://heung-bae-lee.github.io/2019/08/01/kaggle_00/</link>
      <guid>https://heung-bae-lee.github.io/2019/08/01/kaggle_00/</guid>
      <pubDate>Thu, 01 Aug 2019 07:26:46 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;Kaggle Korea에서 진행중인 대회에서 Kaggle Kernel을 사용하다 보니 커널이 자꾸 죽는 이유는 도대체 무엇인지… competition에 늦게 참여한 관계로 더 시간이 촉박하기만 한데…. 그래서 google colab으로 바꾸려고 
        
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Kaggle Korea에서 진행중인 대회에서 Kaggle Kernel을 사용하다 보니 커널이 자꾸 죽는 이유는 도대체 무엇인지… competition에 늦게 참여한 관계로 더 시간이 촉박하기만 한데…. 그래서 google colab으로 바꾸려고 생각하였다.</p><p>캐글은 예측모델 및 분석 대회를 하는 플랫폼이다. 개인 및 단체에서 해결하고 싶은 과제와 데이터를 등록하면, 캐글에 가입한 데이터 과학자들이 모델을 개발하고 결과를 등록한다. 예측력을 순위로 하여 가장 좋은 순위에게는 상금도 주워진다. 그만큼 데이터 사이언스에 관한 분들은 모를 수 없는 사이트라고 생각한다.</p><p>Google Colaboratory는 <code>Google Drive + Jupyter Notebook</code>의 기능을 가지고 있으며, <code>Google Drive처럼 협업 가능(동시에 수정 가능)</code>하다고 한다. <a href="https://colab.research.google.com/" target="_blank" rel="noopener">https://colab.research.google.com/</a>로 접속시 사용 가능하다. 무엇보다 가장 좋았던 점은 캐글의 커널은 9시간이 최장 이용시간인 반면에, <code>colab은 12시간</code>이다. 3시간 차이에 얼마나 더 바뀌겠냐라는 분들도 계시 겠지만 GPU가 없는 나에겐 3시간은 엄청난 시간이다.</p><p>더 자세한 사항은 [<a href="https://zzsza.github.io/data/2018/08/30/google-colab/][https://zzsza.github.io/data/2018/08/30/google-colab/" target="_blank" rel="noopener">https://zzsza.github.io/data/2018/08/30/google-colab/][https://zzsza.github.io/data/2018/08/30/google-colab/</a>] 이 블로그를 참조하는 것을 추천한다! 개인적으로 데이터 사이언스에 관해 많은 것에 대해 자세히 다루고 있다고 생각하며 강추한다!(절대 홍보글 아님.)</p><h3 id="구글-드라이브와-Colab-연동"><a href="#구글-드라이브와-Colab-연동" class="headerlink" title="구글 드라이브와 Colab 연동"></a>구글 드라이브와 Colab 연동</h3><ul><li>매번 session이 끊기거나 종료되면 이 작업을 해주어야 한다. 그래도 kaggle 보단 내 컴퓨터에선 덜 끊긴다. 먼저, 구글 드라이브와 연동을 시키는 이유는 로컬에서 Colab working directory로 파일을 업로드하게 되면 차후 다시 접속할 때 다시 업로드를 해주어야하지만 구글 드라이브에선 바로 읽을 수 있기 때문이다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from google.colab import auth</span><br><span class="line">auth.authenticate_user()</span><br><span class="line"></span><br><span class="line"><span class="comment"># colab에서 drive란 폴더를 만든 후, 우리 구글 드라이브의 root와 drive 폴더를 연결(mount)</span></span><br><span class="line">from google.colab import drive</span><br><span class="line">drive.mount(<span class="string">'/content/gdrive'</span>)</span><br></pre></td></tr></table></figure><h3 id="구글-드라이브와-로컬-연동"><a href="#구글-드라이브와-로컬-연동" class="headerlink" title="구글 드라이브와 로컬 연동"></a>구글 드라이브와 로컬 연동</h3><ul><li>파일을 하나씩 업로드하지 말고 대량의 파일을 한꺼번에 업로드하고 싶은 경우</li><li><code>[BackupAndSync](https://www.google.com/drive/download/)</code>를 사용해 로컬과 구글 드라이브를 연동<ul><li>1) 위 링크를 클릭해 백업 및 동기화 다운로드</li><li>2) InstallBackupAndSync.dmg라는 파일을 클릭한 후, (열리지 않으면 우클릭 후 열기) 프로그램 설치</li><li>3)맥북 환경이 한글이신 분은 Google에서 백업 및 동기화라는 응용 프로그램이 추가됨(이것도 실행이 안되면 클릭 후 실행)</li><li>환경 설정에서 동기화할 폴더 선택 (단, 크기가 큰 파일은 동기화 시간이 오래 걸릴 수 있음)</li></ul></li></ul><h3 id="Kaggle-연동하기"><a href="#Kaggle-연동하기" class="headerlink" title="Kaggle 연동하기"></a>Kaggle 연동하기</h3><h4 id="1-Kaggle-beta-API-Json-Key-다운"><a href="#1-Kaggle-beta-API-Json-Key-다운" class="headerlink" title="- 1) Kaggle beta API Json Key 다운"></a>- 1) Kaggle beta API Json Key 다운</h4><pre><code>- Kaggle - My Account - Dataset 옆에 있는 …을 클릭한 후, Account로 이동- 하단에 API 부분에 Create New API Token을 클릭하면 Json Key가 다운로드 됨- 이 Json 키를 매번 Colab에서 올려서 할 수도 있지만, 더 편하게 사용하고 싶어서 Google Storage에 Json 파일을 올리고, 거기서 키를 복사해오는 방법으로 진행합니다</code></pre><h4 id="2-Google-Storage에-Json-Key-저장"><a href="#2-Google-Storage에-Json-Key-저장" class="headerlink" title="- 2) Google Storage에 Json Key 저장"></a>- 2) Google Storage에 Json Key 저장</h4><pre><code>- Google Storage로 이동한 후, Storage 버킷 선택 (버킷이 없다면 생성!)- Colab에서 아래 명령어 입력</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from google.colab import auth</span><br><span class="line">auth.authenticate_user()</span><br><span class="line"></span><br><span class="line">!mkdir -p ~/.kaggle</span><br><span class="line">!mv ./kaggle.json ~/.kaggle/</span><br><span class="line">!chmod 600 ~/.kaggle/kaggle.json</span><br></pre></td></tr></table></figure><h3 id="우선-여기까지-내일-다시-시작합니다"><a href="#우선-여기까지-내일-다시-시작합니다" class="headerlink" title="우선 여기까지! 내일 다시 시작합니다!!!!!"></a>우선 여기까지! 내일 다시 시작합니다!!!!!</h3>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/08/01/kaggle_00/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture10-Recurrent Neural Networks</title>
      <link>https://heung-bae-lee.github.io/2019/07/29/cs231n_10/</link>
      <guid>https://heung-bae-lee.github.io/2019/07/29/cs231n_10/</guid>
      <pubDate>Mon, 29 Jul 2019 07:22:55 GMT</pubDate>
      <description>
      
      </description>
      
      
      <comments>https://heung-bae-lee.github.io/2019/07/29/cs231n_10/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[수리통계학] 나혼자 정리하는 통계생의 수리통계학 00</title>
      <link>https://heung-bae-lee.github.io/2019/07/29/Statistics_00/</link>
      <guid>https://heung-bae-lee.github.io/2019/07/29/Statistics_00/</guid>
      <pubDate>Mon, 29 Jul 2019 07:12:38 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;먼저, 이 글은 data science라는 분야를 공부하며 원래 통계학을 전공했던 나였지만 학부과정에서 배웠던 그리고 부끄럽지만 석사 때 배웠다고 기억하고 있는 조각들을 모아 수리통계학을 간단히 정리하기 위해 쓰는 글이다.&lt;/p&gt;
&lt;h2 id=&quot;
        
      
      </description>
      
      
      <content:encoded><![CDATA[<p>먼저, 이 글은 data science라는 분야를 공부하며 원래 통계학을 전공했던 나였지만 학부과정에서 배웠던 그리고 부끄럽지만 석사 때 배웠다고 기억하고 있는 조각들을 모아 수리통계학을 간단히 정리하기 위해 쓰는 글이다.</p><h2 id="확률과-확률분포"><a href="#확률과-확률분포" class="headerlink" title="확률과 확률분포"></a>확률과 확률분포</h2><p>여러 가지 조사 연구들은 동일한 조건에서의 반복 실험이 대체적으로 표준이 된다는 것이 특징이다. 예를 들어, 의학 연구에서는 복용된 약의 효과에 관심이 있을 것이다. <code>우리가 어떤 결론을 내리기 까지 그에 따른 근거를 뒷받침하기 위한 정보를 얻을 수 있는 유일한 방법은 실험이다.</code> 이런 실험을 통해 얻은 실험값들은 예측할 수 없다는 것이 실험의 특성이다.</p><p>여기서 통계를 공부하다 보면 제일 먼저 알게되는 sample space를 정의할 것이다.</p><ul><li>sample space : 같은 조건에서 반복할 수 있는 실험에서 실현 가능한 결과의 집합</li></ul>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/07/29/Statistics_00/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture09-CNN_Architectures</title>
      <link>https://heung-bae-lee.github.io/2019/07/28/cs231n_09/</link>
      <guid>https://heung-bae-lee.github.io/2019/07/28/cs231n_09/</guid>
      <pubDate>Sun, 28 Jul 2019 03:43:10 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;img src=&quot;/image/cs231n_09_00.png&quot; alt=&quot;그림 00&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;LeNet&quot;&gt;&lt;a href=&quot;#LeNet&quot; class=&quot;headerlink&quot; title=&quot;LeNet&quot;&gt;&lt;/a&gt;LeNet&lt;/h3&gt;&lt;ul&gt;
&lt;
        
      
      </description>
      
      
      <content:encoded><![CDATA[<p><img src="/image/cs231n_09_00.png" alt="그림 00"></p><h3 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h3><ul><li>산업에 아주 성공적으로 적용된 최초의 ConvNet이다.</li></ul><ul><li>이미지를 입력으로 받아 Stride = 1인 5x5필터를 거치고 몇 개의 Conv Layer와 Pooling Layer를 거친다. 그리고 마지막 출력 노드 전에 Fully Connected Layer가 붙는다.</li></ul><ul><li>엄청 간단한 모델이지만 숫자 인식에서 엄청난 성공을 거두었다.</li></ul><p><img src="/image/cs231n_09_01.png" alt="그림 01"></p><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><ul><li>2012년에 등장한 최초의 Large scale CNN이며 Image Classification Benchmark의 우승 모델이다. ConvNet 연구의 부흥을 일으킨 장본인이다. 수년 전까지 대부분의 CNN 아키텍쳐의 베이스 모델로 사용되어 왔다. AlexNet은 다양한 Task의 transfer learning에 많이 사용되었다.</li></ul><ul><li>AlexNet은 기본적으로 <code>conv - pool - normalization 구조가 2번 반복된다. 그리고 conv layer가 조금 더 붙고 (CONV 3,4,5) 그 뒤에 pooling layer가 있다.(Max POOL3) 그리고 마지막에는 Fully connected layer가 몇 개 붙는다.(FC 6,7,8)</code> 생긴 것만 봐서는 기존의 LeNet과 상당히 유사하며 layer만 늘어 났다고 생각이 들 것이다. AlexNet은 5개의 Conv Layer와 2개의 FC-Layer(마지막 FC Layer 전까지)로 구성된다.</li></ul><ul><li><p><code>다른 Conv Net의 다이어그램과 유사하긴 하지만 한 가지 차이점이 있다. 모델이 두개로 나누어져서 서로 교차한다는 것이다.</code> AlexNet을 학습할 당시에 3GB GTX850으로 학습시켰다. 그래서 전체 Layer를 GPU에 다 넣을 수 없어서 분산 시켜 넣을 수 밖에 없었다. 각 GPU가 모델의 뉴런과 Feature Map을 반반씩 나눠가진다. Conv 1,2,4,5를 살펴보면 같은 GPU 내에 있는 Feature Map만 사용할 수 있다. 즉, 전체 96개의 feature Map을 볼 수 없다. 그래서 다이어그램을 보면 각 Conv Layer의 Depth가 48인 것이다. Conv 3, FC 6,7,8를 보면 이 Layer들은 이전 계층의 전체 Feature Map과 연결되어 있다. 이 Layer들에서는 GPU간의 통신을 하기 때문에 이전 입력 Layer의 전체 Depth를 전부 가져올 수 있는 것이다.</p></li><li><p>AlexNet 논문의 아키텍쳐와 관련한 조그만 이슈는 그림을 자세히 보면 첫 Layer가 224x224라고 되어 있는데, 실제 입력은 227x227이다.</p></li></ul><h4 id="질문"><a href="#질문" class="headerlink" title="질문"></a>질문</h4><ul><li>Pooling layer에는 파라미터가 없는가?<ul><li>파라미터는 우리가 학습시키는 가중치이다. Conv Layer에는 학습할 수 있는 가중치가 있다. 반면 Pooling의 경우에는 가중치가 없고 그저 특정 지역에서 큰 값을 뽑아내는 역할만 한다. 따라서 학습시킬 파라미터가 없는 것이다.</li><li><code>각각의 Layer의 파라미터 사이즈를 계산해 보자!!!!</code></li></ul></li></ul><h3 id="ZFNet"><a href="#ZFNet" class="headerlink" title="ZFNet"></a>ZFNet</h3><ul><li>2013년 우승 모델이며 AlexNet의 하이퍼 파라미터를 개선한 모델이다.</li><li>AlexNet과 같은 Layer 수이고, 기존의 구조도 같다. <code>다만, stride size, 필터 수 같은 하이퍼 파라미터를 조절해서 AlexNet의 Error rate를 좀 더 개선시켰다.</code></li></ul><p>앞으로 언급할 두가지 모델은 <code>Batch normalization이 없던 시절</code>이었기 때문에 깊은 모델을 학습시키는 일이 어려웠다. 그렇기에 깊은 모델을 수렴시키기 위해서 각종 테크닉을 사용해야 했다. 먼저, VGG는 초기에 11 Layer이었는 11 Layer가 모델이 잘 수렴하는 한계였기 때문이다. 그리고 나서 11 Layer 중간에 Layer를 무작위로 추가해서 VGG-16, VGG-19를 학습시켰다. GoogLeNet의 경우에는 auxiliary classifiers를 도입하여 단지 네트워크의 초기 Layer에 gradient를 직접 흘려 보내기 위한 수단이었다.(성능을 올리기 위해 도입한것이 아니다! 그리고 Batch Norm이 있다면 굳이 이런식의 테크닉들은 더이상 필요치 않다!!!)</p><p><img src="/image/cs231n_09_02.png" alt="그림 02"></p><h3 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h3><ul><li><p>훨씬 더 깊어졌고 더 작은 필터를 사용한다. 더 깊게 쌓이므로써 Non-Linearity를 더 추가 할 수 있고 파라미터 수도 더 적어지게 되었다.</p><ul><li>AlexNet에서는 8개의 Layer -&gt; VGGNet 16~19개의 Layer</li><li>3x3필터만 사용 (이웃픽셀을 포함할 수 있는 가장 작은 필터)<ul><li>이유 : <code>필터의 크기가 작으면 파라미터의 수가 더 적어서 Depth를 더 키울 수 있다.</code> 3x3 필터를 여러 개 쌓은 것은 결국 7x7 필터를 사용하는 것과 실질적으로 동일한 Receptive Filter를 가지는 것이다.</li></ul></li><li>작은 필터를 유지해 주고 주기적으로 Pooling을 수행하면서 전체 네트워크를 구성하게 된다.</li><li><code>fc7 은 4096 사이즈의 Layer인데 아주 좋은 feature representation을 가지고 있는 것으로 알려졌으며 다른 데이터에서도 feature 추출이 잘되며 다른 Task에서도 일반화 능력이 뛰어난 것으로 알려져있다.</code>    </li></ul></li><li><p>VGG19의 경우 VGG16과 유사한 아키텍쳐이지만 Conv Layer가 조금 더  추가 되었다. VGG19가 아주 조금 더 좋다. 그러나 보통 VGG16을 더 많이 사용한다. AlexNet에서 처럼 모델 성능을 위해서 앙상블 기법을 사용했다.</p></li></ul><h4 id="질문-3x3인-Stride가-1인-필터-3개를-쌓게-되면-실질적인-Receptive-Field가-어떻게-될까"><a href="#질문-3x3인-Stride가-1인-필터-3개를-쌓게-되면-실질적인-Receptive-Field가-어떻게-될까" class="headerlink" title="질문) 3x3인 Stride가 1인 필터 3개를 쌓게 되면 실질적인 Receptive Field가 어떻게 될까?"></a>질문) 3x3인 Stride가 1인 필터 3개를 쌓게 되면 실질적인 Receptive Field가 어떻게 될까?</h4><ul><li><code>Receptive Field은 필터가 한번에 볼 수 있는 입력의 Spatial area이다.</code></li><li>첫번째 Layer의 Receptive Field는 3x3이다. 두 번째 Layer의 경우는 각 뉴런이 첫 번째 Layer 출력의 3x3 만큼을 보게 될 것이다. 그리고 3x3 중에 각 사이드는 한 픽셀씩 더 볼 수 있게 된다. 따라서 두번째 Layer의 경우는 실제로 5x5의 receptive filed를 가지게 된다. 3번째 Layer의 경우 2번째 Layer의 3x3을 보게된다. 그리고 이 과정을 피라미드처럼 그려보면 입력 Layer의 7x7을 보게 되는 것이다.<code>따라서 실질적인 Receptive Field는 여기에서 7x7이 된다. 하나의 7x7 필터를 사용하는 것과 동일하다.</code></li></ul><h4 id="질문-하나의-Conv-Layer-내에-여러개의-필터가-존재하는-이유는"><a href="#질문-하나의-Conv-Layer-내에-여러개의-필터가-존재하는-이유는" class="headerlink" title="질문) 하나의 Conv Layer 내에 여러개의 필터가 존재하는 이유는?"></a>질문) 하나의 Conv Layer 내에 여러개의 필터가 존재하는 이유는?</h4><ul><li>각 필터가 존재하는 이유는 서로 다른 패턴을 인식하기 위해서라고 할 수 있다. 각 필터는 각각의 Feature Map을 만들게 된다.</li></ul><h4 id="질문-Localization은-무엇인가"><a href="#질문-Localization은-무엇인가" class="headerlink" title="질문) Localization은 무엇인가?"></a>질문) Localization은 무엇인가?</h4><ul><li>task 중에서 예를 들면 “이미지에 고양이가 있는가?”를 분류하는 것 뿐만 아니라 정확히 고양이가 어디에 있는지 네모박스를 그리는 것이다. Detection은 이미지 내에 다수의 객체가 존재할 수 있다. 그에 반해 localization은 이미지에 객체가 하나만 있다고 가정하고 이미지를 분류하고 추가적으로 네모박스도 쳐야한다.</li></ul><p><img src="/image/cs231n_09_03.png" alt="그림 03"></p><h4 id="질문-네트워크가-깊어질수록-Layer의-필터-갯수를-늘려야-하는지-Channel-Depth를-늘려야-하는지"><a href="#질문-네트워크가-깊어질수록-Layer의-필터-갯수를-늘려야-하는지-Channel-Depth를-늘려야-하는지" class="headerlink" title="질문) 네트워크가 깊어질수록 Layer의 필터 갯수를 늘려야 하는지?(Channel Depth를 늘려야 하는지)"></a>질문) 네트워크가 깊어질수록 Layer의 필터 갯수를 늘려야 하는지?(Channel Depth를 늘려야 하는지)</h4><ul><li>디자인하기 나름이고 반드시 그럴 필요는 없다. <code>하지만, 실제로 사람들이 Depth를 많이 늘리는 경우가 많다. Depth를 늘리는 이유 중 하나는 계산량을 일정하게 유지시키기 위해서이다. 왜냐하면 보통 네트워크가 깊어질수록 각 Layer의 입력을 Down sampling하게 된다. 즉, 네트워크를 통해 나가면서 점점 정보를 잃어나가는 현상이 발생될 수 있다는 것이다. 그러므로 Spatial area가 작아질수록 필터의 depth를 조금씩 늘려주게 된다. Width나 Height가 작아지기 때문에 Depth를 늘려도 부담이 없다.</code></li></ul><h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><ul><li>2014년 Classification Challenge에서 우승한 모델이다. 22개의 Layer를 가진 깊은 네트워크이다. <code>가장 중요한 것은 효율적인 계산에 관한 그들의 특별한 관점이 있다는 것과 높은 계산량을 아주 효율적으로 수행하도록 네트워크를 디자인했다는 점이다.</code></li><li>“a good local network typology”를 디자인 하고 싶었다. 그리고 “network within a network”라는 개념으로 local topology를 구현했고 이를 쌓아올렸다. Inception module을 여러개 쌓아서 만든다. 또한 <code>파라미터를 줄이기 위해 FC-Layer를 사용하지 않는다.</code> 전체 파라미터 수가 60M인 AlexNet에 비해 GoogLeNet은 전체 파라미터 수가 5M 정도이다.</li></ul><p><img src="/image/cs231n_09_04.png" alt="그림 04"></p><ul><li><code>Inception Module 내부에는 동일한 입력을 받는 서로 다른 다양한 필터들이 병렬로 존재한다.</code> 이전 Layer의 입력을 받아서 다양한 Conv 연산을 수행 한 후 각 Layer에서 각각의 출력 값들이 나온다. 그 출력들을 모두 Depth 방향으로 합친다.(concatenate) 그렇게 합치면 하나의 tensor로 출력이 결정되고 이 하나의 출력을 다음 레이어로 전달하는 것이다.</li></ul><h3 id="질문-이러한-다양한-연산을-수행하고-이를-하나로-합쳐주는-아주-단순한-방식이-갖는-문제점은-무엇일까"><a href="#질문-이러한-다양한-연산을-수행하고-이를-하나로-합쳐주는-아주-단순한-방식이-갖는-문제점은-무엇일까" class="headerlink" title="질문) 이러한 다양한 연산을 수행하고 이를 하나로 합쳐주는 아주 단순한 방식이 갖는 문제점은 무엇일까?"></a>질문) 이러한 다양한 연산을 수행하고 이를 하나로 합쳐주는 아주 단순한 방식이 갖는 문제점은 무엇일까?</h3><ul><li><p>계산 비용에 문제가 있다. 1x1 conv의 경우 입력에 맞춰 depth는 256이다. 그리고 128개의 필터 하나다. 그리고 128개의 필터 하나 당 28x28 Feature map을 생성하게 될 것이다. 이런식으로 다른 Layer의 출력값을 계산해 보면 다음 그림과 같을 것이다. 참고로 이런 계산이 나온 이유는 <code>spatial dimension을 유지하기 위해서 zero padding을 하였기 때문</code>이다.<code>Stride를 잘 조절해서 Spatial dimension를 유지하면 입력과 출력의 크기는 같게 된다.</code> 즉 28x28은 동일하고 depth가 점점 쌓이게 된다는 것을 의미한다. 그림에서는 최종적으로 28 x 28 x 672 가 된다. Inception module의 입력은 28x28x256 이었으나 출력은 28x28x672이 된 것이다. Spatial dimension은 변하지 않았지만 depth가 엄청나게 불어난 것이다. <code>연산량이 많다는 것이 문제이며, Pooling Layer는 Depth를 그대로 유지하기 때문에 문제를 악화 시킨다.</code></p></li><li><p>위와 같은 문제를 해결하기 위한 key insight <code>bottleneck layer를 이용하는 것이다. Conv 연산을 수행하기에 앞서 입력을 더 낮은 차원으로 보내는 것이다.(depth를 더 낮은 차원으로 projection하는 것) input feature map들 간의 선형 결합(linear combination)이라고 할 수 있다.</code></p></li></ul><p><img src="/image/cs231n_09_05.png" alt="그림 05"><br><code>주요 아이디어는 바로 입력의 depth를 줄이는 것이다.</code>각 Layer의 계산량은 1x1 conv를 통해 줄어든다.</p><h4 id="질문-1x1-Conv를-수행하면-일부-정보손실이-발생하지-않는다"><a href="#질문-1x1-Conv를-수행하면-일부-정보손실이-발생하지-않는다" class="headerlink" title="질문) 1x1 Conv를 수행하면 일부 정보손실이 발생하지 않는다?"></a>질문) 1x1 Conv를 수행하면 일부 정보손실이 발생하지 않는다?</h4><ul><li>정보 손실이 발생할 순 있지만 동시에 redundancy가 있는 imput features를 선형결합 한다고 볼 수 있다. 1x1 conv로 선형결합을 하고 non-Linearity(ReLU같은)를 추가하면 네트워크가 더 깊어지는 효과도 있다. 일반적으로 1x1 con를 추가하면 여러모로 도움이 되고 더 잘 동작한다.</li></ul><p><img src="/image/cs231n_09_06.png" alt="그림 06"><br>위의 그림에서 파란색 네모 박스는 추가시킨 보조 분류기(auxiliary classifier)이다. 그 구조는 Average pooling과 1x1 conv가 있고 FC-layer도 몇개 붙는 우리가 알고있는 작은 네트워크들이다. SoftMax로 1000개의 ImageNet class를 구분한다. 또한 <code>네트워크가 깊기 때문애 이곳에서도 loss를 계산하고 추가적인 gradient를 얻을 수 있고 따라서 중간 Layer의 학습을 도울 수 있다.</code></p><h4 id="질문-보조분류기에서-나온-결과를-최종-분류-결과에-이용할-수-있는가"><a href="#질문-보조분류기에서-나온-결과를-최종-분류-결과에-이용할-수-있는가" class="headerlink" title="질문) 보조분류기에서 나온 결과를 최종 분류 결과에 이용할 수 있는가??"></a>질문) 보조분류기에서 나온 결과를 최종 분류 결과에 이용할 수 있는가??</h4><ul><li>GoogLeNet 학습 시, 각 보조분류기의 Loss를 모두 합친 평균을 계산한다. 아마도 도움이 될 것이다.</li></ul><h4 id="질문-bottleneck-layer를-구성할-때-1x1-conv-말고-다른-방법으로-차원을-축소시켜도-되는가"><a href="#질문-bottleneck-layer를-구성할-때-1x1-conv-말고-다른-방법으로-차원을-축소시켜도-되는가" class="headerlink" title="질문) bottleneck layer를 구성할 때 1x1 conv 말고 다른 방법으로 차원을 축소시켜도 되는가??"></a>질문) bottleneck layer를 구성할 때 1x1 conv 말고 다른 방법으로 차원을 축소시켜도 되는가??</h4><ul><li>여기에서 1x1 conv를 쓴 이유는 차원 축소의 효과도 있고 다른 Layer들 처럼 conv Layer이기 때문이다. <code>차원 축소 과정에서 이전의 feature map과 연관이 있는지 학습하려면 전체 네트워크를 Backprop으로 학습시킬 수 있어야 한다.</code> 네트워크가 엄청 깊은 경우에서는 gradient 신호가 점점 작아지게 되고 결국에는 0에 가깝게 될 수 있다. 그렇기 때문에 보조 분류기를 이용해서 추가적인 gradient 신호를 흘려준다. 이 때 backprop은 각 보조분류기 별로 실행하는 것이 아닌 네트워크 전체가 한번에 작동시킨다.</li></ul><h4 id="질문-각-Layer가-가중치를-공유하는가-아닌가"><a href="#질문-각-Layer가-가중치를-공유하는가-아닌가" class="headerlink" title="질문) 각 Layer가 가중치를 공유하는가 아닌가??"></a>질문) 각 Layer가 가중치를 공유하는가 아닌가??</h4><ul><li>모든 Layer를 가중치를 공유하지 않는다.</li></ul><h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p><img src="/image/cs231n_09_08.png" alt="그림 07"></p><ul><li>2015년도 우승 모델이며, 혁명적으로 네트워크의 깊이가 깊어진 모델이다.(152개의 Layer)</li><li><code>residual connection</code> 이라는 방법을 사용한다. residual block들을 쌓아올리는 구조이다.<ul><li>short connection과 residual block이 도입된 모델</li></ul></li><li><code>모델 Depth가 50이상일 때 Bottleneck Layers를 도입</code></li><li>‘CNN을 깊고 더 깊게 쌓게 되면 어떤 일이 발생할까?’라는 의문에서 부터 시작된다. 예를 들어, VGG에 conv pool Layer를 깊게만 쌓는다고 과연 성ㄴ능이 더 좋아지는 것이 맞는지를 보자면 아니라는 것이다. 다음 그림에서 56-Layer와 20-Layer를 비교해서 설명하고 있다. 우리는 56-Layer는 상대적으로 더 많은 파라미터를 가지고 있기에 20-Layer보다 좀더 overfitting이 일어날 확률이 높다고 생각할 수 있을 것이다. 허나 우리 예상처럼 test error는 56-layer가 더 낮지만 training error 또한 더 낮기에 <code>overfitting이 원인이 아니라는 것을 확실히 알 수 있다.</code></li><li><code>ResNet 저자들아 내린 가설은 더 깊은 모델 학습 시 Optimization에 문제가 생긴다는 것</code>이다. 그렇다면 <code>모델이 더 깊다면 적어도 더 얕은 모델만큼은 성능이 나와야 하지 않는가</code>라는 생각으로 인해 더 얕은 모델의 가중치를 깊은 모델의 일부 Layer에 복사한다. 그리고 나머지 Layer는 identity mapping을 하여 Deeper Model의 학습이 제대로 안되더라도 적어도 shallower Model 만큼의 성능을 보장하게끔 디자인 한다. 이런 아이디어를 모델에 적용시키기 위해 <code>가중치가 없으면 입력을 identity mapping을 시켜 출력으로 내보내는 Skip Connection</code>을 도입하게 된다. <code>실제 Layer는 변화량(delta)만 학습하면 된다. 입력 X에 대한 잔차(residual)이라고 할 수 있다.</code></li></ul><h4 id="질문-Layer의-출력과-Skip-Connection의-출력이-같은-차원인가"><a href="#질문-Layer의-출력과-Skip-Connection의-출력이-같은-차원인가" class="headerlink" title="질문) Layer의 출력과 Skip Connection의 출력이 같은 차원인가?"></a>질문) Layer의 출력과 Skip Connection의 출력이 같은 차원인가?</h4><ul><li>그렇다. 두 경로의 출력 값 모두 같은 차원이다. 일반적으로는 같은 차원이 맞지만, 그렇지 않은 경우에는 Depth-wise padding으로 차원을 맞춰준다.</li></ul><p><img src="/image/cs231n_09_07.png" alt="그림 08"></p><h4 id="질문-Layer의-출력인-Residual의-의미는-무엇인가"><a href="#질문-Layer의-출력인-Residual의-의미는-무엇인가" class="headerlink" title="질문) Layer의 출력인 Residual의 의미는 무엇인가?"></a>질문) Layer의 출력인 Residual의 의미는 무엇인가?</h4><ul><li><p>아래 그림을 보면, 전체 출력 값은 F(x)+X 이고, F(x)는 Layer의 출력 값이다. X는 그저 입력값이다. 왼쪽의 평범한 네트워크는 H(x)를 학습시키고 있지만 아주 깊은 네트워크에서는 H(x)를 학습시키는 것은 너무 어렵다. 그래서 <code>ResNet의 아이디어는 H(x)=F(x)+x이므로 F(x)를 학습시켜보면 어떨까라는 것이다. 즉, H(x)를 직접 배우는 대신에 X에 얼마의 값을 더하고 빼야할까를 배우는 것이 쉬울것이라고 생각한 것이다. 이것은 단지 가설일 뿐이지만 가설이 참이라면 모델의 일부가 학습된 shallow layers이고 나머지 layer들은 identity로 구성되어진 상황에서는 잘 동작할 것이다. 이는 대부분의 layer가 잘 동작하려면 layer의 출력이 identity에 가까워야 할지 모른다는 것을 암시한다. 이 때문에 Identity(Input) +  변화량(delta)만 학습시키면 된다.</code> 예를들어, Output = Input(Identity)이어야만 하는 상황이면 F(x) = 0 이 되면 그만이다. 이는 상대적으로 학습시키기 쉽다고 볼 수 있다.</p></li><li><p><code>ResNet에서는 Layer의 출력은 입력 + residual block의 출력이다.</code> 우선 residual block의 가중치가 0이면 이 block은 identity mapping을 한다. <code>이러한 속성으로 모델이 필요없는 Layer를 사용하지 않도록 학습하는데 아주 유용하다.</code> ResNet의 관점에서 L2 Regularization을 해석해 볼 수도 있다. Layer에 L2 Regularization을 추가시키면 L2는 모든 파라미터가 0이 되도록 노력할 것이다. 사실 CNN Architectures의 관점에서 보면 모든 파라미터가 0이면 이상하다. 하지만 ResNet의 관점에서는 파라미터를 0으로 만드려는 속성은 모델이 불필요한 Layer를 사용하지 않도록 해줄 수 있다.</p></li></ul>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/07/28/cs231n_09/#disqus_thread</comments>
    </item>
    
    <item>
      <title>내가 정리하는 C/C++/자료구조_00</title>
      <link>https://heung-bae-lee.github.io/2019/07/24/data_structure_00/</link>
      <guid>https://heung-bae-lee.github.io/2019/07/24/data_structure_00/</guid>
      <pubDate>Wed, 24 Jul 2019 08:03:14 GMT</pubDate>
      <description>
      
        
        
          &lt;h3 id=&quot;개발환경-구축하기&quot;&gt;&lt;a href=&quot;#개발환경-구축하기&quot; class=&quot;headerlink&quot; title=&quot;개발환경 구축하기&quot;&gt;&lt;/a&gt;개발환경 구축하기&lt;/h3&gt;&lt;h4 id=&quot;C와-C&quot;&gt;&lt;a href=&quot;#C와-C&quot; class=&quot;headerli
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h3 id="개발환경-구축하기"><a href="#개발환경-구축하기" class="headerlink" title="개발환경 구축하기"></a>개발환경 구축하기</h3><h4 id="C와-C"><a href="#C와-C" class="headerlink" title="C와 C++"></a>C와 C++</h4><p>1) C++는 기본적으로 C의 기능을 확장한 형태의 프로그래밍 언어이다.<br>2) 따라서 C 언어의 기능을 포함하고 있다는 점에서 C++프로젝트로 .C 확장자를 갖는 파일을 생성하여 코딩해도 정상적으로 동작한다.</p><p>개발환경 구축하기</p><ul><li><p>나는 개인적으로 IDE(Integrated Development Environment) 중에서 Atom을 이미 설치하고 있기에 따로 대표적인 Visual Studio를 설치하진 않았다.</p></li><li><p>Atom에서는 따로 <code>gpp-compiler</code> 라는 패키지를 설치해주면 끝난다! 단축키 또한 자신이 커스터마이징 할 수 있는데, <code>나는 default인 f5가 compile f6이 디버깅으로 되어있는 상태에서 사용할 것이다.</code></p></li></ul><p><a href>Development_environment</a></p><ul><li>전통적인 프로그램은 전처리기 -&gt; 컴파일러 -&gt; 링커를 거쳐 실행파일로 만들어진다.</li></ul><p>역시! 모든 언어의 기초를 배울때 하는 Hello World를 언급하며 시작해보자!</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;stdio.h&gt;</span></span><br><span class="line"></span><br><span class="line">int main(void) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Hello world\n"</span>);</span><br><span class="line">    // system(<span class="string">"pause"</span>);</span><br><span class="line">    system( <span class="string">"read -n 1 -s -p \"Press any key to continue...\""</span> );</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>명령문 하나하나씩 설명을 하자면 처음, #include 명령어를 이용해 다양한 라이브러리를 불러 올 수 있다. 위에서 불러온 <code>stdio.h</code>(standard io)는 여러 기본적인 기능을 포함하고 있지만 그 중 대표적으로 위에서 사용한 printf가 있다.<code>main</code>함수는 다양한 함수가 사용 될 수 있겠지만 처음 시작할 때는 main함수 이후에 사용한다. 또한 가장 큰 특징은 <code>함수는 반환값이 없을 수도 있지만 main 함수에서는 항상 0을 반환하는 것이 일반적이다.</code> 나와 같이 R과 python으로 프로그래밍을 배운 사람이라면 ;이 낯설을 것이다. C/C++에서는 <code>하나의 명령어가 끝났음을 알리기 위해 ;을 붙인다.</code> 위의 명령 프롬프트에서 pause 명령어를 실행시키면 키보드를 입력 전까지 대기하는 기능을 사용할 수 있다. system 함수를 이용하여 운영체제의 기본적인 기능을 이용할 수 있다. 허나, 나의 mac북은 window의 프롬프트 창과는 다른 운영체제이므로 당연히 pause가 걸리지 않는다! 실행하면 찾을 수 없는 명령어라고 나오므로 약간의 편법으로 구사할 수 있을 것 같다! 혹시라도 mac에서 pause를 걸려한다면 저런식으로 만들어 보는 방법도 있다.</p>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/07/24/data_structure_00/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture08-Deep learning Software</title>
      <link>https://heung-bae-lee.github.io/2019/07/23/cs231n_08/</link>
      <guid>https://heung-bae-lee.github.io/2019/07/23/cs231n_08/</guid>
      <pubDate>Tue, 23 Jul 2019 05:13:30 GMT</pubDate>
      <description>
      
        
        
          &lt;h4 id=&quot;GPU&quot;&gt;&lt;a href=&quot;#GPU&quot; class=&quot;headerlink&quot; title=&quot;GPU&quot;&gt;&lt;/a&gt;GPU&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Graphics card 또는 Graphics Processing Unit이라고 하는데 결국엔 우리가 아는 
        
      
      </description>
      
      
      <content:encoded><![CDATA[<h4 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h4><ul><li>Graphics card 또는 Graphics Processing Unit이라고 하는데 결국엔 우리가 아는 사실 처럼 computer graphics를 랜더링하기 위해 더 와닿게 말하자면 게임을 더 최적의 환경에서 하기 위해 만들어 졌다고 할 수 있다.</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center"># Cores</th><th style="text-align:center">Clock speed</th><th style="text-align:center">Memory</th><th style="text-align:center">Price</th></tr></thead><tbody><tr><td style="text-align:center">CPU</td><td style="text-align:center">4</td><td style="text-align:center">4.4 GHz</td><td style="text-align:center">Shared with system</td><td style="text-align:center">$339</td></tr><tr><td style="text-align:center">CPU</td><td style="text-align:center">10</td><td style="text-align:center">3.5 GHz</td><td style="text-align:center">Shared with system</td><td style="text-align:center">$1723</td></tr><tr><td style="text-align:center">GPU</td><td style="text-align:center">3840</td><td style="text-align:center">1.6 GHz</td><td style="text-align:center">12GB GDDR5X</td><td style="text-align:center">$1200</td></tr><tr><td style="text-align:center">GPU</td><td style="text-align:center">1920</td><td style="text-align:center">1.68 GHz</td><td style="text-align:center">8GB GDDR5</td><td style="text-align:center">$399</td></tr></tbody></table></div><ul><li><p>위의 표에서 볼 수 있듯이 CPU의 경우 core의 수가 적다. GPU는 CPU보다 훨씬 더 많은 core를 가지고 있지만 각각의 코어가 더 느린 clock speed에서 동작하며 그 코어들이 CPU처럼 독립적으로 동작하지 않으며 많은 일을 처리할 수 없다. GPU는 코어마다 독립적인 테스크가 있는 것이 아니라 많은 코어들이 하나의 테스크를 병렬적으로 수행한다. <code>GPU의 코어의 수가 많다는 것은 어떤 테스크가 있을 때 그 테스크에 대해 병렬로 수행하기 아주 적합하다는 것을 알 수 있다.</code></p></li><li><p>CPU에도 캐시가 있지만 비교적 작다. 대부분의 memory는 RAM에서 끌어다 쓴다. 실제 RAM과 GPU간의 통신은 상당한 보틀넥을 초래한다. 그렇기 때문에 GPU는 보통 RAM이 내장되어 있다. GPU는 내장되어있는 메모리와 코어 사이의 캐싱을 하기 위한 일종의 다계층 캐싱 시스템을 가지고 있다. 이는 CPU의 캐싱구조와 매우 유사하다.</p></li><li><p>CPU는 범용처리에 적합하고, GPU는 병렬처리에 더 특화되어 있다. <code>GPU에서 정말 잘 동작하고 아주 적합한 알고리즘은 바로 행렬곱 연산이다.</code></p></li><li><p><code>실제로 GPU로 학습을 할 때 생기는 문제 중 하나는 바로 Model과 Model의 가중치는 전부 GPU RAM에 상주하고 있는 반면에 Train data는 하드드라이브(SSD)에 있다는 것이다.</code> 때문에 Train time에 디스크에 디스크에서 데이터를 읽어들이는 작업을 세심하게 신경쓰지 않으면 보틀넥이 발생할 수 있다. 즉,<code>GPU는 forward/backward 가 아주 빠른 것은 사실이지만, 디스크에서 데이터를 읽어들이는 것이 보틀넥(병목현상)이 되는 것이다.</code> 이러한 문제를 해결하기 위한 해결책 중 하나는 <code>데이터셋이 작다면 데이터 전체를 RAM에 올려 놓는 것이다. 또는 데이터셋이 작지 않더라도, 서버에 RAM 용량이 크다면 가능 할 수도 있을 것이다. 또한 기본적으로 HDD 대신 SSD를 사용하는 것이 좋다. 또 다른 방법으로는 CPU의 multiple CPU threads(CPU의 다중스레드)를 이용해서 데이터를 RAM에 미리 올려 놓는 것이다.(Pre-fetching)</code>GPU는 빠른데 데이터 전송 자체가 충분히 빠르지 못하면 보틀넥이 생길수 밖에 없다.</p></li></ul><h4 id="Deep-learning-framework"><a href="#Deep-learning-framework" class="headerlink" title="Deep learning framework"></a>Deep learning framework</h4><h5 id="Deep-learning-framework를-사용하는-이유"><a href="#Deep-learning-framework를-사용하는-이유" class="headerlink" title="Deep learning framework를 사용하는 이유"></a>Deep learning framework를 사용하는 이유</h5><p>1) 딥러닝 프레임워크를 이용하면 엄청 복잡한 그래프를 우리가 직접 만들지 않아도 된다.<br>2) forward pass만 잘 구현해 놓는다면 Back propagation은 알아서 구성되어 gradient를 쉽게 계산할 수 있다.<br>3) cuBLAS, cuDNN, CUDA 그리고 memory등을 직접 세심하게 다루지 않고 GPU를 효율적으로 사용할 수 있다.</p><p><code>framework의 존재 목표는 forward pass 코드를 Numpy스럽게 작서을 해 놓으면 GPU에서도 동작하고 gradient도 알아서 계산해 주는 것이다.</code></p><p>[그림1]<br>[그림2]</p><h5 id="Tensorflow"><a href="#Tensorflow" class="headerlink" title="Tensorflow"></a>Tensorflow</h5><ul><li>placeholder는 그래프 밖에서 데이터를 넣어주는 변수이고, variable은 그래프 내부에 있는 변수이다.</li><li>Tensorflow는 분산처리도 지원하기 떄문에 서로 다른 머신을 이용해 graph를 쪼개서 실행시킬 수도 있다. 혹 분산처리를 계획한다면 Tensorflow가 유일한 선택지가 될 것이다.</li></ul><h5 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h5><ul><li>Facebook에서 나온 PyTorch는 TensorFlow와는 다르게 3가지 추상화 레벨을 정의해 놓았다. 이미 <code>고수준의 추상화를 내장하고 있기에 (Module 객체) TensorFlow 처럼  어떤 모듈을 선택할 지 고민할 필요가 없다.</code><ul><li>tensor : Numpy array와 유사한 tensor object가 있으며 GPU에서 작동한다.<ul><li>tensorflow의 Numpy array</li></ul></li><li>variable : 그래프의 노드(그래프를 구성하고 gradient 등을 계산)<ul><li>tensorflow의 Tensor, Variable, Placeholder</li></ul></li><li>Module : 전체 Neural network를 구성<ul><li>tensorflow의 tf.layers, TFSlim, TFLearn 등</li></ul></li></ul></li></ul><h4 id="Static-computational-graph-vs-Dynamic-graph"><a href="#Static-computational-graph-vs-Dynamic-graph" class="headerlink" title="Static computational graph vs Dynamic graph"></a>Static computational graph vs Dynamic graph</h4><p>Pytorch와 TensorFlow의 주된 차이점 중 하나이다.</p><ul><li>TensorFlow는 두단계로 나누어진다.(Static computational graph - 그래프가 단 하나만 고정적으로 존재하기 때문이다.)<ul><li>1) 그래프를 구성하는 단계</li><li>2) 구성된 그래프를 반복적으로 돌리는 단계</li><li>그래프를 한번 구성해 놓으면 학습시에는 동일한 그래프를 아주 많이 재사용하게 된다. 그러므로 그런 그래프를 최적화시킬 기회가 주어질 수 있다. 처음 최적화 시킬 때 까지 시간이 소요된다 하더라도 최적화된 그래프를 여러번 사용한다는 것을 고려해보면 그에 따른 소요된 시간은 중요치 않을 수 도 있다. 또한 메모리내에 그 네트워크 구조를 갖고 있다는 것이되므로 네트워크 구조를 파일 형태로 저장할 수 있다.</li><li>그래프의 모든 전체적인 연산들을 다 고려해서 만들어 주어야한다.(ex.loop문)</li><li>TensorFlow Fold라는 TF 라이브러리가 static graph으로 만든 트릭으로 dynamic graphs를 작성하게 해준다.</li></ul></li></ul><ul><li>Pytorch는 하나의 단계이다.(Dynamic computational graph)<ul><li>매번 forward pass 할 때 마다 새로운 그래프를 구성한다.</li><li>또한, 그래프 구성과 그래프 실행하는 과정이 얽혀 있기에 모델을 재사용하기 위해서는 항상 원본 코드가 필요하다.</li><li>코드가 훨씬 깔끔하고 작성하기 더 쉽다.</li><li>tensorflow와는 다르게 python 명령어들을 활용할 수 있다.</li><li>다양한 데이터에도 유동적인 네트워크를 만들 수 있다.(RNN사용 - NLP에서 문장을 파싱하는 문제 중 트리를 파싱하기 위해 recursive한 네트워크가 필요할 수 있다.)</li><li>Recurrent network, Recursive network, Modular Networks(이미지와 질문을 던지면 적절한 답을 하는 구조)를 구성할 때 조금 더 편할 수 있다.</li></ul></li></ul>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/07/23/cs231n_08/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[CS231n]Lecture07-Training Neural Networks2</title>
      <link>https://heung-bae-lee.github.io/2019/07/22/cs231n_07/</link>
      <guid>https://heung-bae-lee.github.io/2019/07/22/cs231n_07/</guid>
      <pubDate>Mon, 22 Jul 2019 03:24:40 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;지난 6강에서는 activation function을 중점적으로 다루어 보았는데, 10년전 까지만 해도 sigmoid가 아주 유명했다. 허나, Vanishing gradient가 생기는 문제로 인해 최근에는 Sigmoid와 tanh 보다는 ReL
        
      
      </description>
      
      
      <content:encoded><![CDATA[<p>지난 6강에서는 activation function을 중점적으로 다루어 보았는데, 10년전 까지만 해도 sigmoid가 아주 유명했다. 허나, Vanishing gradient가 생기는 문제로 인해 최근에는 Sigmoid와 tanh 보다는 ReLU를 쓴다라고 했다.</p><ul><li><p><code>대부분의 경우 normalize나 zero-centered로 데이터를 처리해 주지 않으면, Loss가 파라미터에 너무 민감하기 때문에 학습시키기에 어렵다.</code></p></li><li><p>하이퍼파라미터를 몇 개씩 선택하는지에 따른 고민은 보통 모델에 따라 다르며, 하이퍼파라미터의 수가 많을 수록 기하급수적으로 경우의 수가 늘어난다. 많은 하이퍼 파라미터 중 learning rate가 가장 중요할 것이라고 본다. regularization, learning rate decay, model size 같은 것들은 Learning rate보단 덜 중요하다. <code>그렇기에 Block Coordinate Descent(BCD) 같은 방법을 쓸 수도 있다. 우선 learning rate를 정해놓은 다음에 다양한 모델 사이즈를 시도해 보는 것이다. 이 방법을 사용하면 기하급수적으로 늘어나는 Search space를 조금은 줄일 수 있다. 하지만 정확히 어떤 순서로 어떻게 찾아야 할지 정해야 하는 것이 가장 큰 문제이다.</code></p></li><li><p>우리가 어떤 하이퍼파라미터 값을 변경할 시에 다른 하이퍼파라미터의 최적 값이 변해버리는 경우는 가끔 발생한다. 이런 경우 더 좋은 최적화 방법을 사용하면 모델잉 learning rate에 덜 민감하도록 할 수 있다.</p></li></ul><h4 id="Fancier-Optimization"><a href="#Fancier-Optimization" class="headerlink" title="Fancier Optimization"></a>Fancier Optimization</h4><h5 id="SGD-Stochastic-Gradient-Descent-의-문제점"><a href="#SGD-Stochastic-Gradient-Descent-의-문제점" class="headerlink" title="SGD(Stochastic Gradient Descent)의 문제점"></a>SGD(Stochastic Gradient Descent)의 문제점</h5><ul><li><p>1)가중치가 움직일수 있는 방향 중 불균형한 방향이 존재한다면 SGD는 잘 동작하지 않을 것이다.</p><ul><li>아래의 그림을 보고 수평축과 수직축 이 두가지에 대해 가중치의 변화에 따른 손실함수의 변화량이라고 생각해 보자.(우리가 쉽게 어릴적 보았던 지도에서 등고선을 떠올린다면 더 쉽게 이해할 수 있을 것이다.) 그렇다면, 수평축의 가중치 보다 수직축의 가중치가 훨씬 더 손실함수의 변화하는 속도가 빠를 것이다.(왜? 기울기가 더 가파르니까!!!) 즉, Loss는 수직 방향의 가중치 변화에 훨씬 더 민감하게 반응한다. 아래의 그림에서 red point가 현재 Loss라고 가정했을때, 현재 지점의 Hessian matrix의 최대/최소 singular values값의 비율이 매우 안좋다는 뜻이므로 Loss는 bad condition number를 지니고 있다고 말할 수 있을 것이다.[그림0] 아래와 같은 손실함수에서 SGD를 시행한다면, gradient의 방향이 고르지 못하기 때문에 지그재그 모양으로 gradient의 방향이 그려지게 된다. <code>Loss에 영향을 덜 주는 수평방향 차원의 가중치는 업데이트가 아주 느리게 진행된다.</code> 즉, 이렇게 <code>가중치가 움직일수 있는 방향 중 불균형한 방향이 존재한다면 SGD는 잘 동작하지 않을 것이다.</code> [그림1]</li></ul></li><li><p>2)local minima와 saddle points</p><ul><li>X축은 어떤 하나의 가중치를 나타내고, Y축은 Loss를 나타내고 있다. 위의 그림은 local minima에 관한 그림이고, 아래의 그림은 saddle point와 관련된 그림이다. saddle point가 의미하는 것은 어떤 방향은 Loss가 증가하고 몇몇 방향은 Loss가 감소하고 있는 곳을 생각해 볼 수 있다. 그에 반해 local minima는 한 방향으로 Loss가 상승하는 방향이다. <code>이런 saddle point 문제는 고차원 공간에서는 더욱 더 빈번하게 발생하며, 지난 몇 년간 알려진 사실은 very large neural network가 local minima 보다는 saddle point에 취약하다는 것이다. saddle point 뿐만 아니라 saddle point 근처에서도 문제가 발생하는데 근처에서 gradient가 0은 아니지만 기울기가 아주 작은 곳들이 보일 것이다. 그것이 의미하는 바는 gradient를 계산해서 업데이트를 해도 기울기가 아주 작기 때문에 현재 가중치의 위치가 saddle point 근처라면 업데이트는 아주 느리게 진행된다는 점 또한 문제점이다.</code></li></ul></li><li><p>3) mini-batch로 인한 가중치 업데이트는 추정값이다.</p><ul><li>손실함수를 계산할 때는 엄청 많은 Training Set 각각의 loss를 전부 계산해야 한다. <code>매번 이렇게 전부를 계산하는 것은 어렵기 때문에 실제로는 mini-batch의 데이터들만 가지고 실제 Loss를 추정하기만 한다. 이는 gradient의 부정확한 추정값만을 구할 뿐이라는 것이다.</code></li></ul></li></ul><p>위에서 말한 위험요소들을 다루기 위해서 더 좋은 최적화 알고리즘이 필요하다.</p><ul><li>아래에서 소개하는 최적화 알고리즘들의 velocity은 하이퍼 파라미터가 아니며 초기값을 항상 0으로 둔다!<h5 id="1-SGD-momentum"><a href="#1-SGD-momentum" class="headerlink" title="1) SGD + momentum"></a>1) SGD + momentum</h5></li><li>아이디어는 gradient의 방향으로만 움직이는 SGD에 velocity를 유지하는 것이다. 즉, gradient를 계산할 때 velocity를 이용한다. <code>현재 mini-batch의 gradient 방향만 고려하는 것이 아니라 velocity를 같이 고려하는 것이다.</code>아래의 수식을 보면 velocity의 영향력을 rho의 비율로 맞춰주는데 보통 0.9 또는 0.99 같은 높은 값으로 맞춰준다. gradient vector 그대로의 방향이 아닌 velocity vector의 방향으로 나아가게 된다. [그림2]<code>local minima와 saddle points 문제는 local minima에 도달해도 여전히 velocity를 가지고 있기 때문에 gradient가 0이라도 움직일 수 있으며 계속해서 내려갈 수 있다. saddle point 주변의 gradient가 작더라도, 굴러내려오는 속도가 있기 때문에 velocity를 가지게 되어 이 또한 잘 극복해 내고 계속 밑으로 내려올 수 있는 것이다.</code> 기존의 SGD만을 사용했을 경우처럼 지그재그로 움직이는 상황을 momentum으로 인해 그러한 변동을 서로 상쇄시켜 버린다. noise가 평균화 되버리는 의미를 갖는다. <code>이를 통해서 Loss에 민감한 수직 방향의 변동은 줄여주고 수평방향의 움직임은 점차 가속화 될 것이다. momentum을 추가하게 되면 high condition number problem을 해결하는데 도움이 되는 것이다!</code> 직관적으로 보면 velovity는 이전 gradients의 weighted sum이다. 더 최근의 gradients에 가중치가 더 크게 부여되고 계산되는 과정이 일좀의 smooth moving average라고 볼 수 있다. 시간이 지날수록 이전의 gradient들은 exponentially하게 감소한다.<br>[그림3]</li></ul><h5 id="2-Nesterov-momentum"><a href="#2-Nesterov-momentum" class="headerlink" title="2) Nesterov momentum"></a>2) Nesterov momentum</h5><p>SGD momentum은 현재지점에서의 gradient를 계산한 뒤에 velocity와 곱해주었지만 Nesterov momentum은 계산 순서만 변형을 시켜 주었다고 보면 된다. 아래의 왼쪽 그림을 보면, 빨간 점에서 시작해서 우선은 Velocity 방향으로 움직인다. 그리고 그 지점에서의 gradient를 계산한 후 다시 원점으로 돌아가서 이 둘을 합치는 것이다. <code>velocity의 방향이 잘못되었을 경우에 현재 gradient의 방햐을 좀 더 활용할 수 있도록 해준다. Nesterov는 Convex Optimization 문제에서는 뛰어난 성능을 보이지만 하지만 Neural network와 같은 Non-convex problem에서는 성능이 보장되는 않는다.</code><br>[그림4]<br>Nesterov의 첫번째 수식은 기존의 momentum과 동일하다. 아래 그림에서 재배열한 수식을 보면 기존과 동일하게 velocity와 계산한 gradient를 일정 비율로 섞어주는 역할을 한다. 그리고 두 번째 수식에서 마지막 부분을 보면 현재 점과 velocity를 더해주며, <code>현재 velocity - 이전 velocity를 계산해서 일정 비율(rho)을 곱하고 더해줍니다. 현재/이전의 velocity간의 에러 보정(error-correcting term)이 추가되었다.</code><br>[그림5]<br><code>이전의 velocity의 영향을 받기 때문에 momentum 방법들은 minima를 그냥 지나쳐 버리는 경향이 있다. 하지만 스스로 경로를 수정하고는 결국 minima에 수렴한다.</code></p><h5 id="3-AdaGrad"><a href="#3-AdaGrad" class="headerlink" title="3) AdaGrad"></a>3) AdaGrad</h5><ul><li><code>학습 도중에 계산되는 gradient에 제곱을 해서 계속 더해준다. 가중치를 업데이트 할때 gradient로 나눠주는 작업을 수행한다.</code> 한 차원은 항상 gradient가 높은 차원이고 다른 하나는 항상 작은 gradient를 가지는 2차원 좌표가 있다고 가정하자. small dimension에서는 gradient의 제곱 값 합이 작은데 이 작은 값으로 나워지므로 가속도가 붙게된다. Large dimension에서는 gradient가 큰 값 이므로  큰 값이 나워지게 되어 속도가 점점 줄어든다. <code>하지만 학습이 계속 진행될수록 학습 횟수가 늘어난다는 문제가 있다. 학습 횟수가 많아질수록 AdaGrad의 값은 점점 작아진다. 이러한 점은 Convex한 Loss인 경우에 좋은 특징이 될 수 있다. minimum에 근접하면 서서히 속도를 줄여서 수렴할 수 있게 해 줄 수 있기 때문이다. 하지만 saddle point problem과 같은 non-convex 문제에서는 AdaGrad가 멈춰 버리는 상황이 발생할 수 도 있어 문제가 있다.</code> 일반적으로 NN을 학습시킬 때는 잘 사용하지 않는다.[그림6]</li></ul><h5 id="4-RMSProp"><a href="#4-RMSProp" class="headerlink" title="4) RMSProp"></a>4) RMSProp</h5><ul><li>위와 같은 문제를 보완하기 위한 알고리즘이다. AdaGrad의 gradient 제곱 항을 그대로 사용한다. <code>점점 속도가 줄어드는 문제를 제곱항을 그저 누적시키는 것이 아니라 기존의 누적 값에 decay_rate를 곱해주는</code> 방식을 통해 해결하였다. decay_rate는 보통 0.9 또는 0.99를 자주 사용한다. gradient 제곱을 계속 나눠준다는 점은 AdaGrad와 유사하다. <code>이를 통해 step의 속도를 가속/감속 시킬 수 있다.</code> [그림7]</li></ul><h5 id="5-Adam"><a href="#5-Adam" class="headerlink" title="5) Adam"></a>5) Adam</h5><ul><li><code>momentum + RMSProp</code> 으로 위에서 종합한 momentum계열의 알고리즘과 Ada계열의 알고리즘의 특징을 합한 것이다. 빨간색 부분은 gradient의 가중합이다. 파란색 부분은 AdaGrad나 RMSProp처럼 gradients의 제곱을 이용하는 방법이다. <code>초기 Step이 엄청 커져 버릴 수 있고 이로 인해 잘못될 수도 있다. 이런 문제를 해결하기 위해 보정하는 항을 추가한다.(bias correction term)</code> Adam은 다양한 문제에도 정말 잘 동작한다. 하지만 예를들어 손실함수가 타원형이고 축 방향으로 정렬되어 있지 않고 기울어져 있다고 생각해 보자. <code>회전된 타원(poor conditioning) 문제는 Adam을 비롯한 다른 여러 알고리즘들도 다를 수 없는 문제이다.</code>[그림8]</li></ul><h4 id="learning-rates-decay-전략"><a href="#learning-rates-decay-전략" class="headerlink" title="learning rates decay 전략"></a>learning rates decay 전략</h4><ul><li><code>처음에는 learning rate를 높게 설정한 다음에 학습이 진행될수록 learning rates를 점점 낮추는 것이다.</code> 예를 들면, 100,000 iter에서 learning rates를 낮추고 학습시키는 것이다.(step decay) 또는 exponential decay 처럼 학습과정 동안에 꾸준히 learning rate를 낮출 수도 있다. learning rate가 너무 높아서 더 깊게 들어가지 못하는 상황에 learning rate를 낮추게 되면 속도가 줄어들며 지속해서 Loss를 내려갈 수 있을 것이다. <code>learning rate decay는 부차적으로 생각해보는 것이지 학습 초기부터 고려하지는 않는다. 또한 Adam 보다는 SGD Momentum을 사용할 때 자주 사용한다.</code>[그림9]</li></ul><p>위에서 언급한 알고리즘들은 1차 미분값을 사용하여 1차 근사함수를 실제 손실함수라고 가정하고 가중치의 업데이트를 진행하였다. 이런 방식은 근사 시킨 값이므로 정확성이 떨어져 스텝의 사이즈를 키워 멀리 갈수가 없다. 2차 미분값을 활용하여 근사 시키는 방법을 통해 그러한 문제를 해결할 수 있을 것이다.[그림10][그림11]</p><h4 id="Second-Order-Optimization"><a href="#Second-Order-Optimization" class="headerlink" title="Second-Order Optimization"></a>Second-Order Optimization</h4><ul><li>위의 2차원을 다차원으로 확장시켜보면 이를 Newton step이라고 한다. <code>Hessian matrix의 inverse matrix를 이용하게 되면 실제 손실함수의 2차 근사를 이용해 곧바로 minima로 이동할 수 있다는 것이다. 다른 알고리즘들과 달리 learning rate를 사용하지 않는다. 실제로는 2차 근사도 완벽하지 않기에 learning rate가 필요하다. 어디까지나, minima로 이동하는게 아니라 minima의 방향으로 이동하기 때문이다. 허나, inverse matrix를 구하기 힘들고 메모리에 대량의 파라미터를 저장할 방법이 없기에 이 알고리즘은 NN에서 사용되지 않는다.</code></li></ul><h5 id="1-Quasi-Newton-methods-BGFS-most-popular"><a href="#1-Quasi-Newton-methods-BGFS-most-popular" class="headerlink" title="1) Quasi-Newton methods(BGFS most popular)"></a>1) Quasi-Newton methods(BGFS most popular)</h5><ul><li>Full Hessian을 그대로 사용하기 보다 근사시킨다. Low-rank approximations하는 방법이다.</li></ul><h5 id="2-L-BFGS"><a href="#2-L-BFGS" class="headerlink" title="2) L-BFGS"></a>2) L-BFGS</h5><ul><li>Hessian을 근사시켜 사용하는 second-order optimizer이다. 사실상 DNN에서는 잘 사용하지 않는다. <code>왜냐하면 L-BFGS에서 2차 근사가 stochastic case에서 잘 동작하지는 않으며, Non-convex 문제에도 적합하지 않기 때문이다. 단지 full batch update가 가능하고 stochasticity가 적은 경우라면, L-BFGS가 좋은 선택이 될 수 있다. NN을 학습시키는데 많이 사용되지는 않지만 Style transfer 같은 stochasticity와 파라미터가 적은 경우에서 Optimization을 해야할 경우에 종종 사용할 수 있다.</code></li></ul><ul><li>위에서 살펴본 방법들은 학습과정의 error를 줄이기 위한 방법들이었다. 허나 우리가 진정으로 관심을 갖고 보아야 할 것은 test set의 error이다. 그런 test set의 error를 줄이기 위한 방안들을 다음에서 제시한다.</li></ul><h4 id="Model-Ensemble"><a href="#Model-Ensemble" class="headerlink" title="Model Ensemble"></a>Model Ensemble</h4><ul><li><p><code>model을 train 시킨 후 우리가 가장 기대하는 바는 새롭게 들어온 test set에 대한 성능. 즉, test set에 대한 error가 작기를 기대한다. 그렇게 하는 가장 쉽고 빠른 방법이 바로 Model Ensemble이다.</code> machine learning 분야에서 종종 사용하는 기법으로 예를 들어 설명하자면 모델을 하나만 학습시키지 말고 10개의 모델을 독립적으로 학습시키는 것이다. 결과는 10개 모델 결과의 평균을 이용한다. <code>모델의 수가 늘어날수록 Overfitting이 줄어들고 성능이 조금씩 향상된다. 보통 2%정도 증가한다. ImageNet이나 Kaggle competition 같이 모델의 성능을 최대화 시키는 것이 주된 목표일 경우 많이 사용한다. 허나 개인적으로나 주변의 조언들을 종합해보자면 우선 기본적인 base모델의 성능을 높이는데 주력하는 것이 더 좋을 듯하다. 실제로 실무에서는 Ensemble이나 Stacking같은 기법을 자주 사용하지는 않는다고 하기 때문이다. 하지만 한번 쯤은 만들어 보는 것도 좋은 것 같다.</code> 또한 학습 도중 중간 모델들을 저장하고 앙상블로 사용할 수도 있다. 그리고 Test시에는 여러 중간 모델들을 통해 나온 예측값들을 평균을 내서 사용한다.</p></li><li><p>만약 모델간의 Loss 차이가 크면 한쪽이 Overfitting 일수 있고, 차이가 작아도 안좋은 것은 아닐까라는 생각에 의해 좋은 앙상블 결과를 위해서라면 모델 간의 최저그이 갭을 찾는 것이 중요하지 않는냐는 생각이 들 수도 있겠지만, <code>언제나 말하듯 우리에게 중요한 것은 validation set의 성능을 최대화시키는 것이다.</code></p></li><li><p>앙상블시에 다양한 모델 사이즈, learning rate, 그리고 다양한 regularization 기법 등을 앙상블 할 수 있다.</p></li><li><p>이런 모델을 독립적으로 학습시키는 방법외에도 학습하는 동안에 파라미터의 exponentially decaying average를 계속 계산한다. <code>이 방법은 학습중인 네트워크의 smooth ensemble 효과를 얻을 수 있다. 즉, checkpoints에서의 파라미터를 그대로 사용하지 않고 smoothly decaying average를 사용하는 방법이다.(Polyak averaging)</code></p></li></ul><h4 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h4><ul><li>모델에 어떤 조건들을 추가할 텐데 그 term들은 모델이 Training data에 fit하는 것을 막아줄 것이다. 그리고 한번도 보지 못한 데이터에서의 성능을 향상시키는 방법이다.</li><li><code>L2 regularization은 NN에는 잘 어울리지 않는다. 왜???</code></li><li><p><code>NN에서 가장 많이 사용하는 Regularization은 바로 dropout이다!!!</code></p><ul><li><p>Dropout</p><ul><li><p>Forward pass 과정에서 한 layer씩 출력(activation = previous activation * weight)을 전부 구한 후에 임의로 일부 뉴런을 0으로 만들어 주는데 매번 Forward pass마다 0이 되는 뉴런을 바꿔주어 <code>특징들 간의 상호작용을 방지한다고 볼 수 있다. 즉, 네트워크가 어떤 일부 feature에만 의존하지 못하게 해준다. 다양한 feature를 골고루 이용할 수 있도록 하여 Overfitting을 방지한다고 볼 수 있다..</code>보통은 0.5로 준다. [그림12]</p></li><li><p>단일 모델로 앙상블 효과를 가질 수 있다는 것이다. 서로 다른 파라미터를 공유하는 서브네트워크 앙상블을 동시에 학습시키는 것이라고도 생각할 수도 있다. 그러나, 뉴런의 수에 따라서 앙상블 가능한 서브네트워크의 수가 기하급수적으로 증가하기 때문에 가능한 모든 서브네트워크를 사용하는 것은 사실상 불가능하다.</p></li></ul></li><li><p>Dropout을 사용하면 Test time에는 어떤 일이 발생되나?</p><ul><li><p>Dropout을 사용하면 기본적으로 NN의 동작자체가 변하게 된다. 기존의 NN은 w와 x에 대한 함수였다. 그러나 <code>Dropout을 사용한면 Network에 z라는 입력이 추가된다. z는 random dropout mask이다. test시에는(예측시) 임의의 값을 부여하는 것은 좋지 않다. 왜냐하면 예측할때마다 결과가 바뀔수 있기 때문이다. 이런 randomness를 average out시키는데 적분을 통해 marginalize out시키는 것으로 생각해볼 수 있다. 허나 실제로는 까다로운 문제이므로 z를 여러번 샘플링해서 예측시에 이를 average out시키는 것이다. 하지만 이 방법도 test time에서의 randomness을 만들어 내기 때문에 좋지 않은 방법이다. 허나 다음 그림과 같이 test time에서 stochasticity를 사용하지 않고 할 수 있는 값 싼 방법 중 하나는 dropout probability를 네트워크의 출력에 곱하여 test time과 train time의 기대값을 같게 해주는 것이다.</code> [그림13] 실제로 코드에서는 아래와 같이 예측시에 dropout probability를 곱해주거나 tip으로 train에서는 연산이 GPU에 의해 계산되어 추가되는 것에 별로 신경쓰지 않지만 Test time에서는 효율적으로 동작하길 바라므로 train시에 오히려 역으로 dropout probability를 나누어주는 식으로 수행할 수 있다. [그림14]</p></li><li><p>dropout을 사용하게 되면 Train time에서 gradient에는 어떤 일이 일어나는지 궁금할 것이다. 결론은 우리가 생각하던 Dropout이 0으로 만들지 않은 노드에서만 Backpropagation이 발생하게 된다. <code>Dropout을 사용하게 되면 각 스텝마다 업데이트되는 파라미터의 수가 줄어들기 때문에 전체 학습시간은 늘어나지만 모델이 수렴한 후에는 더 좋은 일반화 능력을 얻을 수 있다.</code></p></li><li><p>기본적으로 Dropout은 일반적인 regularization전략을 구체화시킨 하나의 예시에 불과하다. 이 전략은 Train time에는 네트워크에 randomness를 추가해 네트워크를 마구잡이로 흩뜨려 놓으므로써 Training data에 너무 fit하지 않게 해준다. 그리고 Test time에서는 randomness를 평균화 시켜서 generalization 효과를 주는 것이다. <code>Dropout이 Regularization에 가장 대표적인 예이긴 하지만 Batch normalization 또한 비슷한 동작을 할 수 있다. 왜냐하면 mini-batch로 하나의 데이터가 샘플링 될 때 매번 서로 다른 데이터들과 만나게 된다. Train time에서는 각 데이터에 대해서 이 데이터를 얼마나 어떻게 정규화시킬 것인지에 대한 stochasticity이 존재했다. 하지만 test time에서는 정규화를 mini-batch 단위가 아닌 global 단위로 수행함으로써 stochasticity를 평균화 시킨다.</code> 이러한 특성 때문에 Batch-Normalization은 Dropout과 유사한 Regularization 효과를 얻을 수 있다. <code>실제로 Batch-Normalization을 사용할 때는 Dropout을 사용하지 않는다. Batch-Normalization에도 충분히 regularization 효과가 있기 때문이다.</code>[그림15]</p></li><li><p>Batch-Normalization과는 다르게 자유롭게 조절할 수 있는 파라미터 p가 있기 때문에 Batch-Normalization은 여전히 쓸모있다.</p></li></ul></li><li><p>data augmentation</p><ul><li><p>Regularization 패러다임에 부합하는 전략 중 하나이다. 예를 들어 고양이 사진을 classification 문제로 풀려고 할때, 이미지의 반전을 주어 입력한다던지 아니면, 임의의 다야한 사이즈로 잘라서(crop) 사용할 수 있다. 또한, color jittering도 있는데 간단한 방법으로는 학습시 이미지의 contrast 또는 brightness를 바꿔준다. 복잡한 방법으로는 PCA의 방향을 고려하여 color offset을 조절하는 방법이다. 이런 방법은 color jittering을 좀 더 data-dependent한 방법으로 진행하는 것으로 자주 사용하는 방법은 아니다.</p></li><li><p>data augmentation은 어떤 문제에도 적용해 볼 수 있는 아주 일반적인 방법이라고 할 수 있다. 어떤 문제를 풀려고 할 때, 이미지의 label을 바꾸지 않으면서 이미지를 변환시킬 수 있는 많은 방법들을 생각해 볼 수 있다.<code>train time에 입력 데이터에 임의의 변환을 시켜주게 되면 일종의 regularization 효과를 얻을 수 있다. 그 이유는 위에서 언급하고 강조한 것과 같이 train time에는 stochasticity가 추가되고 test time에는 marginalize out 되기 때문이다.</code></p></li></ul></li><li><p>DropConnect</p><ul><li>Dropout과 다르게 activation이 아닌 weight matrix를 임의적으로 0으로 만들어주는 방법이다.</li></ul></li><li><p>fractional max pooling</p><ul><li>보통의 경우, 2x2 max pooling 연산은 고정된 2x2 지역에서만 수행하지만 fractional max pooling에서는 그렇게 하지 않고 pooling 연산을 수행할 지역이 임의로 선정된다. 예를 들면 아래의 그림에서 Train time에 샘플링 될 수 있는 임의의 pooling region을 볼 수 있다. 그리고 test time에 stochasticity를 average out 시키려면 pooling regions를 고정시켜 버리거나 혹은 여러개의 pooling regions를 만들고 averaging over를 시킨다. 많이 사용하지는 않지만 좋은 방법이다.[그림16]</li></ul></li><li><p>Stochastic Depth</p><ul><li>Train time에는 layer 중 일부를 제거해 버리고 일부만 사용해서 학습한다. Test time에는 전체 네트워크를 다 사용한다. 최신의 연구이며 실제로 잘 사용하진 않지만 아주 좋은 아이디어이다.</li></ul></li></ul></li></ul><p>보통 하나 이상의 regularization 방법을 사용하는데 그 중에서도 Batch-Normalization만으로도 충분하다. <code>다만 Overfitting이 발생한다 싶으면 Dropout과 같은 다양한 방법을 추가해 볼 수 있다. 이를 가지고 blind cross-validation을 수행하지는 않는다. 대신에 네트워크에 overfit의 조짐이 보일때 하나씩 추가시켜 본다.</code></p><h4 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h4><ul><li><p><code>overfitting이 일어날 수 있는 상황 중 하나는 충분한 데이터가 없을 때이다. 우리는 이런 상황에서 Transfer learning을 사용하여 문제를 해결 할 수 있다.</code> 또한, 흔히들 CNN 학습에는 엄청많은 데이터가 필요하다고 생각할 수 있는데 그런한 사고를 무너뜨려 버려준다.</p></li><li><p>1) 먼저 ImageNet 같은 아주 큰 데이터셋으로 학습을 한번 시킨다.<br>ImageNet에서 학습된 feature를 우리가 가진 작은 데이터셋에 적용하는 것이다.이제는 1000개의 ImageNet 카테고리를 분류하는 것이 아니라 10종의 강아지를 분류하는 문제이다. 데이터는 엄청 적다. 이 데이터 셋은 오직 C(예:10개)개의 클래스만 가지고 있다.</p></li><li>2) 가장 마지막의 Fully connected layer는 최종 feature와 class scores간의 연결인데 이를 초기화시킨다. 또한, 기존의 ImageNet은 4,096 x 1,000 차원의 matrix였지만 이제는 우리가 10개의 클래스를 갖으므로 4,096 x 10 차원의 matrix로 바꿔준다. 나머지 이전의 모든 레이어드르이 가중치는 그대로 둔다. <code>이렇게 되면 linear classifier를 학습시키는 것과 같다. 왜냐하면 오로지 마지막 레이어만 가지고 우리 데이터를 학습시키는 것이기 때문이다.</code></li></ul><p>이러한 방법을 사용하면 아주 작은 데이터 셋일지라도 아주 잘 동작하는 모델을 만들 수 있다.</p><ul><li><p>만일, 데이터가 조금 더 있다면 전체 네트워크를 fine-tuning 할 수 있다. 최종 레이어들을 학습시키고 나면, 네트워크의 일부만이 아닌 네트워크 전체의 학습을 고려해 볼 수도 있을 것이다 데이터가 더 많이 있다면 네트워크의 더 많은 부분을 업데이트 시킬 수 있을지도 모른다. <code>이 부분에서는 보통 기존의 Learning rate보다는 낮춰서 학습시킨다. 왜냐하면 기존의 가중치들이 이미 ImageNet으로 잘 학습되어 있고 이 가중치들이 대게는 아주 잘 동작하기 때문이다. 우리가 가진 데이터셋에서의 성능을 높히기 위해서라면 그 가중치들을 아주 조금씩만 수저정하면 될 것이다.</code></p></li><li><p><code>transfer learning은 거의 일상적인 수준이 되었다. 대부분은 ImageNet pretrained model을 사용하고 현재 본인의 task에 맞도록 fine tuning한다.</code> captioning의 경우 word vectors를 pretrain하기도 한다. pretrained CNN 뿐만 아니라 큰 규모의 코퍼스로 부터 학습된 pretrained word vectors도 함께 이용할 수 있다. 허나, captioning task에서는 pretrained word vectors을 사용하는 경우가 많지 않고 크게 중요하지 않다.</p></li></ul><p>문제에 대한 데이터셋이 크지 않은 경우라면 풀려는 문제와 유사한 데이터셋으로 학습된 pretrained model을 다운로드 받아라. 그리고 이 모델의 일부를 초기화시키고 가지고있는 데이터로 모델을 fine-tuning한다.</p><p>TensorFlow : <a href="https://github.com/tensorflow/models" target="_blank" rel="noopener">https://github.com/tensorflow/models</a><br>Pytorch : <a href="https://github.com/pytorch/vision" target="_blank" rel="noopener">https://github.com/pytorch/vision</a></p>]]></content:encoded>
      
      <comments>https://heung-bae-lee.github.io/2019/07/22/cs231n_07/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
