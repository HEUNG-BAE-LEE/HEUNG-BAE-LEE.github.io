<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    

    
    <title>쉽게 배우는 경사하강 학습법 | DataLatte&#39;s IT Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    
    <meta name="description" content="쉽게 배우는 경사하강 학습법      어떤 손실 함수를 사용하느냐에 따라서 학습이 어떻게 이루어질 것인지, 그리고 학습을 할 때 정답의 형태를 결정하기 때문에 손실 함수는 중요하다!    Traning Data를 Model에 입력해 우리가 학습시키고자 하는 Trainable Parameters를 얻게 되는데 Trainable Parameters들을 inpu">
<meta property="og:type" content="article">
<meta property="og:title" content="쉽게 배우는 경사하강 학습법">
<meta property="og:url" content="https://heung-bae-lee.github.io/2019/12/08/deep_learning_02/index.html">
<meta property="og:site_name" content="DataLatte&#39;s IT Blog">
<meta property="og:description" content="쉽게 배우는 경사하강 학습법      어떤 손실 함수를 사용하느냐에 따라서 학습이 어떻게 이루어질 것인지, 그리고 학습을 할 때 정답의 형태를 결정하기 때문에 손실 함수는 중요하다!    Traning Data를 Model에 입력해 우리가 학습시키고자 하는 Trainable Parameters를 얻게 되는데 Trainable Parameters들을 inpu">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://heung-bae-lee.github.io/image/supervised_learning_vs_unsupervised_learning.png">
<meta property="og:updated_time" content="2019-12-13T03:55:29.137Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="쉽게 배우는 경사하강 학습법">
<meta name="twitter:description" content="쉽게 배우는 경사하강 학습법      어떤 손실 함수를 사용하느냐에 따라서 학습이 어떻게 이루어질 것인지, 그리고 학습을 할 때 정답의 형태를 결정하기 때문에 손실 함수는 중요하다!    Traning Data를 Model에 입력해 우리가 학습시키고자 하는 Trainable Parameters를 얻게 되는데 Trainable Parameters들을 inpu">
<meta name="twitter:image" content="https://heung-bae-lee.github.io/image/supervised_learning_vs_unsupervised_learning.png">
<meta property="fb:app_id" content="100003222637819">


    <link rel="canonical" href="https://heung-bae-lee.github.io/2019/12/08/deep_learning_02/">

    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">
    <link rel="stylesheet" type="text/css" href>
    <link rel="stylesheet" href="https://cdn.rawgit.com/innks/NanumSquareRound/master/nanumsquareround.css">	
    <link rel="stylesheet" href="https://fonts.googleapis.com/earlyaccess/nanumgothiccoding.css">
    <link rel="stylesheet" href="/css/style.css">
   
    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-154199624-1', 'auto');
ga('send', 'pageview');

</script>

    
    


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4604833066889492" data-ad-slot="4588503508" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<link rel="alternate" href="/rss2.xml" title="DataLatte's IT Blog" type="application/rss+xml">
</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">DataLatte&#39;s IT Blog using Hexo</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Bayes/">Bayes</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/CS231n/">CS231n</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Front-end/">Front end</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/">Python</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/crawling/">crawling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/data-engineering/">data engineering</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/growth-hacking/">growth hacking</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/hexo/">hexo</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/linear-algebra/">linear algebra</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/machine-learning/">machine learning</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/deep-learning/">deep learning</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="4588503508"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

			    <article id="post-deep_learning_02" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        쉽게 배우는 경사하강 학습법
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2019/12/08/deep_learning_02/" class="article-date">
            <time datetime="2019-12-07T15:00:00.000Z" itemprop="datePublished">2019-12-08</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h2 id="쉽게-배우는-경사하강-학습법"><a href="#쉽게-배우는-경사하강-학습법" class="headerlink" title="쉽게 배우는 경사하강 학습법"></a>쉽게 배우는 경사하강 학습법</h2><p><img src="/image/supervised_learning_vs_unsupervised_learning.png" alt="지도 학습 vs 비지도 학습"></p>
<p><img src="/image/supervised_learning_of_human.png" alt="사람의 지도학습"></p>
<p><img src="/image/supervised_learning_of_machine.png" alt="머신러닝의 지도학습"></p>
<p><img src="/image/hyper_parameters.png" alt="학습 매개변수"></p>
<p><img src="/image/Loss_function.png" alt="손실 함수"></p>
<ul>
<li><code>어떤 손실 함수를 사용하느냐에 따라서 학습이 어떻게 이루어질 것인지, 그리고 학습을 할 때 정답의 형태를 결정하기 때문에 손실 함수는 중요하다!</code></li>
</ul>
<p><img src="/image/another_aspect_about_algorithm_learning.png" alt="알고리즘 학습을 달리 말하면"></p>
<ul>
<li>Traning Data를 Model에 입력해 우리가 학습시키고자 하는 Trainable Parameters를 얻게 되는데 <code>Trainable Parameters</code>들을 <code>inputs</code>으로 보고 <code>outputs</code>을 학습결과인 <code>Loss Function</code>으로 생각하면, <code>알고리즘 학습은 입력을 바꿔가면서, 출력값이 점점 작아지게 하는 것이라고 볼 수 있다.</code></li>
</ul>
<p><img src="/image/optimization_theory_and_algorithm_learning.png" alt="최적화 이론과 알고리즘 학습"></p>
<ul>
<li>결국 알고리즘 학습은 입력을 바꿔가면서, 출력값이 점점 작아지게 하는 것이라는 관점에서 <code>최적화 이론의 목표와 동일</code>하다는 사실을 알 수 있다.</li>
</ul>
<h2 id="경사-하강-학습법"><a href="#경사-하강-학습법" class="headerlink" title="경사 하강 학습법"></a>경사 하강 학습법</h2><p><img src="/image/Brute_Force.png" alt="무차별 대입법(Brute-Force)"></p>
<ul>
<li><code>무차별 대입법</code>은 범위를 알아야하고 범위를 안다해도 step을 촘촘히 조사해야 하므로 <code>계산 복잡도가 높다</code>. <code>적게 대입해 보고 답을 찾을 수 있는 방법을 생각하다 최적화 알고리즘이 발전 하게 되었다.</code></li>
</ul>
<p><img src="/image/Graadient_Descent.png" alt="경사하강법(Gradient Descent)"></p>
<p><img src="/image/Graadient_Descent_01.png" alt="경사하강법(Gradient Descent)"></p>
<p><img src="/image/selection_of_learning_rate.png" alt="학습률의 선택 00"></p>
<p><img src="/image/selection_of_learning_rate_01.png" alt="학습률의 선택 01"></p>
<p><img src="/image/selection_of_learning_rate_02.png" alt="학습률의 선택 02"></p>
<p><img src="/image/Convex_Function.png" alt="Convex Function"></p>
<p><img src="/image/Non_Convex_Function.png" alt="Non-convex Function"></p>
<h2 id="최적화-이론과-수학적-표현"><a href="#최적화-이론과-수학적-표현" class="headerlink" title="최적화 이론과 수학적 표현"></a>최적화 이론과 수학적 표현</h2><p><img src="/image/optimization_theory.png" alt="최적화 이론(Optimization Theory)"></p>
<p><img src="/image/analysis_and_numerical_method.png" alt="분석적 vs 수치적 방법"></p>
<ul>
<li>수치적 방법의 대표적인 방법이 경사하강법이다.</li>
</ul>
<p><img src="/image/global_and_local_solution.png" alt="Global vs local solution"></p>
<p><img src="/image/deep_learning_and_optimization_theory.png" alt="딥러닝과 최적화 이론"></p>
<h2 id="심화-경사-하강-학습법"><a href="#심화-경사-하강-학습법" class="headerlink" title="심화 경사 하강 학습법"></a>심화 경사 하강 학습법</h2><ul>
<li>경사하강 학습법의 단점들을 극복한 알고리즘에 대해서 알아보자.</li>
</ul>
<p><img src="/image/Non_convex_function_01.png" alt="Non_convex Finction"></p>
<p><img src="/image/Local_minimum.png" alt="Local Minimum"></p>
<p><img src="/image/Saddle_point.png" alt="Saddle Point"></p>
<ul>
<li>경사하강법은 안장점에서 기울기가 0이 되므로 벗어나지 못하게 되는 문제점이 있다.</li>
</ul>
<p><img src="/image/Momentum.png" alt="Momentum"></p>
<ul>
<li><p><code>이동 벡터가 이전 기울기에 영향을 받도록 하는 방법 이전의 속도에 영향을 받는 방법이라고 할 수 있다.</code></p>
</li>
<li><p>장점 : <code>Local minimum과 noise에 대처 가능</code></p>
</li>
<li><p>단점 : <code>경사하강법은 단순히</code>$x_{t-1}$<code>이동벡터(</code>$v_{t}$<code>)를 추가로 사용하므로, 경사 하강법 대비 2배의 메모리를 사용</code></p>
</li>
</ul>
<p><img src="/image/AdaGrad.png" alt="AdaGrad"></p>
<ul>
<li><p><code>변수별로 learning rate가 달라지게 조절한다.</code> 예를 들어서 $x=[x_{1}, x_{2}, x_{3},…,x_{n}]$이 존재할때 어떤 변수는 기울기를 크게 가져가고 어떤 변수는 기울기를 작게 가져갈 경우 <code>처음에 기울기를 크게 가져가지 못한다면 local minimum에 빠지기 쉬운 문제점이 있다.</code> 이런 문제점을 해결하고자 변수별로 learning rate를 다르게 가져가는 알고리즘인 Ada Grad 탄생된 것이다.</p>
</li>
<li><p>장점 : $g_{t}$가 누적되어 커진 것은 학습이 그만큼 많이 된 것이므로 <code>학습이 많이 변수는 학습율을 감소시켜, 다른 변수들이 잘 학습되도록 한다.</code></p>
</li>
<li><p>단점 : $g_{t}$ <code>가 계속해서 커져서 학습이 오래 진행되면 learning rate가 0ㅇ에 가까워지므로 더이상 학습이 이루어지지 않는 단점이 있다.</code></p>
</li>
</ul>
<p><img src="/image/RMSprop.png" alt="RMSProp"></p>
<ul>
<li>gradient의 크기를 제곱한 벡터(gradient벡터의 L2-norm)를 누적합을 해서 적게 학습되는 변수들을 더 학습시켜 주도록했지만 <code>epoch나 batchsize등 반복 시키는 parameter의 value가 높아질수록 오래 진행되어 누적합이 커지게 되면 더 이상 학습이 되지 않는 문제점을 개선한 방법</code>이다. 위의 식에서 $\gamma$<code>값은 0~1값을 갖게 되며, 이 값을 통해 이전의 gradient 누적합을 감소시키는 효과를 주면서 새로운 gradient의 값을 쫓아갈 수 있도록 개선하였다. 그러므로, 변수 간의 상대적인 학습율 차이는 유지하면서</code>$g_{t}$<code>가 무한정 커지지 않아 학습을 오래 할 수 있다.</code></li>
</ul>
<p><img src="/image/Adam.png" alt="Adam"></p>
<ul>
<li><code>RMSprop과 Momentum의 장점을 결합한 알고리즘이다. 대부분의 코드에 이 Adam optimization을 사용한다.</code></li>
</ul>
<h2 id="경사-하강법을-이용한-얕은-신경망-학습"><a href="#경사-하강법을-이용한-얕은-신경망-학습" class="headerlink" title="경사 하강법을 이용한 얕은 신경망 학습"></a>경사 하강법을 이용한 얕은 신경망 학습</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 경사 하강법을 이용한 얕은 신경망 학습</span></span><br><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment">## 하이퍼 파라미터 설정</span></span><br><span class="line">epochs = 1000</span><br><span class="line"></span><br><span class="line"><span class="comment">## 네트워크 구조 정의</span></span><br><span class="line"><span class="comment">### 얕은 신경망</span></span><br><span class="line"><span class="comment">#### 입력 계층 : 2, 은닉 계층 : 128 (Sigmoid activation), 출력 계층 : 10 (Softmax activation)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># keras의 모듈을 상속해서 Model을 구현</span></span><br><span class="line">class MyModel(tf.keras.Model):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        <span class="comment"># 상속을 한 경우에는 상속을 한 상위 class를 initialize하는 것을 잊어버리지 말자!</span></span><br><span class="line">        super(MyModel, self).__init__()</span><br><span class="line">        <span class="comment"># 아래의 input_dim을 적어줄 필요는 없다. 실제 데이터가 들어올때 정의 되기 떄문이다.</span></span><br><span class="line">        self.d1 = tf.keras.layers.Dense(128, input_dim=2, activation=<span class="string">"sigmoid"</span>)</span><br><span class="line">        self.d2 = tf.keras.layers.Dense(10, input_dim=128, activation=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Model이 실제 call이 될때 입력에서 출력으로 어떻게 연결이 될 것인지를 정의</span></span><br><span class="line">    def call(self, x, training=None, mask=None):</span><br><span class="line">        x = self.d1(x)</span><br><span class="line">        <span class="built_in">return</span> self.d2(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 학습 루프 정의</span></span><br><span class="line">@tf.function</span><br><span class="line"><span class="comment"># tensorflow의 Auto Graph를 통해 쉽게 구현가능하다.</span></span><br><span class="line"><span class="comment"># function 내의 python 문법으로 입력된 모든 tensor 연산들을 tf.function에 의해서</span></span><br><span class="line"><span class="comment"># 최적화된다.</span></span><br><span class="line">def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_metric):</span><br><span class="line">    <span class="comment"># Gradient를 계산하기위한</span></span><br><span class="line">    with tf.GradientTape() as tape:</span><br><span class="line">        predictions = model(inputs)</span><br><span class="line">        loss = loss_object(labels, predictions)</span><br><span class="line">    <span class="comment"># loss를 model의 trainable_variables(W,b)로 각각 미분해서 gradient를 구한것.</span></span><br><span class="line">    <span class="comment"># loss는 scalar이고, model.trainable_variables는 벡터이므로 결과 또한 벡터가 될 것이다.</span></span><br><span class="line">    gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 각 gradient와 trainable_variables들이 optimizer로 학습</span></span><br><span class="line">    optimizer.apply_gradients(zip(gradients, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loss를 종합</span></span><br><span class="line">    train_loss(loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># matric</span></span><br><span class="line">    train_metric(labels, predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 데이터셋 생성, 전처리</span></span><br><span class="line">np.random.seed(0)</span><br><span class="line"></span><br><span class="line">pts = []</span><br><span class="line">labels = []</span><br><span class="line"></span><br><span class="line">center_pts =  np.random.uniform(-8.0, 8.0, size=(10, 2))</span><br><span class="line"><span class="keyword">for</span> label, center_pt <span class="keyword">in</span> enumerate(center_pts):</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(100):</span><br><span class="line">        pts.append(center_pt + np.random.randn(*center_pt.shape))</span><br><span class="line">        labels.append(label)</span><br><span class="line"></span><br><span class="line"><span class="comment"># GPU를 사용하게 된다면 위의 MyModel class에서 initialize 할때</span></span><br><span class="line"><span class="comment"># Layer에 따로 dtype을 지정하지 않으면 float32로 설정되므로 동일하게 해주기 위해 type 재설정</span></span><br><span class="line">pts =  np.stack(pts, axis=0).astype(np.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이미 integer이므로 바꿀 필요가 없음.</span></span><br><span class="line">labels =  np.stack(labels, axis=0)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 위에서 만든 데이터를 train data set으로 변형</span></span><br><span class="line"><span class="comment"># train_ds는 iterable한 object가 된다.</span></span><br><span class="line"><span class="comment"># 1000개를 섞어 batch_size를 32개로 해서 구성해준다.</span></span><br><span class="line">train_ds =  tf.data.Dataset.from_tensor_slices((pts, labels)).shuffle(1000).batch(32)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pts.shape)</span><br><span class="line"><span class="built_in">print</span>(labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 모델 생성</span></span><br><span class="line">model = MyModel()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 손실 함수 및 최적화 알고리즘 설정</span></span><br><span class="line"><span class="comment">### CrossEntropy, Adam Optimizer</span></span><br><span class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class="line">optimizer = tf.keras.optimizers.Adam()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 평가 지표 설정</span></span><br><span class="line"><span class="comment">### Accuracy</span></span><br><span class="line">train_loss = tf.keras.metrics.Mean(name=<span class="string">'train_loss'</span>)</span><br><span class="line">train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">'train_accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 학습 루프</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line"></span><br><span class="line">    <span class="comment">#위에서 batch_size를 32로 했으므로 한번 실행시 32개씩 나옴.</span></span><br><span class="line">    <span class="keyword">for</span> x, label <span class="keyword">in</span> train_ds:</span><br><span class="line">        train_step(model, x, label, loss_object, optimizer, train_loss, train_accuracy)</span><br><span class="line"></span><br><span class="line">    template = <span class="string">'Epoch &#123;&#125;, Loss: &#123;&#125;, Accuracy: &#123;&#125;'</span></span><br><span class="line">    <span class="built_in">print</span>(template.format(epoch+1, train_loss.result(), train_accuracy.result()*100))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 데이터셋 및 학습 파라미터 저장</span></span><br><span class="line"><span class="comment"># 압축해서 여러개의 Numpy Object들을 저장할 수 있다.</span></span><br><span class="line">np.savez_compressed(<span class="string">'ch2_dataset.npz'</span>, inputs=pts, labels=labels)</span><br><span class="line"></span><br><span class="line">W_h, b_h = model.d1.get_weights()</span><br><span class="line">W_o, b_o = model.d2.get_weights()</span><br><span class="line"></span><br><span class="line"><span class="comment"># weight는 tensorflow에서 사용하고 있는 convention이랑</span></span><br><span class="line"><span class="comment"># shallowNN을 구현할 때 사용했던 convention이 좀 다르다.</span></span><br><span class="line">W_h = np.transpose(W_h)</span><br><span class="line">W_o = np.transpose(W_o)</span><br><span class="line"></span><br><span class="line">np.savez_compressed(<span class="string">'ch2_parameters.npz'</span>, W_h=W_h, b_h=b_h, W_o=W_o, b_o=b_o)</span><br></pre></td></tr></table></figure>

        </div>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 하단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="9861011486"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "HeungBae Lee"
        },
        "headline": "쉽게 배우는 경사하강 학습법",
        "image": "https://heung-bae-lee.github.io/image/supervised_learning_vs_unsupervised_learning.png",
        "keywords": "",
        "genre": "deep learning",
        "datePublished": "2019-12-08",
        "dateCreated": "2019-12-08",
        "dateModified": "2019-12-13",
        "url": "https://heung-bae-lee.github.io/2019/12/08/deep_learning_02/",
        "description": "쉽게 배우는 경사하강 학습법





어떤 손실 함수를 사용하느냐에 따라서 학습이 어떻게 이루어질 것인지, 그리고 학습을 할 때 정답의 형태를 결정하기 때문에 손실 함수는 중요하다!



Traning Data를 Model에 입력해 우리가 학습시키고자 하는 Trainable Parameters를 얻게 되는데 Trainable Parameters들을 inpu"
        "wordCount": 1238
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/heungbae.lee" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HEUNG-BAE-LEE" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2019/12/09/data_engineering_01/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            data engineering basic(Unix환경 및 커맨드)
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2019/12/08/deep_learning_03/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">심층 신경망의 구조</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/linear-algebra/">linear algebra</a></p>
                            <p class="item-title"><a href="/2020/06/09/linear_algebra_06/" class="title">Least Squares Problem &amp; Orthogonal Projection</a></p>
                            <p class="item-date"><time datetime="2020-06-09T14:12:36.000Z" itemprop="datePublished">2020-06-09</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/linear-algebra/">linear algebra</a></p>
                            <p class="item-title"><a href="/2020/06/09/linear_algebra_05/" class="title">Linear Transformation &amp; onto, ono-to-one의 개념</a></p>
                            <p class="item-date"><time datetime="2020-06-09T05:23:12.000Z" itemprop="datePublished">2020-06-09</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/linear-algebra/">linear algebra</a></p>
                            <p class="item-title"><a href="/2020/06/08/linear_algebra_04/" class="title">Linear Independence, Span, and Subspace</a></p>
                            <p class="item-date"><time datetime="2020-06-08T06:52:22.000Z" itemprop="datePublished">2020-06-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/06/06/machine_learning_21/" class="title">Imbalanced Data</a></p>
                            <p class="item-date"><time datetime="2020-06-05T16:52:20.000Z" itemprop="datePublished">2020-06-06</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/06/04/machine_learning_20/" class="title">Clustering - Hierarchical, DBSCAN, Affinity Propagation</a></p>
                            <p class="item-date"><time datetime="2020-06-04T13:46:15.000Z" itemprop="datePublished">2020-06-04</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bayes/">Bayes</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n/">CS231n</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Front-end/">Front end</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/crawling/">crawling</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-engineering/">data engineering</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/growth-hacking/">growth hacking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">22</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">21</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crawling/">crawling</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CS231n/" style="font-size: 10px;">CS231n</a> <a href="/tags/crawling/" style="font-size: 20px;">crawling</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 사이드바 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="3275421833"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 HeungBae Lee</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://heung-bae-lee.github.io/2019/12/08/deep_learning_02/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</body>
</html>
