<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    

    
    <title>Clustering - Hierarchical, DBSCAN, Affinity Propagation | DataLatte&#39;s IT Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    
    <meta name="description" content="Hierarchical clustering(계층적 군집화) 계층적 군집화(hierachical clustering)는 여러개의 군집 중에서 가장 유사도가 높은 혹은 거리가 가까운 군집 두개를 선택하여 하나로 합치면서 군집 개수를 줄여 가는 방법을 말한다. 합체 군집화(agglomerative clustering)라고도 한다. 가장 처음에는 모든 군집이 하나">
<meta property="og:type" content="article">
<meta property="og:title" content="Clustering - Hierarchical, DBSCAN, Affinity Propagation">
<meta property="og:url" content="https://heung-bae-lee.github.io/2020/06/04/machine_learning_19/index.html">
<meta property="og:site_name" content="DataLatte&#39;s IT Blog">
<meta property="og:description" content="Hierarchical clustering(계층적 군집화) 계층적 군집화(hierachical clustering)는 여러개의 군집 중에서 가장 유사도가 높은 혹은 거리가 가까운 군집 두개를 선택하여 하나로 합치면서 군집 개수를 줄여 가는 방법을 말한다. 합체 군집화(agglomerative clustering)라고도 한다. 가장 처음에는 모든 군집이 하나">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://heung-bae-lee.github.io/image/Hierachical_distance_conception_01.png">
<meta property="og:updated_time" content="2020-06-05T16:53:48.077Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Clustering - Hierarchical, DBSCAN, Affinity Propagation">
<meta name="twitter:description" content="Hierarchical clustering(계층적 군집화) 계층적 군집화(hierachical clustering)는 여러개의 군집 중에서 가장 유사도가 높은 혹은 거리가 가까운 군집 두개를 선택하여 하나로 합치면서 군집 개수를 줄여 가는 방법을 말한다. 합체 군집화(agglomerative clustering)라고도 한다. 가장 처음에는 모든 군집이 하나">
<meta name="twitter:image" content="https://heung-bae-lee.github.io/image/Hierachical_distance_conception_01.png">
<meta property="fb:app_id" content="100003222637819">


    <link rel="canonical" href="https://heung-bae-lee.github.io/2020/06/04/machine_learning_19/">

    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">
    <link rel="stylesheet" type="text/css" href>
    <link rel="stylesheet" href="https://cdn.rawgit.com/innks/NanumSquareRound/master/nanumsquareround.css">	
    <link rel="stylesheet" href="https://fonts.googleapis.com/earlyaccess/nanumgothiccoding.css">
    <link rel="stylesheet" href="/css/style.css">
   
    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-154199624-1', 'auto');
ga('send', 'pageview');

</script>

    
    


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4604833066889492" data-ad-slot="4588503508" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<link rel="alternate" href="/rss2.xml" title="DataLatte's IT Blog" type="application/rss+xml">
</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">DataLatte&#39;s IT Blog using Hexo</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Bayes/">Bayes</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/CS231n/">CS231n</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Front-end/">Front end</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/">Python</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/crawling/">crawling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/data-engineering/">data engineering</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/growth-hacking/">growth hacking</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/hexo/">hexo</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/linear-algebra/">linear algebra</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/machine-learning/">machine learning</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/machine-learning/">machine learning</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="4588503508"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

			    <article id="post-machine_learning_19" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Clustering - Hierarchical, DBSCAN, Affinity Propagation
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2020/06/04/machine_learning_19/" class="article-date">
            <time datetime="2020-06-04T13:46:15.000Z" itemprop="datePublished">2020-06-04</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h2 id="Hierarchical-clustering-계층적-군집화"><a href="#Hierarchical-clustering-계층적-군집화" class="headerlink" title="Hierarchical clustering(계층적 군집화)"></a>Hierarchical clustering(계층적 군집화)</h2><ul>
<li><code>계층적 군집화(hierachical clustering)는 여러개의 군집 중에서 가장 유사도가 높은 혹은 거리가 가까운 군집 두개를 선택하여 하나로 합치면서 군집 개수를 줄여 가는 방법</code>을 말한다. 합체 군집화(agglomerative clustering)라고도 한다. 가장 처음에는 모든 군집이 하나의 데이터만을 가진다. 따라서 <code>최초에는 데이터 개수만큼 군집이 존재하지만 군집을 합치면서 최종적으로 하나의 군집만 남게 된다.</code></li>
</ul>
<p><img src="/image/Hierachical_distance_conception_01.png" alt="계층적 군집화 개념 - 01"></p>
<p><img src="/image/Hierachical_distance_conception_02.png" alt="계층적 군집화 개념 - 02"></p>
<p><img src="/image/Hierachical_distance_conception_03.png" alt="계층적 군집화 개념 - 03"></p>
<p><img src="/image/Hierachical_distance_conception_04.png" alt="계층적 군집화 개념 - 04"></p>
<h3 id="군집간의-거리-측정"><a href="#군집간의-거리-측정" class="headerlink" title="군집간의 거리 측정"></a>군집간의 거리 측정</h3><ul>
<li>계층적 군집화를 하려면 우선 모든 군집 간에 거리를 측정해야 한다. <code>군집 간의 거리를 측정하는 방법에는 계층적 방법에 의존하지 않는 비계층적 방법과 이미 이전 단계에서 계층적 방법으로 군집이 합쳐진 적이 있다는 가정을 하는 계층적 방법 두 가지가 있다.</code></li>
</ul>
<h3 id="비계층적-거리-측정법"><a href="#비계층적-거리-측정법" class="headerlink" title="비계층적 거리 측정법"></a>비계층적 거리 측정법</h3><ul>
<li><code>비계층적 거리측정법</code>은 계층적 군집화가 아니더라도 <code>모든 경우에 사용할 수 있는 거리 측정 방법</code>이다. 중심거리, 단일거리, 완전거리, 평균거리 등이 있다. 다음에 설명할 계층적 거리측정법에 비해 <code>계산량이 많은 단점</code>이 있다.</li>
</ul>
<p><img src="/image/non_hierachical_distance_types.png" alt="비계층적 거리 측정 방법들"></p>
<h4 id="중심-centroid-거리"><a href="#중심-centroid-거리" class="headerlink" title="중심(centroid)거리"></a>중심(centroid)거리</h4><ul>
<li>두 군집의 중심점(centroid)를 정의한 다음 두 중심점의 거리를 군집간의 거리로 정의한다.</li>
</ul>
<script type="math/tex; mode=display">d(u,v) = \|c_u - c_v\|_2</script><ul>
<li>여기에서 $ d(u, v) $ 는 군집 $ u $ 와 군집  $ v $ 사이의 거리를 뜻한다. 또한 $ c_{u} $ 와 $ c_{v} $ 는 각각 두 군집 $ u $ 와 $ v $ 의 중심점이다. 군집의 중심점은 그 군집에 포함된 모든 데이터의 평균을 사용한다.</li>
</ul>
<script type="math/tex; mode=display">c_u = \dfrac{1}{|u|}\sum_i u_i</script><ul>
<li>이 식에서 $ |\cdot| $ 기호는 군집의 원소의 개수를 말한다.</li>
</ul>
<h4 id="단일-single-거리"><a href="#단일-single-거리" class="headerlink" title="단일(single)거리"></a>단일(single)거리</h4><ul>
<li>군집 $ u $ 의 모든 데이터 $ u_{i} $ 와 군집 $ v $ 의 모든 데이터 $ v_{j} $ 의 모든 조합에 대해 데이터 사이의 거리 $ d( u_{i}, v_{j} ) $ 를 측정해서 가장 작은 값을 구한다. 최소 거리(Nearest Point) 방법이라고도 한다.</li>
</ul>
<script type="math/tex; mode=display">d(u,v) = \min(d(u_i,v_j))</script><h4 id="완전-complete-거리"><a href="#완전-complete-거리" class="headerlink" title="완전(complete) 거리"></a>완전(complete) 거리</h4><ul>
<li>군집 $ u $ 의 모든 데이터 $ u_{i} $ 와 군집 $ v $ 의 모든 데이터 $ v_{j} $ 의 모든 조합에 대해 데이터 사이의 거리 $ d(u_{i}, v_{j}) $ 를 측정해서 가장 큰 값을 구한다. 최장 거리(Farthest Point) 방법이라고도 한다.</li>
</ul>
<script type="math/tex; mode=display">d(u,v) = \max(d(u_i,v_j))</script><h4 id="평균-average-거리"><a href="#평균-average-거리" class="headerlink" title="평균(average) 거리"></a>평균(average) 거리</h4><ul>
<li>군집 $ u $ 의 모든 데이터 $ u_{i} $ 와 군집 $ v $ 의 모든 데이터 $ v_{j} $ 의 모든 조합에 대해 데이터 사이의 거리 $ d(u_{i}, v_{j}) $ 를 측정해서 평균을 구한다. $ |u| $ 와 $ |v| $ 는 각각 두 군집의 원소의 개수를 뜻한다.</li>
</ul>
<script type="math/tex; mode=display">d(u,v) = \sum_{i,j} \frac{d(u_i, v_j)}{|u||v|}</script><h3 id="계층적-거리-측정법"><a href="#계층적-거리-측정법" class="headerlink" title="계층적 거리 측정법"></a>계층적 거리 측정법</h3><ul>
<li>계층적 거리 측정법은 <code>계층적 군집화에서만 사용할 수 있는 방법</code>이다. 즉, 이전 단계에서 이미 어떤 두 개의 군집이 하나로 합쳐진 적이 있다고 가정하여 이 정보를 사용하는 측정법이다. <code>비계층적 거리 측정법에 비해 계산량이 적어 효율적</code>이다.</li>
</ul>
<h4 id="중앙값-median-거리"><a href="#중앙값-median-거리" class="headerlink" title="중앙값(median)거리"></a>중앙값(median)거리</h4><ul>
<li>이 방법은 중심거리 방법의 변형이다. 중심거리 방법처럼 군집의 중심점의 거리를 군집간의 거리라고 한다. 하지만 군집의 중심점을 계산하는 방법이 다르다. 만약 군집 $ u $ 가 군집 $ s $ 와 군집 $ t $ 가 결합하여 생겼다면</li>
</ul>
<script type="math/tex; mode=display">u \leftarrow s + t</script><ul>
<li>군집 $ u $ 의 중심점은 새로 계산하지 않고 원래 군집의 두 군집의 중심정의 평균을 사용한다.</li>
</ul>
<script type="math/tex; mode=display">c_u = \dfrac{1}{2}(c_s + s_t)</script><ul>
<li>따라서 해당 군집의 모든 데이터를 평균하여 중심점을 구하는 것 보다 계산이 빠르다.</li>
</ul>
<h4 id="가중-weighted-거리"><a href="#가중-weighted-거리" class="headerlink" title="가중(weighted)거리"></a>가중(weighted)거리</h4><ul>
<li>가중거리를 사용하려면 원래 어떤 두 개의 군집이 합쳐져서 하나의 군집이 만들어졌는지 알아야 한다. 만약 군집 $ u $ 가 군집 $ s $ 와 군집 $ t $ 가 결합하여 생겼다면</li>
</ul>
<script type="math/tex; mode=display">u \leftarrow s + t</script><ul>
<li>이 군집 $ u $ 와 다른 군집 $ v $ 사이의 거리는 군집 $ u $ 를 구성하는 원래 군집 $ s $, $ t $ 와 $ v $ 사이의 두 거리의 평균을 사용한다.</li>
</ul>
<script type="math/tex; mode=display">d(u,v) = \dfrac{1}{2}(d(s,v) + d(t,v))</script><p><img src="/image/weighted_distance_hierachical_distance.png" alt="계층적 거리 - 가중 거리"></p>
<h4 id="와드-Ward-거리"><a href="#와드-Ward-거리" class="headerlink" title="와드(Ward)거리"></a>와드(Ward)거리</h4><p><img src="/image/hierachical_distance_type_ward_distance.png" alt="계층적 거리 - 와드 거리 개념"></p>
<ul>
<li>와드 거리는 <code>가중거리 방법의 변형</code>이다. 만약 군집 $ u $ 가 군집 $ s $ 와 군집 $ t $ 가 결합하여 생겼다면</li>
</ul>
<script type="math/tex; mode=display">u \leftarrow s + t</script><ul>
<li>이 군집 $ u $ 와 다른 군집 $ v $ 사이의 거리를 구하는데 있어서 군집 $ u $ 를 구성하는 원래 군집 $ s $, $ t $ 와  $ v $ 사이의 거리를 사용하는 것은 가중거리 방법과 같지만 원래의 두 군집 $ s $, $ t $ 가 너무 가까우면 $ v $ 와의 거리가 더 먼것으로 인식한다.</li>
</ul>
<script type="math/tex; mode=display">d(u,v) = \sqrt{\frac{|v|+|s|}{|v|+|s|+|t|}d(v,s)^2 + \frac{|v|+|t|}{|v|+|s|+|t|}d(v,t)^2 - \frac{|v|}{|v|+|s|+|t|}d(s,t)^2}</script><p><img src="/image/ward_distance_hierachical_distance.png" alt="계층적 거리 - 와드 거리"></p>
<h4 id="Scipy의-계층적-군집화"><a href="#Scipy의-계층적-군집화" class="headerlink" title="Scipy의 계층적 군집화"></a>Scipy의 계층적 군집화</h4><ul>
<li>Python으로 계층적 군집화를 하려면 Scipy 패키지의 <code>linkage</code> 명령을 사용하거나 Scikit-Learn 패키지의 <code>AgglomerativeClustering</code> 클래스를 사용한다. 각각 장단점이 있는데 Scipy 패키지는 군집화 결과를 트리 형태로 시각화해주는 <code>dendrogram</code> 명령도 지원한다.</li>
</ul>
<ul>
<li>MNIST digit 이미지 중 20개의 이미지를 무작위로 골라 계층적 군집화를 적용해 볼 것이다.</li>
</ul>
<hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import load_digits</span><br><span class="line"></span><br><span class="line">digits = load_digits()</span><br><span class="line">n_image = 20</span><br><span class="line">np.random.seed(0)</span><br><span class="line">idx = np.random.choice(range(len(digits.images)), n_image)</span><br><span class="line">X = digits.data[idx]</span><br><span class="line">images = digits.images[idx]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(20, 15))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_image):</span><br><span class="line">    plt.subplot(1, n_image, i + 1)</span><br><span class="line">    plt.imshow(images[i], cmap=plt.cm.bone)</span><br><span class="line">    plt.grid(False)</span><br><span class="line">    plt.xticks(())</span><br><span class="line">    plt.yticks(())</span><br><span class="line">    plt.title(i)</span><br><span class="line"><span class="comment"># plt.savefig("random_sample_MNIST")</span></span><br></pre></td></tr></table></figure>
<hr>
<p><img src="/image/random_sample_MNIST.png" alt="임의로 추출한 MNIST 이미지"></p>
<hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from scipy.cluster.hierarchy import linkage, dendrogram</span><br><span class="line"></span><br><span class="line">Z = linkage(X, <span class="string">'ward'</span>)</span><br><span class="line">Z</span><br></pre></td></tr></table></figure>
<h5 id="결과"><a href="#결과" class="headerlink" title="결과"></a>결과</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">array([[ 3.        , 18.        , 23.51595203,  2.        ],</span><br><span class="line">       [13.        , 19.        , 25.27844932,  2.        ],</span><br><span class="line">       [ 1.        , 14.        , 28.67054237,  2.        ],</span><br><span class="line">       [17.        , 21.        , 31.04298096,  3.        ],</span><br><span class="line">       [ 4.        ,  7.        , 31.51190251,  2.        ],</span><br><span class="line">       [ 6.        ,  8.        , 32.54228019,  2.        ],</span><br><span class="line">       [ 9.        , 10.        , 33.36165464,  2.        ],</span><br><span class="line">       [ 0.        , 24.        , 34.51086785,  3.        ],</span><br><span class="line">       [ 2.        , 22.        , 37.03151811,  3.        ],</span><br><span class="line">       [11.        , 26.        , 43.25505751,  3.        ],</span><br><span class="line">       [12.        , 15.        , 45.31004304,  2.        ],</span><br><span class="line">       [16.        , 20.        , 45.36151085,  3.        ],</span><br><span class="line">       [ 5.        , 27.        , 53.54437412,  4.        ],</span><br><span class="line">       [30.        , 32.        , 56.6892112 ,  6.        ],</span><br><span class="line">       [25.        , 29.        , 60.16809786,  5.        ],</span><br><span class="line">       [28.        , 34.        , 66.61618922,  8.        ],</span><br><span class="line">       [31.        , 33.        , 70.35228813,  9.        ],</span><br><span class="line">       [23.        , 36.        , 80.11172754, 12.        ],</span><br><span class="line">       [35.        , 37.        , 93.57946712, 20.        ]])</span><br></pre></td></tr></table></figure>
<hr>
<hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">from matplotlib.offsetbox import OffsetImage, AnnotationBbox</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(10, 4))</span><br><span class="line">ax = plt.subplot()</span><br><span class="line"></span><br><span class="line">ddata = dendrogram(Z)</span><br><span class="line"></span><br><span class="line">dcoord = np.array(ddata[<span class="string">"dcoord"</span>])</span><br><span class="line">icoord = np.array(ddata[<span class="string">"icoord"</span>])</span><br><span class="line">leaves = np.array(ddata[<span class="string">"leaves"</span>])</span><br><span class="line">idx = np.argsort(dcoord[:, 2])</span><br><span class="line">dcoord = dcoord[idx, :]</span><br><span class="line">icoord = icoord[idx, :]</span><br><span class="line">idx = np.argsort(Z[:, :2].ravel())</span><br><span class="line">label_pos = icoord[:, 1:3].ravel()[idx][:20]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(20):</span><br><span class="line">    imagebox = OffsetImage(images[i], cmap=plt.cm.bone_r, interpolation=<span class="string">"bilinear"</span>, zoom=3)</span><br><span class="line">    ab = AnnotationBbox(imagebox, (label_pos[i], 0),  box_alignment=(0.5, -0.1),</span><br><span class="line">                        bboxprops=&#123;<span class="string">"edgecolor"</span> : <span class="string">"none"</span>&#125;)</span><br><span class="line">    ax.add_artist(ab)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.grid()</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/MNIST_hierachical_clustering_random_index_20.png" alt="MNIST 임의 20개 이미지의 계층적 군집화 결과"></p>
<h3 id="DBSCAN-Clustering"><a href="#DBSCAN-Clustering" class="headerlink" title="DBSCAN Clustering"></a>DBSCAN Clustering</h3><ul>
<li>K-means 군집화 방법은 단순하고 강력한 방법이지만 군집의 모양이 원형이 아닌 경우에는 잘 동작하지 않으며 군집의 개수를 사용자가 지정해 주어야 한다는 단점이 있다.</li>
</ul>
<ul>
<li><p>DBSCAN(Density-Based Spatial Clustering of Application with Noise) 군집화 방법은 데이터가 밀집한 정도 즉, 밀도를 이용한다. DBSCAN 군집화는 군집의 형태에 구애받지 않으며 군집의 갯수를 사용자가 지정할 필요가 없다. DBSCAN 군집화 방법에서는 초기 데이터로부터 근접한 데이터를 찾아나가는 방법으로 군집을 확장한다. 이 때 다음 사용자 인수를 사용한다.</p>
<ul>
<li>최소거리 $ \varepsilon $ : 이웃(neighborhood)을 정의하기 위한 거리</li>
<li>최소 데이터 개수(minimum points) : 밀집지역을 정의하기 위해 필요한 이웃의 개수</li>
</ul>
</li>
</ul>
<p><img src="/image/what_is_DBSCAN_cinception.png" alt="DBSCAN 개념"></p>
<ul>
<li>만약 $ \varepsilon $ 최소 거리 안의 이웃 영역 안에 최소 데이터 개수 이상의 데이터가 있으면  그 데이터는 핵심(core) 데이터이다. 이렇게 핵심 데이터를 찾아낸 다음에는 이 핵심 데이터의 이웃 영역 안에 있는 데이터를 이 핵심데이터와 연결된 핵심 데이터로 정의한다. 핵심 데이터의 이웃 영역안에 있는 데이터도 마찬가지로 연결된 핵심 데이터가 된다. 만약 고밀도 데이터에 더이상 이웃이 없으면 이 데이터는 경계(border) 데이터라고 한다. 핵심 데이터도 아니고 경계 데이터도 아닌 데이터를 outlier라고 한다.</li>
</ul>
<p><img src="/image/how_to_DBSCAN_clustering.png" alt="DBSCAN"></p>
<p><img src="/image/how_to_make_cluster_in_DBSCAN_Algorithme.png" alt="DBSCAN 알고리즘"></p>
<p><img src="/image/DBSCAN_examples.png" alt="DBSCAN 알고리즘 예시들"></p>
<ul>
<li>Scikit-learn의 cluster 서브패키지는 DBSCAN 클래스를 제공한다. 다음과 같은 인수를 받을 수 있다.<ul>
<li><code>eps</code> : 이웃을 정의하기 위한 거리. epsilon</li>
<li><code>min_samples</code> : 핵심 데이터를 정의하기 위해 필요한 이웃영역안의 데이터 개수.</li>
</ul>
</li>
</ul>
<p><img src="/image/DBSCAN_parameters_setting_tip.png" alt="DBSCAN 파라미터 설정시 유의점"></p>
<ul>
<li>군집화가 끝나면 객체는 다음 속성을 갖는다.<ul>
<li><code>labels_</code> : 군집번호. 아웃라이어는 -1 값을 갖는다.</li>
<li><code>core_sample_indices_</code> : 핵심 데이터의 인덱스. 여기에 포함되지 않고 outlier도 아닌 데이터는 경계 데이터이다.</li>
</ul>
</li>
</ul>
<p><img src="/image/DBSCAN_advantages_disadvantages.png" alt="DBSCAN 군집화의 장단점"></p>
<ul>
<li>다음은 <code>make_circles</code> 명령과 <code>make_moons</code> 명령으로 만든 동심원, 초승달 데이터를 DBSCAN으로 군집화한 결과를 나타낸 것이다. 마커(marker)의 모양은 군집을 나타내고 마커의 크기가 큰 데이터는 핵심데이터, x 표시된 데이터는 outlier이다.</li>
</ul>
<hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import make_circles, make_moons</span><br><span class="line">from sklearn.cluster import DBSCAN</span><br><span class="line"></span><br><span class="line">n_samples = 1000</span><br><span class="line">np.random.seed(2)</span><br><span class="line">X1, y1 = make_circles(n_samples=n_samples, factor=.5, noise=.09)</span><br><span class="line">X2, y2 = make_moons(n_samples=n_samples, noise=.1)</span><br><span class="line"></span><br><span class="line">def plot_DBSCAN(title, X, eps, xlim, ylim):</span><br><span class="line">    model = DBSCAN(eps=eps)</span><br><span class="line">    y_pred = model.fit_predict(X)</span><br><span class="line">    idx_outlier = model.labels_ == -1</span><br><span class="line">    plt.scatter(X[idx_outlier, 0], X[idx_outlier, 1], marker=<span class="string">'x'</span>, lw=1, s=20)</span><br><span class="line">    plt.scatter(X[model.labels_ == 0, 0], X[model.labels_ == 0, 1], marker=<span class="string">'o'</span>, facecolor=<span class="string">'g'</span>, s=5)</span><br><span class="line">    plt.scatter(X[model.labels_ == 1, 0], X[model.labels_ == 1, 1], marker=<span class="string">'s'</span>, facecolor=<span class="string">'y'</span>, s=5)</span><br><span class="line">    X_core = X[model.core_sample_indices_, :]</span><br><span class="line">    idx_core_0 = np.array(list(<span class="built_in">set</span>(np.where(model.labels_ == 0)[0]).intersection(model.core_sample_indices_)))</span><br><span class="line">    idx_core_1 = np.array(list(<span class="built_in">set</span>(np.where(model.labels_ == 1)[0]).intersection(model.core_sample_indices_)))</span><br><span class="line">    plt.scatter(X[idx_core_0, 0], X[idx_core_0, 1], marker=<span class="string">'o'</span>, facecolor=<span class="string">'g'</span>, s=80, alpha=0.3)</span><br><span class="line">    plt.scatter(X[idx_core_1, 0], X[idx_core_1, 1], marker=<span class="string">'s'</span>, facecolor=<span class="string">'y'</span>, s=80, alpha=0.3)</span><br><span class="line">    plt.grid(False)</span><br><span class="line">    plt.xlim(*xlim)</span><br><span class="line">    plt.ylim(*ylim)</span><br><span class="line">    plt.xticks(())</span><br><span class="line">    plt.yticks(())</span><br><span class="line">    plt.title(title)</span><br><span class="line">    <span class="built_in">return</span> y_pred</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(10, 5))</span><br><span class="line">plt.subplot(121)</span><br><span class="line">y_pred1 = plot_DBSCAN(<span class="string">"동심원 군집"</span>, X1, 0.1, (-1.2, 1.2), (-1.2, 1.2))</span><br><span class="line">plt.subplot(122)</span><br><span class="line">y_pred2 = plot_DBSCAN(<span class="string">"초승달 군집"</span>, X2, 0.1, (-1.5, 2.5), (-0.8, 1.2))</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<hr>
<p><img src="/image/different_result_of_each_clustering_data.png" alt="군집을 이루는 모양에 따른 DBSCAN 결과"></p>
<hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">labels = pd.DataFrame(iris.target)</span><br><span class="line">labels.columns=[<span class="string">'labels'</span>]</span><br><span class="line">data = pd.DataFrame(iris.data)</span><br><span class="line">data.columns=[<span class="string">'Sepal length'</span>,<span class="string">'Sepal width'</span>,<span class="string">'Petal length'</span>,<span class="string">'Petal width'</span>]</span><br><span class="line">data = pd.concat([data,labels],axis=1)</span><br><span class="line"></span><br><span class="line">feature = data[ [<span class="string">'Sepal length'</span>,<span class="string">'Sepal width'</span>,<span class="string">'Petal length'</span>,<span class="string">'Petal width'</span>]]</span><br></pre></td></tr></table></figure>
<hr>
<hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.cluster import DBSCAN</span><br><span class="line">import matplotlib.pyplot  as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model and prediction</span></span><br><span class="line">model = DBSCAN(eps=0.5,min_samples=5)</span><br><span class="line">predict = pd.DataFrame(model.fit_predict(feature))</span><br><span class="line">predict.columns=[<span class="string">'predict'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># concatenate labels to df as a new column</span></span><br><span class="line">r = pd.concat([feature,predict],axis=1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure>
<h5 id="결과-1"><a href="#결과-1" class="headerlink" title="결과"></a>결과</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Sepal length  Sepal width  Petal length  Petal width  predict</span><br><span class="line">0             5.1          3.5           1.4          0.2        0</span><br><span class="line">1             4.9          3.0           1.4          0.2        0</span><br><span class="line">2             4.7          3.2           1.3          0.2        0</span><br><span class="line">3             4.6          3.1           1.5          0.2        0</span><br><span class="line">4             5.0          3.6           1.4          0.2        0</span><br><span class="line">..            ...          ...           ...          ...      ...</span><br><span class="line">145           6.7          3.0           5.2          2.3        1</span><br><span class="line">146           6.3          2.5           5.0          1.9        1</span><br><span class="line">147           6.5          3.0           5.2          2.0        1</span><br><span class="line">148           6.2          3.4           5.4          2.3        1</span><br><span class="line">149           5.9          3.0           5.1          1.8        1</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="DBSCAN-결과-시각화"><a href="#DBSCAN-결과-시각화" class="headerlink" title="DBSCAN 결과 시각화"></a>DBSCAN 결과 시각화</h4><hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#pairplot with Seaborn</span></span><br><span class="line">sns.pairplot(r,hue=<span class="string">'predict'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<hr>
<p><img src="/image/DBSCAN_with_iris.png" alt="iris 데이터를 DBSCAN 군집한 결과"></p>
<hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#pairplot with Seaborn</span></span><br><span class="line">sns.pairplot(data,hue=<span class="string">'labels'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<hr>
<p><img src="/image/iris_raw.png" alt="iris raw 데이터의 pair plot"></p>
<h4 id="Kmeans-결과와-비교"><a href="#Kmeans-결과와-비교" class="headerlink" title="Kmeans 결과와 비교"></a>Kmeans 결과와 비교</h4><hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">km = KMeans(n_clusters = 3, n_jobs = 4, random_state=21)</span><br><span class="line">km.fit(feature)</span><br><span class="line">new_labels =pd.DataFrame(km.labels_)</span><br><span class="line">new_labels.columns=[<span class="string">'predict'</span>]</span><br><span class="line">r2 = pd.concat([feature,new_labels],axis=1)</span><br></pre></td></tr></table></figure>
<hr>
<hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#pairplot with Seaborn</span></span><br><span class="line">sns.pairplot(r2,hue=<span class="string">'predict'</span>)</span><br><span class="line">plt.savefig(<span class="string">'k_means_iris_pair_plot'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<hr>
<ul>
<li><code>DBSCAN의 결과보다 더 좋게 군집을 나눈것을 볼 수 있다. K-means는 원형으로 군집을 이룬 데이터에 대해 더 예측력이 좋다는 사실을 확인할 수 있다. 또한, K-means는 대체로 균등적으로 군집의 데이터를 나누어 주기 때문에 아래 그림에서 볼 수 있듯이 군집마다 데이터의 개수가 비슷해 보인다.</code></li>
</ul>
<p><img src="/image/k_means_iris_pair_plot.png" alt="k-means 군집화 결과의 pair plot"></p>
<blockquote>
<p>참고로, DBSCAN의 파라미터에 민감한 단점을 보완한 HDBSCAN이 있다.</p>
</blockquote>
<hr>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install hdbscan</span><br></pre></td></tr></table></figure>
<hr>
<p><a href="https://godongyoung.github.io/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2019/07/15/HDBSCAN-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-(with-python" target="_blank" rel="noopener">참조</a>.html)</p>

        </div>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 하단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="9861011486"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "HeungBae Lee"
        },
        "headline": "Clustering - Hierarchical, DBSCAN, Affinity Propagation",
        "image": "https://heung-bae-lee.github.io/image/Hierachical_distance_conception_01.png",
        "keywords": "",
        "genre": "machine learning",
        "datePublished": "2020-06-04",
        "dateCreated": "2020-06-04",
        "dateModified": "2020-06-06",
        "url": "https://heung-bae-lee.github.io/2020/06/04/machine_learning_19/",
        "description": "Hierarchical clustering(계층적 군집화)
계층적 군집화(hierachical clustering)는 여러개의 군집 중에서 가장 유사도가 높은 혹은 거리가 가까운 군집 두개를 선택하여 하나로 합치면서 군집 개수를 줄여 가는 방법을 말한다. 합체 군집화(agglomerative clustering)라고도 한다. 가장 처음에는 모든 군집이 하나"
        "wordCount": 3172
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/heungbae.lee" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HEUNG-BAE-LEE" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2020/06/06/machine_learning_20/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            Imbalanced Data
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2020/05/30/machine_learning_18/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">Clustering - K-means, K-medoid</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/06/06/machine_learning_20/" class="title">Imbalanced Data</a></p>
                            <p class="item-date"><time datetime="2020-06-05T16:52:20.000Z" itemprop="datePublished">2020-06-06</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/06/04/machine_learning_19/" class="title">Clustering - Hierarchical, DBSCAN, Affinity Propagation</a></p>
                            <p class="item-date"><time datetime="2020-06-04T13:46:15.000Z" itemprop="datePublished">2020-06-04</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/05/30/machine_learning_18/" class="title">Clustering - K-means, K-medoid</a></p>
                            <p class="item-date"><time datetime="2020-05-29T16:01:30.000Z" itemprop="datePublished">2020-05-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/05/29/machine_learning_17/" class="title">Clustering</a></p>
                            <p class="item-date"><time datetime="2020-05-28T18:17:21.000Z" itemprop="datePublished">2020-05-29</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/05/27/machine_learning_16/" class="title">Ensemble Learning - Ensemble의 Ensemble</a></p>
                            <p class="item-date"><time datetime="2020-05-26T17:04:18.000Z" itemprop="datePublished">2020-05-27</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bayes/">Bayes</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n/">CS231n</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Front-end/">Front end</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/crawling/">crawling</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-engineering/">data engineering</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/growth-hacking/">growth hacking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">21</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crawling/">crawling</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CS231n/" style="font-size: 10px;">CS231n</a> <a href="/tags/crawling/" style="font-size: 20px;">crawling</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 사이드바 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="3275421833"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 HeungBae Lee</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://heung-bae-lee.github.io/2020/06/04/machine_learning_19/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</body>
</html>
