<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    

    
    <title>NLP 실습 Chat bot 만들기 | DataLatte&#39;s IT Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    
    <meta name="description" content="지금까지 두 가지 문제에 대해 실습을 진행하였다. 1) 텍스트를 분석해서 각 텍스트를 분류하는 문제를 실습했고, 2) 두 개의 텍스트가 있을 때 각 텍스트끼리의 유사도를 판단하는 문제를 실습했다. 마지막으로 이번에는 텍스트를 단순히 분석해서 분류나 유사도를 측정하는 것이 아닌 직업 문장을 생성할 수 있는 text generation 문제를 실습해 볼 것이">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP 실습 Chat bot 만들기">
<meta property="og:url" content="https://heung-bae-lee.github.io/2020/02/11/NLP_12/index.html">
<meta property="og:site_name" content="DataLatte&#39;s IT Blog">
<meta property="og:description" content="지금까지 두 가지 문제에 대해 실습을 진행하였다. 1) 텍스트를 분석해서 각 텍스트를 분류하는 문제를 실습했고, 2) 두 개의 텍스트가 있을 때 각 텍스트끼리의 유사도를 판단하는 문제를 실습했다. 마지막으로 이번에는 텍스트를 단순히 분석해서 분류나 유사도를 측정하는 것이 아닌 직업 문장을 생성할 수 있는 text generation 문제를 실습해 볼 것이">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://heung-bae-lee.github.io/image/the_zone_online_center.png">
<meta property="og:updated_time" content="2020-02-18T13:56:14.751Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NLP 실습 Chat bot 만들기">
<meta name="twitter:description" content="지금까지 두 가지 문제에 대해 실습을 진행하였다. 1) 텍스트를 분석해서 각 텍스트를 분류하는 문제를 실습했고, 2) 두 개의 텍스트가 있을 때 각 텍스트끼리의 유사도를 판단하는 문제를 실습했다. 마지막으로 이번에는 텍스트를 단순히 분석해서 분류나 유사도를 측정하는 것이 아닌 직업 문장을 생성할 수 있는 text generation 문제를 실습해 볼 것이">
<meta name="twitter:image" content="https://heung-bae-lee.github.io/image/the_zone_online_center.png">
<meta property="fb:app_id" content="100003222637819">


    <link rel="canonical" href="https://heung-bae-lee.github.io/2020/02/11/nlp_12/">

    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-154199624-1', 'auto');
ga('send', 'pageview');

</script>

    
    


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4604833066889492" data-ad-slot="4588503508" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<link rel="alternate" href="/rss2.xml" title="DataLatte's IT Blog" type="application/rss+xml">
</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">DataLatte&#39;s IT Blog using Hexo</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Bayes/">Bayes</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/CS231n/">CS231n</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Front-end/">Front end</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/crawling/">crawling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/data-engineering/">data engineering</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/growth-hacking/">growth hacking</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/hexo/">hexo</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/linear-algebra/">linear algebra</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/machine-learning/">machine learning</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/NLP/">NLP</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="4588503508"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

			    <article id="post-NLP_12" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        NLP 실습 Chat bot 만들기
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2020/02/11/NLP_12/" class="article-date">
            <time datetime="2020-02-11T08:16:56.000Z" itemprop="datePublished">2020-02-11</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <ul>
<li>지금까지 두 가지 문제에 대해 실습을 진행하였다. 1) 텍스트를 분석해서 각 텍스트를 분류하는 문제를 실습했고, 2) 두 개의 텍스트가 있을 때 각 텍스트끼리의 유사도를 판단하는 문제를 실습했다. 마지막으로 이번에는 텍스트를 단순히 분석해서 분류나 유사도를 측정하는 것이 아닌 직업 문장을 생성할 수 있는 text generation 문제를 실습해 볼 것이다. text generation에도 많은 문제가 있지만 ‘자연어의 꽃’이라고 불리는 ‘Chat bot’을 제작해 볼 것이다.</li>
</ul>
<h1 id="Chat-bot-만들기"><a href="#Chat-bot-만들기" class="headerlink" title="Chat bot 만들기"></a>Chat bot 만들기</h1><ul>
<li><p>일반적으로 chat bot을 제작하는 방법은 매우 다양하다. 단순하게 rule based 기반으로 제작할 수도 있고, machine learning을 섞은 hybrid 기반, 특정 시나리오에서 동작 가능해지는 시나리오 기반까지 정의하는 사람에 따라 제작 방법이 매우 다양하다. 물론, 정의하는 것은 어디까지나 가용할 데이터의 성격에 매우 의존적일 것이다.</p>
</li>
<li><p>필자는 우선 제작방법 중에서 딥러닝 모델을 통한 chat bot을 만들어 볼 것이다. 또한 chat bot을 만들기 위한 딥러닝 모델에도 여러 가지가 있지만 그 중에서 번역 문제에서 이미 성능이 입증 된 Seq2seq를 활용하여 제작할 것이다.</p>
</li>
<li><p>이번 실습의 소개는 프로젝트성으로 진행 할 것이다.</p>
</li>
</ul>
<h3 id="프로젝트-소개"><a href="#프로젝트-소개" class="headerlink" title="프로젝트 소개"></a>프로젝트 소개</h3><h4 id="더존-ICT-온라인-고객센터-키워드-검색-최적화-및-챗봇-구현"><a href="#더존-ICT-온라인-고객센터-키워드-검색-최적화-및-챗봇-구현" class="headerlink" title="더존 ICT 온라인 고객센터 키워드 검색 최적화 및 챗봇 구현"></a>더존 ICT 온라인 고객센터 키워드 검색 최적화 및 챗봇 구현</h4><ul>
<li><p>프로젝트를 하게 된 계기</p>
<ul>
<li><p>먼저, 더존 온라인 고객센터 페이지 중 smart A에 관한 페이지에서 전체 탭을 클릭한 후, 살펴본 QnA 페이지를 살펴보았다.</p>
<p><img src="/image/the_zone_online_center.png" alt="더존 온라인 고객센터"></p>
</li>
<li><p><code>필자는 고객들의 입장에서 생각해보았을때, 자신이 작성하는 질문(물론, 그림으로 첨부해야할 만큼 그 환경이 중요한 질문들은 제외하고)과 비슷한 질문들이 존재할 거라는 생각을 갖고 키워드를 통해 검색해볼 것</code>이다. 아래 그림은 <code>재입사자</code>라는 키워드를 smart A페이지에서 검색했을 때 출력되는 결과이다. 11건의 총 검색 결과 중 <code>재입사자에 대한 연말정산과 관련된 문건이 8건이 존재</code>한다.</p>
<p><img src="/image/smart_A_search_for_recruit.png" alt="smart A에서 재입사라는 키워드에 관한 검색 결과"></p>
</li>
<li><p>그래서 필자는 <code>재입사자 연말정산</code>이라는 키워드를 통해 검색을 해보았다. 위에서 재입사자라는 키워드를 통해 검색 했을 때, 재입사자의 연말정산에 대한 질문이 8건이 존재한 반면에 아래 그림에서와 같이 8건 중 5건 만을 보여준다.</p>
<p><img src="/image/smart_A_search_for_recruit_year.png" alt="smart A에서 재입사자 연말정산이라는 키워드에 관한 검색 결과">  </p>
</li>
<li><p>필자는 질문의 내용이 아닌 질문의 제목에 재입사자 연말정산이라는 키워드가 8건이 존재할 뿐 내용은 그와는 다를 수도 있다는 생각이 들어, 검색결과에 포함되어 있지 않는 질문들을 살펴보았다. 또한, 질문 내용 자체가 본질적으로 물어보는 의미가 검색결과에 포함되지 않은 질문들은 다를 수도 있기에 특정 알고리즘을 통해 결과를 보여줄 수 있다는 생각이 들어 검색 결과에 포함된 질문과도 비교해 보기로 했다.</p>
<p><img src="/image/non_search_for_recruit.png" alt="검색결과에 포함되지 않은 질문과 답변들"></p>
</li>
<li><p>검색결과에 포함되지 않은 질문과 답변이 왼쪽 그림이고, 검색결과에 포함된 질문과 답변이 오른쪽의 빨강색 네모로 되어있는 그림이다. 두 질문은 비슷한 질문이라고 보인다. 그런데도 불구하고 재입사자 연말정산이라는 키워드 검색 결과에 포함되어 있지 않는 점을 통해 필자는 <code>각각의 질문들과 검색 키워드 간의 유사성을 점수화해 유사성이 높은 질문들을 보여주는 시스템</code>도입이 필요할 것 같다는 생각이 들었다.</p>
<p><img src="/image/between_difference_search_non_search.png" alt="검색결과에 포함되지 않은 질문과 답변, 검색결과에 포함된 질문과 답변"></p>
</li>
<li><p>또한, 챗봇을 만드는 부분에 있어서 입력과 출력의 문장의 sequence 길이를 맞춰주어야 하는데, 그에 따라서 답변이 특정 분야(예를들면, 연말정산이나 원천징수등)에서는 긴 문장으로 이루어질 수도 있으므로, 챗봇을 구현한다면, 각 분야에 따른 문장길이를 분석해 보기도 해야 할 것 같다는 생각이들었다.</p>
</li>
<li><p>이런 제한 상황으로 인해 챗봇 구현이 힘들다면, 질문과 검색 키워드 간의 유사도를 반영한 검색 결과를 통해서라도 더존 온라인 고객센터의 질문을 하시는 고객 분들에게 조금이나마 더 편의성을 드릴수 있게끔 하면 좋을 것 같다는 생각이 들었다.</p>
</li>
<li><p><code>더존 사이트내에서 영업 문의 전화나 구매자에 대한 상담은 따로 서비스를 제공하고 있지만, 온라인 고객센터 tap부분에서만 Q&amp;A에 관한 사항을 다루는데 답변을 해주는 시간은 업무 시간내로만 제한</code> 되어있다. 이에 따라 24시간 또는 업무 이외의 시간에는 <code>챗봇 서비스를 시행한다면 고객들의 입장에서 보았을 때 조금 더 편리하게 더존의 서비스나 솔루션을 이용할 수 있을 것이라는 취지에 의해서 챗봇 구현에 관심</code>을 갖게 되었다.</p>
</li>
</ul>
</li>
<li><p>데이터 이름 : qna_smart_a.csv</p>
<ul>
<li>더존에서는 WEHAGO 플랫폼상에서 여러가지 서비스를 제공하고 있다. 그 중 더존 Smart A는 재무회계, 세무신고, 인사·급여관리, 물류관리까지 중소기업의 업무를 통합적으로 관리할 수 있는 회계프로그램로서, 이 프로그램의 질문과 답변에 의해서만 먼저 학습을 해 볼 것이다. 그 이유는 다른 프로그램들(ERP와 WEHAGO)은 사용자들의 성격에 따라 다양한 용도로 개발 되어있지만, 회계프로그램인 Smart A는 모든 기업이 공용으로 사용하기 때문에 우선적으로 학습해 볼 것이다. 또한, 가장 주요한 선택 이유는 Q&amp;A 게시판의 데이터 중 가장 많은 데이터를 포함하고 있었기 때문이다.</li>
</ul>
</li>
<li><p>데이터 용도 :</p>
</li>
<li><p>데이터 출처 : <a href="http://help.douzone.com/pboard/index.jsp?code=qna10&amp;pid=10&amp;s_category_id=all&amp;type=all&amp;page=1" target="_blank" rel="noopener">더존 온라인 고객센터 Smart A 전체 tap</a>의 전체 질문과 답변들을 크롤링 해서 사용하였다. 크롤링 방식은 Scrapy를 통해 페이지를 순회하게끔 코드를 작성하여 크롤링해서 얻었다.</p>
</li>
<li><p>먼저, 더존 온라인 고객 센터페이지에서 질문과 답변을 크롤링해와서 데이터 셋을 구성할 것이다.</p>
</li>
</ul>
<h3 id="Spider-bot-만들기"><a href="#Spider-bot-만들기" class="headerlink" title="Spider bot 만들기"></a>Spider bot 만들기</h3><ul>
<li><p>전체 scrapy bot의 구성은 다음과 같다.</p>
</li>
<li><p>items.py와 settings.py를 활용했으며, 마지막 결과 파일은 csv로 저장했다. 혹시 db파일로 저장하고 싶다면 추가적으로 pipelines에서 작업을 하면된다. 더존 온라인 고객센터의 게시판에서 최근 게시판에서는 답변 완료상태인 데이터가 주로 많지만 예전 데이터 중에는 간간히 답변 대기 상태인 데이터가 존재한다. 그러므로 pipeline.py에서 이를 통해 답변 완료인 상태인 데이터만을 크롤링하여도 되지만, 필자는 어떤 데이터가 답변 대기 상태인 데이터인지 눈으로 살펴보기 위해 그냥 모두 크롤링하는 것으로 처리하였다.</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">thezone</span><br><span class="line">├── scrapy.cfg</span><br><span class="line">└── thezone</span><br><span class="line">    ├── __init__.py</span><br><span class="line">    ├── __pycache__</span><br><span class="line">    │   ├── __init__.cpython-37.pyc</span><br><span class="line">    │   ├── items.cpython-37.pyc</span><br><span class="line">    │   ├── pipelines.cpython-37.pyc</span><br><span class="line">    │   └── settings.cpython-37.pyc</span><br><span class="line">    ├── items.py</span><br><span class="line">    ├── middlewares.py</span><br><span class="line">    ├── pipelines.py</span><br><span class="line">    ├── settings.py</span><br><span class="line">    └── spiders</span><br><span class="line">        ├── __init__.py</span><br><span class="line">        ├── __pycache__</span><br><span class="line">        │   ├── __init__.cpython-37.pyc</span><br><span class="line">        │   └── qnacrawler.cpython-37.pyc</span><br><span class="line">        ├── last_qna_smart_a.csv</span><br><span class="line">        ├── qna_smart_a.csv</span><br><span class="line">        └── qnacrawler.py</span><br></pre></td></tr></table></figure>
<ul>
<li>qnacrawler.py</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import scrapy</span><br><span class="line">from scrapy.linkextractors import LinkExtractor</span><br><span class="line">from scrapy.spiders import CrawlSpider, Rule</span><br><span class="line">import sys</span><br><span class="line">sys.path.insert(0, <span class="string">'/Users/heungbaelee/workspace/project/chat_bot_project/thezone/thezone'</span>)</span><br><span class="line">from items import ThezoneItem</span><br><span class="line"></span><br><span class="line">class QnacrawlerSpider(CrawlSpider):</span><br><span class="line">    name = <span class="string">'qnacrawler'</span></span><br><span class="line">    allowed_domains = [<span class="string">'help.douzone.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://help.douzone.com/pboard/index.jsp?code=qna10&amp;pid=10&amp;s_category_id=all&amp;type=all&amp;s_listnum=50&amp;s_field=&amp;s_keyword='</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># rules = [</span></span><br><span class="line">    <span class="comment">#     Rule(LinkExtractor(allow=r'/pboard/index.jsp?code=qna10&amp;pid=10&amp;s_category_id=all&amp;type=all&amp;s_listnum=50&amp;s_field=&amp;s_keyword=&amp;page=\d+', ), callback='parse_parent', follow=True),</span></span><br><span class="line">    <span class="comment"># ]</span></span><br><span class="line">    rules = [</span><br><span class="line">        Rule(LinkExtractor(restrict_css=<span class="string">'div.page_box &gt; ul &gt; li:nth-child(n+4)'</span>,attrs=<span class="string">'href'</span>), callback=<span class="string">'parse_parent'</span>, follow=True),</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse_parent(self, response):</span><br><span class="line">        <span class="comment"># link = LinkExtractor(allow=r'/pboard/index.jsp?code=qna10&amp;pid=10&amp;s_category_id=all&amp;type=all&amp;s_listnum=50&amp;s_field=&amp;s_keyword=&amp;page=\d+')</span></span><br><span class="line">        <span class="comment"># links = link.extract_links(response)</span></span><br><span class="line">        <span class="comment"># print(links)</span></span><br><span class="line">        <span class="comment"># print(response.status)</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> response.css(<span class="string">'div.tab_cnt.mt30 &gt; table &gt; tbody &gt; tr'</span>):</span><br><span class="line">            article_num = url.css(<span class="string">'td:nth-child(1)::text'</span>).extract_first().strip()</span><br><span class="line">            self.logger.info(<span class="string">'Article number : %s'</span> % article_num)</span><br><span class="line">            article_link = url.css(<span class="string">'td:nth-child(3) &gt; a::attr(href)'</span>).extract_first().strip()</span><br><span class="line">            self.logger.info(<span class="string">'Article link : %s'</span> % article_link)</span><br><span class="line">            <span class="comment"># print(article_num, response.urljoin(article_link))</span></span><br><span class="line">            yield scrapy.Request(response.urljoin(article_link), self.parse_child, meta=&#123;<span class="string">'article_num'</span>: article_num&#125;)</span><br><span class="line"></span><br><span class="line">    def parse_child(self, response):</span><br><span class="line">        <span class="comment"># 부모, 자식 수신 정보 로깅</span></span><br><span class="line">        self.logger.info(<span class="string">'----------------------------------------'</span>)</span><br><span class="line">        self.logger.info(<span class="string">'Child Response URL : %s'</span> % response.url)</span><br><span class="line">        self.logger.info(<span class="string">'Child Response Status ; %s'</span> % response.status)</span><br><span class="line">        self.logger.info(<span class="string">'----------------------------------------'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 질문 번호</span></span><br><span class="line">        article_num = response.meta[<span class="string">'article_num'</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 유형</span></span><br><span class="line">        category = response.css(<span class="string">"div.qna_read.mt30 &gt; table:nth-child(1) &gt; tbody &gt; tr:nth-child(2) &gt; td &gt; dl &gt; dd:nth-child(2)::text"</span>).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 질문</span></span><br><span class="line">        question = <span class="string">""</span>.join(response.css(<span class="string">"div.qna_read.mt30 &gt; table:nth-child(1) &gt; tbody &gt; tr:nth-child(2) &gt; td &gt; div.q &gt; div.q_cnt &gt; p::text"</span>).extract()).strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 등록일</span></span><br><span class="line">        enrolled_date_time = response.css(<span class="string">"div.qna_read.mt30 &gt; table:nth-child(1) &gt; tbody &gt; tr:nth-child(1) &gt; td:nth-child(4)::text"</span>).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 작성일</span></span><br><span class="line">        answer_date_time = response.css(<span class="string">"table.mt10 &gt; tbody &gt; tr:nth-child(1) &gt; td:nth-child(4)::text"</span>).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 답변여부</span></span><br><span class="line">        answer_yes = response.css(<span class="string">"table.mt10 &gt; tbody &gt; tr:nth-child(1) &gt; td.ta_l &gt; span::text"</span>).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 답변</span></span><br><span class="line">        answering = <span class="string">""</span>.join(response.css(<span class="string">"table.mt10 &gt; tbody &gt; tr:nth-child(2) &gt; td.ta_l.pd20 &gt; div.a &gt; div &gt; p::text"</span>).extract()).strip()</span><br><span class="line"></span><br><span class="line">        yield ThezoneItem(article_num=article_num, category=category, enrolled_date_time=enrolled_date_time, question=question, answer_date_time=answer_date_time, answer_yes=answer_yes, answering=answering)</span><br></pre></td></tr></table></figure>
<ul>
<li>items.py</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://docs.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ThezoneItem(scrapy.Item):</span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    <span class="comment"># 문서번호</span></span><br><span class="line">    article_num = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 유형</span></span><br><span class="line">    category = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 질문</span></span><br><span class="line">    question = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 답변</span></span><br><span class="line">    answering = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 작성일</span></span><br><span class="line">    answer_date_time = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 등록일</span></span><br><span class="line">    enrolled_date_time = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 답변여부</span></span><br><span class="line">    answer_yes = scrapy.Field()</span><br></pre></td></tr></table></figure>
<ul>
<li>settings.py</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line">BOT_NAME = <span class="string">'thezone'</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">'thezone.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'thezone.spiders'</span></span><br><span class="line"></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;<span class="string">'Referer'</span> : <span class="string">'http://help.douzone.com'</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = False</span><br><span class="line"></span><br><span class="line"><span class="comment"># 쿠키사용</span></span><br><span class="line">COOKIES_ENABLED = True</span><br><span class="line"></span><br><span class="line">DOWNLOAD_DELAY = 3</span><br><span class="line"></span><br><span class="line"><span class="comment"># User-Agent 미들웨어 사용</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span>: None,</span><br><span class="line">    <span class="string">'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware'</span>: 400,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 파이프 라인 활성화</span></span><br><span class="line"><span class="comment"># 숫자가 작을 수록 우선순위 상위</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'thezone.pipelines.ThezonePipeline'</span>: 300,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 재시도 횟수</span></span><br><span class="line">RETRY_ENABLED = True</span><br><span class="line">RETRY_TIMES = 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 한글 쓰기(출력 인코딩)</span></span><br><span class="line">FEED_EXPORT_ENCODING = <span class="string">'utf-8'</span></span><br></pre></td></tr></table></figure>
<ul>
<li>위의 scrapy 파일들을 통해서 데이터를 먼저 확보 했다. 필자의 로컬환경을 통해서는 10시간 정도 걸렸다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy runspider qnacrawler.py -o qna_smart_a.csv - t csv</span><br></pre></td></tr></table></figure>
<h2 id="데이터-소개"><a href="#데이터-소개" class="headerlink" title="데이터 소개"></a>데이터 소개</h2><ul>
<li><p>위의 scrapy spider bot을 통해서 얻은 데이터를 통해 다음과 같은 feature들을 얻었다.</p>
</li>
<li><p>회계프로그램인 smart_a에 대한 전체 Q&amp;A를 크롤링하여 챗봇을 만드는 것이 프로젝트의 목표이다.</p>
</li>
</ul>
<h3 id="raw-데이터-구성"><a href="#raw-데이터-구성" class="headerlink" title="raw 데이터 구성"></a>raw 데이터 구성</h3><ul>
<li>answer_date_time : 답변완료일자</li>
<li>answer_yes : 답변 여부</li>
<li>answering : 답변 내용</li>
<li>category : 질문의 유형</li>
<li>enrolled_date_time : 질문등록일자</li>
<li>question : 질문 내용</li>
</ul>
<p><img src="/image/thezone_raw_data_head.png" alt="thezone smart A 온라인고객센터 데이터"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">raw_data.info()</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;class <span class="string">'pandas.core.frame.DataFrame'</span>&gt;</span><br><span class="line">RangeIndex: 12475 entries, 0 to 12474</span><br><span class="line">Data columns (total 6 columns):</span><br><span class="line">answer_date_time      12436 non-null object</span><br><span class="line">answer_yes            12436 non-null object</span><br><span class="line">answering             12420 non-null object</span><br><span class="line">category              12475 non-null object</span><br><span class="line">enrolled_date_time    12475 non-null object</span><br><span class="line">question              12409 non-null object</span><br><span class="line">dtypes: object(6)</span><br><span class="line">memory usage: 584.9+ KB</span><br></pre></td></tr></table></figure>
<ul>
<li>데이터에 null 값이 포함되어 있기 때문에 null값들을 제거해주고, 답변 대기 상태인 데이터들은 총 39건이 있었는데 답변이 작성되지 않은 데이터 이므로 답변 대기 상태인 데이터들도 같이 제거해준다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">raw_data = raw_data[raw_data[<span class="string">"answer_yes"</span>]==<span class="string">"답변완료"</span>]</span><br><span class="line">raw_data.reset_index(drop=True, inplace=True)</span><br><span class="line"></span><br><span class="line">raw_data = raw_data[pd.isnull(raw_data[<span class="string">"question"</span>])!=True].reset_index(drop=True)</span><br><span class="line"><span class="built_in">print</span>(sum(raw_data[<span class="string">"question"</span>].apply(lambda x: pd.isnull(x))))</span><br><span class="line"></span><br><span class="line">raw_data = raw_data[pd.isnull(raw_data[<span class="string">"answering"</span>])!=True].reset_index(drop=True)</span><br><span class="line"><span class="built_in">print</span>(sum(raw_data[<span class="string">"question"</span>].apply(lambda x: pd.isnull(x))))</span><br></pre></td></tr></table></figure>
<ul>
<li>답변대기 상태인 데이터들을 제거하고 총 사용가능한 데이터는 12,354건의 질문과 답변 쌍이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;class <span class="string">'pandas.core.frame.DataFrame'</span>&gt;</span><br><span class="line">RangeIndex: 12354 entries, 0 to 12353</span><br><span class="line">Data columns (total 6 columns):</span><br><span class="line">answer_date_time      12354 non-null object</span><br><span class="line">answer_yes            12354 non-null object</span><br><span class="line">answering             12354 non-null object</span><br><span class="line">category              12354 non-null object</span><br><span class="line">enrolled_date_time    12354 non-null object</span><br><span class="line">question              12354 non-null object</span><br><span class="line">dtypes: object(6)</span><br><span class="line">memory usage: 579.2+ KB</span><br></pre></td></tr></table></figure>
<ul>
<li>먼저, 간단하게 데이터들의 분류 카테고리에 따라서 어떤 분포를 띄고 있는지 간략하게 살펴볼 것이다.</li>
</ul>
<p><img src="/image/category_histogram_thezone.png" alt="카테고리 별 질문 및 답변쌍의 개수"></p>
<h3 id="질문-데이터-전처리"><a href="#질문-데이터-전처리" class="headerlink" title="질문 데이터 전처리"></a>질문 데이터 전처리</h3><ul>
<li>세무/회계관련 질문들이라서 금액에 관한 질문과 답변들이 많이 있기에 숫자에 대한 내용을 제거할지 하지 말하야 할지를 두고 필자는 생각이 많았는데, 우선 프로젝트의 첫번째 목표인 검색 키워드와 질문의 내용간의 유사도를 측정하는 면에 있어서는 숫자들이 크게 중요하지 않을 것이라는 판단하에 <code>숫자부분들과 마침표같은 부호들을 제거</code>하기로 결정했다. 다만, <code>[]안의 내용은 대부분 smart A의 메뉴명을 의미하기 때문에 살려</code>두었다. <code>[메뉴명]을 하나의 명사로 인식하기 위해 형태소 분석을 할 경우에도 비지도 학습을 통한 방식을 채택하기 위해 soynlp를 사용할 것</code>이다.</li>
</ul>
<p><img src="/image/thezone_raw_data_question.png" alt="질문 데이터들"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def pattern_match(x):</span><br><span class="line"></span><br><span class="line">    pattern = <span class="string">"\d+"</span></span><br><span class="line">    reg = re.compile(pattern)</span><br><span class="line">    sentence = re.sub(reg, <span class="string">" "</span>, x)</span><br><span class="line"></span><br><span class="line">    pattern = <span class="string">"[!|,|.|?|~|※|)|(|■|+|=|-|/|*|-|&gt;|-|;|^|]|-|%|'|'|ㅠ+|ㅎ+]"</span></span><br><span class="line">    reg = re.compile(pattern)</span><br><span class="line">    sentence = re.sub(reg, <span class="string">" "</span>, sentence)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">raw_data[<span class="string">'question_after'</span>] = raw_data[<span class="string">'question_after'</span>].apply(lambda x : pattern_match(str(x)))</span><br></pre></td></tr></table></figure>
<ul>
<li>기본적인 부호들과 숫자들을 제거해 주었으므로 이제 기본적인 <code>띄어쓰기 단위 어절과 음절(문자 하나하나를 의미)단위로 질문의 평균적인 길이와 한 질문당 단어의 평균적인 사용량을 대략적으로 살펴볼 것</code>이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 띄어쓰기 단위로 나눈 어절 기초통계량</span></span><br><span class="line">raw_data[<span class="string">'question_after'</span>].apply(lambda x: len(str(x).split(<span class="string">" "</span>))).describe()</span><br></pre></td></tr></table></figure>
<ul>
<li>위의 띄어쓰기 단위로 나눈 질문의 Token의 개수는 평균적으로 33개의 어절과 중앙값은 27개의 어절을 갖는다는 것을 확인 할 수 있다. 평균이 올라간것은 3사분위수가 42개인 것과 최대 어절이 791개인 것으로 미루어 보아 이상치에 의한 영향을 받아 평균이 데이터의 중심을 잘 반영하고 있지 않다고 판단해 볼 수 있다. 그러므로 이상치들의 데이터 형태를 살펴보고 문제점이 무엇인지 파악해 볼 것이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">count    12290.000000</span><br><span class="line">mean        35.055411</span><br><span class="line">std         33.537140</span><br><span class="line">min          1.000000</span><br><span class="line">25%         17.000000</span><br><span class="line">50%         27.000000</span><br><span class="line">75%         42.000000</span><br><span class="line">max        791.000000</span><br><span class="line">Name: question_after, dtype: float64</span><br></pre></td></tr></table></figure>
<ul>
<li>가장 높은 최댓값을 갖는 데이터를 살펴보면, 아래의 그림과 같이 공백으로 일정한 형식을 맞춰보려고 한 것 같이 되어있다. 그러나 우리는 이 질문의 내용적인 면이나 키워드가 중요한 것이므로 형식이 우리가 푸는 문제에는 큰 영향을 주지 못하므로 공백을 제거해 줄 것이다.</li>
</ul>
<p><img src="/image/many_space_bar_thezone_question.png" alt="이상치 데이터의 모습"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def pattern_match(x):</span><br><span class="line">    pattern = <span class="string">"  +"</span></span><br><span class="line">    reg = re.compile(pattern)</span><br><span class="line">    sentence = re.sub(reg, <span class="string">" "</span>, x)</span><br><span class="line">    <span class="built_in">return</span> sentence</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">raw_data[<span class="string">'question_after'</span>] = raw_data[<span class="string">'question_after'</span>].apply(lambda x : pattern_match(str(x)))</span><br><span class="line"></span><br><span class="line">sent_len_by_token = raw_data[<span class="string">'question_after'</span>].apply(lambda x: len(str(x).split(<span class="string">" "</span>)))</span><br></pre></td></tr></table></figure>
<ul>
<li>공백이 많은 데이터들을 공백을 줄여주는 함수를 통해 처리를 해준 후에 다시 질문 당 띄어쓰기 단위 어절의 길이에 관한 기초 통계량을 살펴보면 다음과 같다. 역시 함수를 통해 공백을 줄여준 후에 다시 측정해보니 평균과 중앙값의 차이가 이전과 다르게 확연히 줄어든 것을 볼 수 있으며, 평균적으로 22~23개의 어절을 사용함을 확인해 볼 수 있다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">count    12290.000000</span><br><span class="line">mean        28.416273</span><br><span class="line">std         22.040055</span><br><span class="line">min          1.000000</span><br><span class="line">25%         15.000000</span><br><span class="line">50%         23.000000</span><br><span class="line">75%         35.000000</span><br><span class="line">max        355.000000</span><br><span class="line">Name: question_after, dtype: float64</span><br></pre></td></tr></table></figure>
<ul>
<li>90%의 위치에 위치하고 있는 어절의 길이는 52개 였다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.quantile(sent_len_by_token, 0.90)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">52.0</span><br></pre></td></tr></table></figure>
<ul>
<li>또한, 위에서 355개의 어절을 갖는 데이터에 관해서도 이상치이므로 살펴보았다. 아래와 같이 오류 코드에 관한 질문이었기 때문에 공백이 많이 포함되어있을 수 밖에 없다는 것을 확인 할 수 있었다. 그러므로 이 데이터의 공백은 질문의 내용을 표현하는데 불필요한 요소가 아니므로 그대로 상태를 유지 할 것이다.</li>
</ul>
<p><img src="/image/eujeol_token_maximum_last.png" alt="355개의 어절을 갖는 질문"></p>
<ul>
<li>그 다음은 <code>음절 단위 길이를 분석</code>해 볼 것이다. 음절 단위의 기초 통계량은 아래와 같다. 평균적으로 136자를 사용하였으며, 중앙값은 112자이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">count    12279.000000</span><br><span class="line">mean       136.459647</span><br><span class="line">std        109.823703</span><br><span class="line">min          3.000000</span><br><span class="line">25%         74.000000</span><br><span class="line">50%        112.000000</span><br><span class="line">75%        167.000000</span><br><span class="line">max       2637.000000</span><br><span class="line">Name: question_after, dtype: float64</span><br></pre></td></tr></table></figure>
<ul>
<li>위에서의 기초 통계량 값을 시각화해서 간단히 살펴 보기위해서 아래와 같이 히스토그램을 활용하였다. 상식적으로도 알 수 있듯이, 음절이 어절보다 훨씬 단위가 클수밖에 없을 것이다. 여기서 볼 것은 꼬리 분포이다. 음절과 어절 단위로 살펴본 질문의 길이는 둘다 일정 수준이하에 주로 분포돼있고, 일정 수준 이상은 이상치가 존재하고 있다.</li>
</ul>
<p><img src="/image/sentence_length_by_emjeol_and_euojeol.png" alt="어절 및 음절 단위 문장 길이 히스토그램"></p>
<h3 id="모델-설정"><a href="#모델-설정" class="headerlink" title="모델 설정"></a>모델 설정</h3><ul>
<li>제일 먼저, TF-IDF 행렬을 사용해 LSA 분석의 일종인 TruncatedSVD 행렬을 이용해 문장 임베딩을 실행한 후, 키워드 검색어와의 유사한 문서들을 살펴 볼 것이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import math</span><br><span class="line">from soynlp.word import WordExtractor</span><br><span class="line">from soynlp.tokenizer import LTokenizer</span><br><span class="line">q_sentence = list(raw_data[<span class="string">'question_after'</span>])</span><br><span class="line"></span><br><span class="line">word_extractor = WordExtractor(min_frequency=1, min_cohesion_forward=0.05, min_right_branching_entropy=0.0)</span><br><span class="line">word_extractor.train(q_sentence)</span><br><span class="line">scores = word_extractor.word_scores()</span><br><span class="line"></span><br><span class="line">cohesion_scores = &#123;key:(scores[key].cohesion_forward * math.exp(scores[key].right_branching_entropy)) <span class="keyword">for</span> key <span class="keyword">in</span> scores.keys()&#125;</span><br></pre></td></tr></table></figure>

        </div>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 하단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="9861011486"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "HeungBae Lee"
        },
        "headline": "NLP 실습 Chat bot 만들기",
        "image": "https://heung-bae-lee.github.io/image/the_zone_online_center.png",
        "keywords": "",
        "genre": "NLP",
        "datePublished": "2020-02-11",
        "dateCreated": "2020-02-11",
        "dateModified": "2020-02-18",
        "url": "https://heung-bae-lee.github.io/2020/02/11/NLP_12/",
        "description": "
지금까지 두 가지 문제에 대해 실습을 진행하였다. 1) 텍스트를 분석해서 각 텍스트를 분류하는 문제를 실습했고, 2) 두 개의 텍스트가 있을 때 각 텍스트끼리의 유사도를 판단하는 문제를 실습했다. 마지막으로 이번에는 텍스트를 단순히 분석해서 분류나 유사도를 측정하는 것이 아닌 직업 문장을 생성할 수 있는 text generation 문제를 실습해 볼 것이"
        "wordCount": 3253
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/heungbae.lee" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HEUNG-BAE-LEE" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
    
        <a href="/2020/02/11/NLP_11/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">NLP 실습 텍스트 유사도 - 02 (XGBoost, 1D-CNN, MaLSTM)</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/11/NLP_12/" class="title">NLP 실습 Chat bot 만들기</a></p>
                            <p class="item-date"><time datetime="2020-02-11T08:16:56.000Z" itemprop="datePublished">2020-02-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/11/NLP_11/" class="title">NLP 실습 텍스트 유사도 - 02 (XGBoost, 1D-CNN, MaLSTM)</a></p>
                            <p class="item-date"><time datetime="2020-02-10T16:36:58.000Z" itemprop="datePublished">2020-02-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/10/NLP_10/" class="title">NLP 실습 텍스트 유사도 - 01 (데이터 EDA 및 전처리)</a></p>
                            <p class="item-date"><time datetime="2020-02-09T17:34:30.000Z" itemprop="datePublished">2020-02-10</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/08/NLP_09/" class="title">NLP 문장 수준 임베딩 - 02</a></p>
                            <p class="item-date"><time datetime="2020-02-07T16:02:58.000Z" itemprop="datePublished">2020-02-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/06/NLP_08/" class="title">NLP 문장 수준 임베딩 - 01</a></p>
                            <p class="item-date"><time datetime="2020-02-05T15:32:51.000Z" itemprop="datePublished">2020-02-06</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bayes/">Bayes</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n/">CS231n</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Front-end/">Front end</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/crawling/">crawling</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-engineering/">data engineering</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/growth-hacking/">growth hacking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">5</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crawling/">crawling</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CS231n/" style="font-size: 10px;">CS231n</a> <a href="/tags/crawling/" style="font-size: 20px;">crawling</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 사이드바 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="3275421833"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 HeungBae Lee</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://heung-bae-lee.github.io/2020/02/11/NLP_12/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</body>
</html>
