<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    

    
    <title>NLP 실습 유사도를 반영한 검색 키워드 최적화 | DataLatte&#39;s IT Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    
    <meta name="description" content="이번 실습의 소개는 프로젝트성으로 진행 할 것이다.  프로젝트 소개더존 ICT 온라인 고객센터 키워드 검색 최적화 및 챗봇 구현 프로젝트를 하게 된 계기  먼저, 더존 온라인 고객센터 페이지 중 smart A에 관한 페이지에서 전체 탭을 클릭한 후, 살펴본 QnA 페이지를 살펴보았다.   필자는 고객들의 입장에서 생각해보았을때, 자신이 작성하는 질문(물론">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP 실습 유사도를 반영한 검색 키워드 최적화">
<meta property="og:url" content="https://heung-bae-lee.github.io/2020/02/11/NLP_12/index.html">
<meta property="og:site_name" content="DataLatte&#39;s IT Blog">
<meta property="og:description" content="이번 실습의 소개는 프로젝트성으로 진행 할 것이다.  프로젝트 소개더존 ICT 온라인 고객센터 키워드 검색 최적화 및 챗봇 구현 프로젝트를 하게 된 계기  먼저, 더존 온라인 고객센터 페이지 중 smart A에 관한 페이지에서 전체 탭을 클릭한 후, 살펴본 QnA 페이지를 살펴보았다.   필자는 고객들의 입장에서 생각해보았을때, 자신이 작성하는 질문(물론">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://heung-bae-lee.github.io/image/the_zone_online_center.png">
<meta property="og:updated_time" content="2020-02-20T07:19:46.701Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NLP 실습 유사도를 반영한 검색 키워드 최적화">
<meta name="twitter:description" content="이번 실습의 소개는 프로젝트성으로 진행 할 것이다.  프로젝트 소개더존 ICT 온라인 고객센터 키워드 검색 최적화 및 챗봇 구현 프로젝트를 하게 된 계기  먼저, 더존 온라인 고객센터 페이지 중 smart A에 관한 페이지에서 전체 탭을 클릭한 후, 살펴본 QnA 페이지를 살펴보았다.   필자는 고객들의 입장에서 생각해보았을때, 자신이 작성하는 질문(물론">
<meta name="twitter:image" content="https://heung-bae-lee.github.io/image/the_zone_online_center.png">
<meta property="fb:app_id" content="100003222637819">


    <link rel="canonical" href="https://heung-bae-lee.github.io/2020/02/11/nlp_12/">

    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-154199624-1', 'auto');
ga('send', 'pageview');

</script>

    
    


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4604833066889492" data-ad-slot="4588503508" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<link rel="alternate" href="/rss2.xml" title="DataLatte's IT Blog" type="application/rss+xml">
</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">DataLatte&#39;s IT Blog using Hexo</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Bayes/">Bayes</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/CS231n/">CS231n</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Front-end/">Front end</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/crawling/">crawling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/data-engineering/">data engineering</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/growth-hacking/">growth hacking</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/hexo/">hexo</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/linear-algebra/">linear algebra</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/machine-learning/">machine learning</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/NLP/">NLP</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="4588503508"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

			    <article id="post-NLP_12" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        NLP 실습 유사도를 반영한 검색 키워드 최적화
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2020/02/11/NLP_12/" class="article-date">
            <time datetime="2020-02-11T08:16:56.000Z" itemprop="datePublished">2020-02-11</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <ul>
<li>이번 실습의 소개는 프로젝트성으로 진행 할 것이다.</li>
</ul>
<h3 id="프로젝트-소개"><a href="#프로젝트-소개" class="headerlink" title="프로젝트 소개"></a>프로젝트 소개</h3><h4 id="더존-ICT-온라인-고객센터-키워드-검색-최적화-및-챗봇-구현"><a href="#더존-ICT-온라인-고객센터-키워드-검색-최적화-및-챗봇-구현" class="headerlink" title="더존 ICT 온라인 고객센터 키워드 검색 최적화 및 챗봇 구현"></a>더존 ICT 온라인 고객센터 키워드 검색 최적화 및 챗봇 구현</h4><ul>
<li><p>프로젝트를 하게 된 계기</p>
<ul>
<li><p>먼저, 더존 온라인 고객센터 페이지 중 smart A에 관한 페이지에서 전체 탭을 클릭한 후, 살펴본 QnA 페이지를 살펴보았다.</p>
<p><img src="/image/the_zone_online_center.png" alt="더존 온라인 고객센터"></p>
</li>
<li><p><code>필자는 고객들의 입장에서 생각해보았을때, 자신이 작성하는 질문(물론, 그림으로 첨부해야할 만큼 그 환경이 중요한 질문들은 제외하고)과 비슷한 질문들이 존재할 거라는 생각을 갖고 키워드를 통해 검색해볼 것</code>이다. 아래 그림은 <code>재입사자</code>라는 키워드를 smart A페이지에서 검색했을 때 출력되는 결과이다. 11건의 총 검색 결과 중 <code>재입사자에 대한 연말정산과 관련된 문건이 8건이 존재</code>한다.</p>
<p><img src="/image/smart_A_search_for_recruit.png" alt="smart A에서 재입사라는 키워드에 관한 검색 결과"></p>
</li>
<li><p>그래서 필자는 <code>재입사자 연말정산</code>이라는 키워드를 통해 검색을 해보았다. 위에서 재입사자라는 키워드를 통해 검색 했을 때, 재입사자의 연말정산에 대한 질문이 8건이 존재한 반면에 아래 그림에서와 같이 8건 중 5건 만을 보여준다.</p>
<p><img src="/image/smart_A_search_for_recruit_year.png" alt="smart A에서 재입사자 연말정산이라는 키워드에 관한 검색 결과">  </p>
</li>
<li><p>필자는 질문의 내용이 아닌 질문의 제목에 재입사자 연말정산이라는 키워드가 8건이 존재할 뿐 내용은 그와는 다를 수도 있다는 생각이 들어, 검색결과에 포함되어 있지 않는 질문들을 살펴보았다. 또한, 질문 내용 자체가 본질적으로 물어보는 의미가 검색결과에 포함되지 않은 질문들은 다를 수도 있기에 특정 알고리즘을 통해 결과를 보여줄 수 있다는 생각이 들어 검색 결과에 포함된 질문과도 비교해 보기로 했다.</p>
<p><img src="/image/non_search_for_recruit.png" alt="검색결과에 포함되지 않은 질문과 답변들"></p>
</li>
<li><p>검색결과에 포함되지 않은 질문과 답변이 왼쪽 그림이고, 검색결과에 포함된 질문과 답변이 오른쪽의 빨강색 네모로 되어있는 그림이다. 두 질문은 비슷한 질문이라고 보인다. 그런데도 불구하고 재입사자 연말정산이라는 키워드 검색 결과에 포함되어 있지 않는 점을 통해 필자는 <code>각각의 질문들과 검색 키워드 간의 유사성을 점수화해 유사성이 높은 질문들을 보여주는 시스템</code>도입이 필요할 것 같다는 생각이 들었다.</p>
<p><img src="/image/between_difference_search_non_search.png" alt="검색결과에 포함되지 않은 질문과 답변, 검색결과에 포함된 질문과 답변"></p>
</li>
<li><p>또한, 챗봇을 만드는 부분에 있어서 입력과 출력의 문장의 sequence 길이를 맞춰주어야 하는데, 그에 따라서 답변이 특정 분야(예를들면, 연말정산이나 원천징수등)에서는 긴 문장으로 이루어질 수도 있으므로, 챗봇을 구현한다면, 각 분야에 따른 문장길이를 분석해 보기도 해야 할 것 같다는 생각이들었다.</p>
</li>
<li><p>이런 제한 상황으로 인해 챗봇 구현이 힘들다면, 질문과 검색 키워드 간의 유사도를 반영한 검색 결과를 통해서라도 더존 온라인 고객센터의 질문을 하시는 고객 분들에게 조금이나마 더 편의성을 드릴수 있게끔 하면 좋을 것 같다는 생각이 들었다.</p>
</li>
<li><p><code>더존 사이트내에서 영업 문의 전화나 구매자에 대한 상담은 따로 서비스를 제공하고 있지만, 온라인 고객센터 tap부분에서만 Q&amp;A에 관한 사항을 다루는데 답변을 해주는 시간은 업무 시간내로만 제한</code> 되어있다. 이에 따라 24시간 또는 업무 이외의 시간에는 <code>챗봇 서비스를 시행한다면 고객들의 입장에서 보았을 때 조금 더 편리하게 더존의 서비스나 솔루션을 이용할 수 있을 것이라는 취지에 의해서 챗봇 구현에 관심</code>을 갖게 되었다.</p>
</li>
</ul>
</li>
<li><p>데이터 이름 : qna_smart_a.csv</p>
<ul>
<li>더존에서는 WEHAGO 플랫폼상에서 여러가지 서비스를 제공하고 있다. 그 중 더존 Smart A는 재무회계, 세무신고, 인사·급여관리, 물류관리까지 중소기업의 업무를 통합적으로 관리할 수 있는 회계프로그램로서, 이 프로그램의 질문과 답변에 의해서만 먼저 학습을 해 볼 것이다. 그 이유는 다른 프로그램들(ERP와 WEHAGO)은 사용자들의 성격에 따라 다양한 용도로 개발 되어있지만, 회계프로그램인 Smart A는 모든 기업이 공용으로 사용하기 때문에 우선적으로 학습해 볼 것이다. 또한, 가장 주요한 선택 이유는 Q&amp;A 게시판의 데이터 중 가장 많은 데이터를 포함하고 있었기 때문이다.</li>
</ul>
</li>
<li><p>데이터 용도 :</p>
</li>
<li><p>데이터 출처 : <a href="http://help.douzone.com/pboard/index.jsp?code=qna10&amp;pid=10&amp;s_category_id=all&amp;type=all&amp;page=1" target="_blank" rel="noopener">더존 온라인 고객센터 Smart A 전체 tap</a>의 전체 질문과 답변들을 크롤링 해서 사용하였다. 크롤링 방식은 Scrapy를 통해 페이지를 순회하게끔 코드를 작성하여 크롤링해서 얻었다.</p>
</li>
<li><p>먼저, 더존 온라인 고객 센터페이지에서 질문과 답변을 크롤링해와서 데이터 셋을 구성할 것이다.</p>
</li>
</ul>
<h3 id="Spider-bot-만들기"><a href="#Spider-bot-만들기" class="headerlink" title="Spider bot 만들기"></a>Spider bot 만들기</h3><ul>
<li><p>전체 scrapy bot의 구성은 다음과 같다.</p>
</li>
<li><p>items.py와 settings.py를 활용했으며, 마지막 결과 파일은 csv로 저장했다. 혹시 db파일로 저장하고 싶다면 추가적으로 pipelines에서 작업을 하면된다. 더존 온라인 고객센터의 게시판에서 최근 게시판에서는 답변 완료상태인 데이터가 주로 많지만 예전 데이터 중에는 간간히 답변 대기 상태인 데이터가 존재한다. 그러므로 pipeline.py에서 이를 통해 답변 완료인 상태인 데이터만을 크롤링하여도 되지만, 필자는 어떤 데이터가 답변 대기 상태인 데이터인지 눈으로 살펴보기 위해 그냥 모두 크롤링하는 것으로 처리하였다.</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">thezone</span><br><span class="line">├── scrapy.cfg</span><br><span class="line">└── thezone</span><br><span class="line">    ├── __init__.py</span><br><span class="line">    ├── __pycache__</span><br><span class="line">    │   ├── __init__.cpython-37.pyc</span><br><span class="line">    │   ├── items.cpython-37.pyc</span><br><span class="line">    │   ├── pipelines.cpython-37.pyc</span><br><span class="line">    │   └── settings.cpython-37.pyc</span><br><span class="line">    ├── items.py</span><br><span class="line">    ├── middlewares.py</span><br><span class="line">    ├── pipelines.py</span><br><span class="line">    ├── settings.py</span><br><span class="line">    └── spiders</span><br><span class="line">        ├── __init__.py</span><br><span class="line">        ├── __pycache__</span><br><span class="line">        │   ├── __init__.cpython-37.pyc</span><br><span class="line">        │   └── qnacrawler.cpython-37.pyc</span><br><span class="line">        ├── last_qna_smart_a.csv</span><br><span class="line">        ├── qna_smart_a.csv</span><br><span class="line">        └── qnacrawler.py</span><br></pre></td></tr></table></figure>
<ul>
<li>qnacrawler.py</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import scrapy</span><br><span class="line">from scrapy.linkextractors import LinkExtractor</span><br><span class="line">from scrapy.spiders import CrawlSpider, Rule</span><br><span class="line">import sys</span><br><span class="line">sys.path.insert(0, <span class="string">'/Users/heungbaelee/workspace/project/chat_bot_project/thezone/thezone'</span>)</span><br><span class="line">from items import ThezoneItem</span><br><span class="line"></span><br><span class="line">class QnacrawlerSpider(CrawlSpider):</span><br><span class="line">    name = <span class="string">'qnacrawler'</span></span><br><span class="line">    allowed_domains = [<span class="string">'help.douzone.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://help.douzone.com/pboard/index.jsp?code=qna10&amp;pid=10&amp;s_category_id=all&amp;type=all&amp;s_listnum=50&amp;s_field=&amp;s_keyword='</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># rules = [</span></span><br><span class="line">    <span class="comment">#     Rule(LinkExtractor(allow=r'/pboard/index.jsp?code=qna10&amp;pid=10&amp;s_category_id=all&amp;type=all&amp;s_listnum=50&amp;s_field=&amp;s_keyword=&amp;page=\d+', ), callback='parse_parent', follow=True),</span></span><br><span class="line">    <span class="comment"># ]</span></span><br><span class="line">    rules = [</span><br><span class="line">        Rule(LinkExtractor(restrict_css=<span class="string">'div.page_box &gt; ul &gt; li:nth-child(n+4)'</span>,attrs=<span class="string">'href'</span>), callback=<span class="string">'parse_parent'</span>, follow=True),</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse_parent(self, response):</span><br><span class="line">        <span class="comment"># link = LinkExtractor(allow=r'/pboard/index.jsp?code=qna10&amp;pid=10&amp;s_category_id=all&amp;type=all&amp;s_listnum=50&amp;s_field=&amp;s_keyword=&amp;page=\d+')</span></span><br><span class="line">        <span class="comment"># links = link.extract_links(response)</span></span><br><span class="line">        <span class="comment"># print(links)</span></span><br><span class="line">        <span class="comment"># print(response.status)</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> response.css(<span class="string">'div.tab_cnt.mt30 &gt; table &gt; tbody &gt; tr'</span>):</span><br><span class="line">            article_num = url.css(<span class="string">'td:nth-child(1)::text'</span>).extract_first().strip()</span><br><span class="line">            self.logger.info(<span class="string">'Article number : %s'</span> % article_num)</span><br><span class="line">            article_link = url.css(<span class="string">'td:nth-child(3) &gt; a::attr(href)'</span>).extract_first().strip()</span><br><span class="line">            self.logger.info(<span class="string">'Article link : %s'</span> % article_link)</span><br><span class="line">            <span class="comment"># print(article_num, response.urljoin(article_link))</span></span><br><span class="line">            yield scrapy.Request(response.urljoin(article_link), self.parse_child, meta=&#123;<span class="string">'article_num'</span>: article_num&#125;)</span><br><span class="line"></span><br><span class="line">    def parse_child(self, response):</span><br><span class="line">        <span class="comment"># 부모, 자식 수신 정보 로깅</span></span><br><span class="line">        self.logger.info(<span class="string">'----------------------------------------'</span>)</span><br><span class="line">        self.logger.info(<span class="string">'Child Response URL : %s'</span> % response.url)</span><br><span class="line">        self.logger.info(<span class="string">'Child Response Status ; %s'</span> % response.status)</span><br><span class="line">        self.logger.info(<span class="string">'----------------------------------------'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 질문 번호</span></span><br><span class="line">        article_num = response.meta[<span class="string">'article_num'</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 유형</span></span><br><span class="line">        category = response.css(<span class="string">"div.qna_read.mt30 &gt; table:nth-child(1) &gt; tbody &gt; tr:nth-child(2) &gt; td &gt; dl &gt; dd:nth-child(2)::text"</span>).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 질문</span></span><br><span class="line">        question = <span class="string">""</span>.join(response.css(<span class="string">"div.qna_read.mt30 &gt; table:nth-child(1) &gt; tbody &gt; tr:nth-child(2) &gt; td &gt; div.q &gt; div.q_cnt &gt; p::text"</span>).extract()).strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 등록일</span></span><br><span class="line">        enrolled_date_time = response.css(<span class="string">"div.qna_read.mt30 &gt; table:nth-child(1) &gt; tbody &gt; tr:nth-child(1) &gt; td:nth-child(4)::text"</span>).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 작성일</span></span><br><span class="line">        answer_date_time = response.css(<span class="string">"table.mt10 &gt; tbody &gt; tr:nth-child(1) &gt; td:nth-child(4)::text"</span>).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 답변여부</span></span><br><span class="line">        answer_yes = response.css(<span class="string">"table.mt10 &gt; tbody &gt; tr:nth-child(1) &gt; td.ta_l &gt; span::text"</span>).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 답변</span></span><br><span class="line">        answering = <span class="string">""</span>.join(response.css(<span class="string">"table.mt10 &gt; tbody &gt; tr:nth-child(2) &gt; td.ta_l.pd20 &gt; div.a &gt; div &gt; p::text"</span>).extract()).strip()</span><br><span class="line"></span><br><span class="line">        yield ThezoneItem(article_num=article_num, category=category, enrolled_date_time=enrolled_date_time, question=question, answer_date_time=answer_date_time, answer_yes=answer_yes, answering=answering)</span><br></pre></td></tr></table></figure>
<ul>
<li>items.py</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://docs.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ThezoneItem(scrapy.Item):</span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    <span class="comment"># 문서번호</span></span><br><span class="line">    article_num = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 유형</span></span><br><span class="line">    category = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 질문</span></span><br><span class="line">    question = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 답변</span></span><br><span class="line">    answering = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 작성일</span></span><br><span class="line">    answer_date_time = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 등록일</span></span><br><span class="line">    enrolled_date_time = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 답변여부</span></span><br><span class="line">    answer_yes = scrapy.Field()</span><br></pre></td></tr></table></figure>
<ul>
<li>settings.py</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line">BOT_NAME = <span class="string">'thezone'</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">'thezone.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'thezone.spiders'</span></span><br><span class="line"></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;<span class="string">'Referer'</span> : <span class="string">'http://help.douzone.com'</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = False</span><br><span class="line"></span><br><span class="line"><span class="comment"># 쿠키사용</span></span><br><span class="line">COOKIES_ENABLED = True</span><br><span class="line"></span><br><span class="line">DOWNLOAD_DELAY = 3</span><br><span class="line"></span><br><span class="line"><span class="comment"># User-Agent 미들웨어 사용</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span>: None,</span><br><span class="line">    <span class="string">'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware'</span>: 400,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 파이프 라인 활성화</span></span><br><span class="line"><span class="comment"># 숫자가 작을 수록 우선순위 상위</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'thezone.pipelines.ThezonePipeline'</span>: 300,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 재시도 횟수</span></span><br><span class="line">RETRY_ENABLED = True</span><br><span class="line">RETRY_TIMES = 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 한글 쓰기(출력 인코딩)</span></span><br><span class="line">FEED_EXPORT_ENCODING = <span class="string">'utf-8'</span></span><br></pre></td></tr></table></figure>
<ul>
<li>위의 scrapy 파일들을 통해서 데이터를 먼저 확보 했다. 필자의 로컬환경을 통해서는 10시간 정도 걸렸다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy runspider qnacrawler.py -o qna_smart_a.csv - t csv</span><br></pre></td></tr></table></figure>
<h2 id="데이터-소개"><a href="#데이터-소개" class="headerlink" title="데이터 소개"></a>데이터 소개</h2><ul>
<li><p>위의 scrapy spider bot을 통해서 얻은 데이터를 통해 다음과 같은 feature들을 얻었다.</p>
</li>
<li><p>회계프로그램인 smart_a에 대한 전체 Q&amp;A를 크롤링하여 챗봇을 만드는 것이 프로젝트의 목표이다.</p>
</li>
</ul>
<h3 id="raw-데이터-구성"><a href="#raw-데이터-구성" class="headerlink" title="raw 데이터 구성"></a>raw 데이터 구성</h3><ul>
<li>answer_date_time : 답변완료일자</li>
<li>answer_yes : 답변 여부</li>
<li>answering : 답변 내용</li>
<li>category : 질문의 유형</li>
<li>enrolled_date_time : 질문등록일자</li>
<li>question : 질문 내용</li>
</ul>
<p><img src="/image/thezone_raw_data_head.png" alt="thezone smart A 온라인고객센터 데이터"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">raw_data.info()</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;class <span class="string">'pandas.core.frame.DataFrame'</span>&gt;</span><br><span class="line">RangeIndex: 12475 entries, 0 to 12474</span><br><span class="line">Data columns (total 6 columns):</span><br><span class="line">answer_date_time      12436 non-null object</span><br><span class="line">answer_yes            12436 non-null object</span><br><span class="line">answering             12420 non-null object</span><br><span class="line">category              12475 non-null object</span><br><span class="line">enrolled_date_time    12475 non-null object</span><br><span class="line">question              12409 non-null object</span><br><span class="line">dtypes: object(6)</span><br><span class="line">memory usage: 584.9+ KB</span><br></pre></td></tr></table></figure>
<ul>
<li>데이터에 null 값이 포함되어 있기 때문에 null값들을 제거해주고, 답변 대기 상태인 데이터들은 총 39건이 있었는데 답변이 작성되지 않은 데이터 이므로 답변 대기 상태인 데이터들도 같이 제거해준다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">raw_data = raw_data[raw_data[<span class="string">"answer_yes"</span>]==<span class="string">"답변완료"</span>]</span><br><span class="line">raw_data.reset_index(drop=True, inplace=True)</span><br><span class="line"></span><br><span class="line">raw_data = raw_data[pd.isnull(raw_data[<span class="string">"question"</span>])!=True].reset_index(drop=True)</span><br><span class="line"><span class="built_in">print</span>(sum(raw_data[<span class="string">"question"</span>].apply(lambda x: pd.isnull(x))))</span><br><span class="line"></span><br><span class="line">raw_data = raw_data[pd.isnull(raw_data[<span class="string">"answering"</span>])!=True].reset_index(drop=True)</span><br><span class="line"><span class="built_in">print</span>(sum(raw_data[<span class="string">"question"</span>].apply(lambda x: pd.isnull(x))))</span><br></pre></td></tr></table></figure>
<ul>
<li>답변대기 상태인 데이터들을 제거하고 총 사용가능한 데이터는 12,354건의 질문과 답변 쌍이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;class <span class="string">'pandas.core.frame.DataFrame'</span>&gt;</span><br><span class="line">RangeIndex: 12354 entries, 0 to 12353</span><br><span class="line">Data columns (total 6 columns):</span><br><span class="line">answer_date_time      12354 non-null object</span><br><span class="line">answer_yes            12354 non-null object</span><br><span class="line">answering             12354 non-null object</span><br><span class="line">category              12354 non-null object</span><br><span class="line">enrolled_date_time    12354 non-null object</span><br><span class="line">question              12354 non-null object</span><br><span class="line">dtypes: object(6)</span><br><span class="line">memory usage: 579.2+ KB</span><br></pre></td></tr></table></figure>
<ul>
<li>먼저, 간단하게 데이터들의 분류 카테고리에 따라서 어떤 분포를 띄고 있는지 간략하게 살펴볼 것이다.</li>
</ul>
<p><img src="/image/category_histogram_thezone.png" alt="카테고리 별 질문 및 답변쌍의 개수"></p>
<h3 id="질문-데이터-전처리"><a href="#질문-데이터-전처리" class="headerlink" title="질문 데이터 전처리"></a>질문 데이터 전처리</h3><ul>
<li>세무/회계관련 질문들이라서 금액에 관한 질문과 답변들이 많이 있기에 숫자에 대한 내용을 제거할지 하지 말하야 할지를 두고 필자는 생각이 많았는데, 우선 프로젝트의 첫번째 목표인 검색 키워드와 질문의 내용간의 유사도를 측정하는 면에 있어서는 숫자들이 크게 중요하지 않을 것이라는 판단하에 <code>숫자부분들과 마침표같은 부호들을 제거</code>하기로 결정했다. 다만, <code>[]안의 내용은 대부분 smart A의 메뉴명을 의미하기 때문에 살려</code>두었다. <code>[메뉴명]을 하나의 명사로 인식하기 위해 형태소 분석을 할 경우에도 비지도 학습을 통한 방식을 채택하기 위해 soynlp를 사용할 것</code>이다.</li>
</ul>
<p><img src="/image/thezone_raw_data_question.png" alt="질문 데이터들"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def pattern_match(x):</span><br><span class="line"></span><br><span class="line">    pattern = <span class="string">"\d+"</span></span><br><span class="line">    reg = re.compile(pattern)</span><br><span class="line">    sentence = re.sub(reg, <span class="string">" "</span>, x)</span><br><span class="line"></span><br><span class="line">    pattern = <span class="string">"[!|,|.|?|~|※|)|(|■|+|=|-|/|*|-|&gt;|-|;|^|]|-|%|'|'|ㅠ+|ㅎ+]"</span></span><br><span class="line">    reg = re.compile(pattern)</span><br><span class="line">    sentence = re.sub(reg, <span class="string">" "</span>, sentence)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">raw_data[<span class="string">'question_after'</span>] = raw_data[<span class="string">'question_after'</span>].apply(lambda x : pattern_match(str(x)))</span><br></pre></td></tr></table></figure>
<ul>
<li>기본적인 부호들과 숫자들을 제거해 주었으므로 이제 기본적인 <code>띄어쓰기 단위 어절과 음절(문자 하나하나를 의미)단위로 질문의 평균적인 길이와 한 질문당 단어의 평균적인 사용량을 대략적으로 살펴볼 것</code>이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 띄어쓰기 단위로 나눈 어절 기초통계량</span></span><br><span class="line">raw_data[<span class="string">'question_after'</span>].apply(lambda x: len(str(x).split(<span class="string">" "</span>))).describe()</span><br></pre></td></tr></table></figure>
<ul>
<li>위의 띄어쓰기 단위로 나눈 질문의 Token의 개수는 평균적으로 33개의 어절과 중앙값은 27개의 어절을 갖는다는 것을 확인 할 수 있다. 평균이 올라간것은 3사분위수가 42개인 것과 최대 어절이 791개인 것으로 미루어 보아 이상치에 의한 영향을 받아 평균이 데이터의 중심을 잘 반영하고 있지 않다고 판단해 볼 수 있다. 그러므로 이상치들의 데이터 형태를 살펴보고 문제점이 무엇인지 파악해 볼 것이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">count    12290.000000</span><br><span class="line">mean        35.055411</span><br><span class="line">std         33.537140</span><br><span class="line">min          1.000000</span><br><span class="line">25%         17.000000</span><br><span class="line">50%         27.000000</span><br><span class="line">75%         42.000000</span><br><span class="line">max        791.000000</span><br><span class="line">Name: question_after, dtype: float64</span><br></pre></td></tr></table></figure>
<ul>
<li>가장 높은 최댓값을 갖는 데이터를 살펴보면, 아래의 그림과 같이 공백으로 일정한 형식을 맞춰보려고 한 것 같이 되어있다. 그러나 우리는 이 질문의 내용적인 면이나 키워드가 중요한 것이므로 형식이 우리가 푸는 문제에는 큰 영향을 주지 못하므로 공백을 제거해 줄 것이다.</li>
</ul>
<p><img src="/image/many_space_bar_thezone_question.png" alt="이상치 데이터의 모습"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def pattern_match(x):</span><br><span class="line">    pattern = <span class="string">"  +"</span></span><br><span class="line">    reg = re.compile(pattern)</span><br><span class="line">    sentence = re.sub(reg, <span class="string">" "</span>, x)</span><br><span class="line">    <span class="built_in">return</span> sentence</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">raw_data[<span class="string">'question_after'</span>] = raw_data[<span class="string">'question_after'</span>].apply(lambda x : pattern_match(str(x)))</span><br><span class="line"></span><br><span class="line">sent_len_by_token = raw_data[<span class="string">'question_after'</span>].apply(lambda x: len(str(x).split(<span class="string">" "</span>)))</span><br></pre></td></tr></table></figure>
<ul>
<li>공백이 많은 데이터들을 공백을 줄여주는 함수를 통해 처리를 해준 후에 다시 질문 당 띄어쓰기 단위 어절의 길이에 관한 기초 통계량을 살펴보면 다음과 같다. 역시 함수를 통해 공백을 줄여준 후에 다시 측정해보니 평균과 중앙값의 차이가 이전과 다르게 확연히 줄어든 것을 볼 수 있으며, 평균적으로 22~23개의 어절을 사용함을 확인해 볼 수 있다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">count    12290.000000</span><br><span class="line">mean        28.416273</span><br><span class="line">std         22.040055</span><br><span class="line">min          1.000000</span><br><span class="line">25%         15.000000</span><br><span class="line">50%         23.000000</span><br><span class="line">75%         35.000000</span><br><span class="line">max        355.000000</span><br><span class="line">Name: question_after, dtype: float64</span><br></pre></td></tr></table></figure>
<ul>
<li>90%의 위치에 위치하고 있는 어절의 길이는 52개 였다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.quantile(sent_len_by_token, 0.90)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">52.0</span><br></pre></td></tr></table></figure>
<ul>
<li>또한, 위에서 355개의 어절을 갖는 데이터에 관해서도 이상치이므로 살펴보았다. 아래와 같이 오류 코드에 관한 질문이었기 때문에 공백이 많이 포함되어있을 수 밖에 없다는 것을 확인 할 수 있었다. 그러므로 이 데이터의 공백은 질문의 내용을 표현하는데 불필요한 요소가 아니므로 그대로 상태를 유지 할 것이다.</li>
</ul>
<p><img src="/image/eujeol_token_maximum_last.png" alt="355개의 어절을 갖는 질문"></p>
<ul>
<li>그 다음은 <code>음절 단위 길이를 분석</code>해 볼 것이다. 음절 단위의 기초 통계량은 아래와 같다. 평균적으로 136자를 사용하였으며, 중앙값은 112자이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">count    12279.000000</span><br><span class="line">mean       136.459647</span><br><span class="line">std        109.823703</span><br><span class="line">min          3.000000</span><br><span class="line">25%         74.000000</span><br><span class="line">50%        112.000000</span><br><span class="line">75%        167.000000</span><br><span class="line">max       2637.000000</span><br><span class="line">Name: question_after, dtype: float64</span><br></pre></td></tr></table></figure>
<ul>
<li>위에서의 기초 통계량 값을 시각화해서 간단히 살펴 보기위해서 아래와 같이 히스토그램을 활용하였다. 상식적으로도 알 수 있듯이, 음절이 어절보다 훨씬 단위가 클수밖에 없을 것이다. 여기서 볼 것은 꼬리 분포이다. 음절과 어절 단위로 살펴본 질문의 길이는 둘다 일정 수준이하에 주로 분포돼있고, 일정 수준 이상은 이상치가 존재하고 있다.</li>
</ul>
<p><img src="/image/sentence_length_by_emjeol_and_euojeol.png" alt="어절 및 음절 단위 문장 길이 히스토그램"></p>
<h3 id="모델-설정"><a href="#모델-설정" class="headerlink" title="모델 설정"></a>모델 설정</h3><ul>
<li>제일 먼저, TF-IDF 행렬을 사용해 LSA 분석의 일종인 TruncatedSVD 행렬을 이용해 문장 임베딩을 실행한 후, 키워드 검색어와의 유사한 문서들을 살펴 볼 것이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">import math</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line">from soynlp.word import WordExtractor</span><br><span class="line">from soynlp.tokenizer import LTokenizer</span><br><span class="line">from sklearn.decomposition import TruncatedSVD</span><br><span class="line">from sklearn.preprocessing import normalize</span><br><span class="line">from sklearn.metrics.pairwise import cosine_similarity</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">q_sentence = list(raw_data[<span class="string">'question_after'</span>])</span><br><span class="line"></span><br><span class="line">word_extractor = WordExtractor(min_frequency=1, min_cohesion_forward=0.05, min_right_branching_entropy=0.0)</span><br><span class="line">word_extractor.train(q_sentence)</span><br><span class="line">scores = word_extractor.word_scores()</span><br><span class="line"></span><br><span class="line">cohesion_scores = &#123;key:(scores[key].cohesion_forward * math.exp(scores[key].right_branching_entropy)) <span class="keyword">for</span> key <span class="keyword">in</span> scores.keys()&#125;</span><br><span class="line">tokenizer = LTokenizer(scores=cohesion_scores)</span><br><span class="line"></span><br><span class="line">tokens = []</span><br><span class="line"><span class="keyword">for</span> q_s <span class="keyword">in</span> q_sentence:</span><br><span class="line">    tokens.append(tokenizer.tokenize(q_s))</span><br><span class="line"></span><br><span class="line">sentence_by_tokens = [<span class="string">' '</span>.join(word) <span class="keyword">for</span> word <span class="keyword">in</span> tokens]</span><br><span class="line"></span><br><span class="line"><span class="comment">## TfidfVectorizer</span></span><br><span class="line">vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1,1), lowercase=True, tokenizer=lambda x : x.split(<span class="string">" "</span>))</span><br><span class="line">input_matrix = vectorizer.fit_transform(sentence_by_tokens)</span><br><span class="line"></span><br><span class="line">vocab2id = &#123;token : vectorizer.vocabulary_[token] <span class="keyword">for</span> token <span class="keyword">in</span> vectorizer.vocabulary_.keys()&#125;</span><br><span class="line"></span><br><span class="line">id2vocab = &#123;vectorizer.vocabulary_[token]: token <span class="keyword">for</span> token <span class="keyword">in</span> vectorizer.vocabulary_.keys()&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## TruncatedSVD</span></span><br><span class="line">svd =  TruncatedSVD(n_components=100)</span><br><span class="line">vecs = svd.fit_transform(input_matrix)</span><br><span class="line"></span><br><span class="line">criterion_sentence = <span class="string">"재입사자 연말정산"</span></span><br><span class="line"></span><br><span class="line">criterion_tokens = tokenizer.tokenize(criterion_sentence)</span><br><span class="line">criterion_tokens</span><br></pre></td></tr></table></figure>
<ul>
<li><code>재입사자 연말정산</code>이라는 키워드를 tokenizing한 결과는 아래와 같다. <code>재입사</code>, <code>자</code>, <code>연말정산</code> 이렇게 3가지 형태로 형태소를 분리했다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'재입사'</span>, <span class="string">'자'</span>, <span class="string">'연말정산'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">criterion_sentence_by_token = [<span class="string">" "</span>.join(criterion_tokens)]</span><br><span class="line">criterion_vec = vectorizer.transform(criterion_sentence_by_token)</span><br><span class="line">criterion_vec = svd.transform(criterion_vec)</span><br><span class="line"></span><br><span class="line">svd_l2norm_vectors = normalize(vecs, axis=1, norm=<span class="string">'l2'</span>)</span><br><span class="line">svd_l2norm_criterion_vectors = normalize(criterion_vec, axis=1, norm=<span class="string">'l2'</span>).reshape(100,1)</span><br><span class="line">cosine_similarity = np.dot(svd_l2norm_vectors, svd_l2norm_criterion_vectors)</span><br><span class="line"></span><br><span class="line">ls=[]</span><br><span class="line"><span class="keyword">for</span> idx, cosine_similarity <span class="keyword">in</span> enumerate(cosine_similarity.tolist()):</span><br><span class="line">    ls.append((idx, cosine_similarity))</span><br><span class="line">sorted_list = sorted(ls, key= lambda x: x[1], reverse=True)</span><br><span class="line"></span><br><span class="line">criterion_tokens_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.arange(len(sorted_list)):</span><br><span class="line">    criterion_tokens_list.append(criterion_tokens)</span><br><span class="line">show_list = []</span><br><span class="line"><span class="keyword">for</span> sorted_lists, criterion_tokens <span class="keyword">in</span> zip(sorted_list, criterion_tokens_list):</span><br><span class="line">    idx=sorted_lists[0]</span><br><span class="line">    similarity=sorted_lists[1]</span><br><span class="line">    tf_list=[]</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> criterion_tokens:</span><br><span class="line">        tf_list.append(token <span class="keyword">in</span> raw_data[<span class="string">'question'</span>].loc[idx])</span><br><span class="line">    <span class="keyword">if</span> (np.array(tf_list) == True).all():</span><br><span class="line">        show_list.append((idx, similarity))</span><br><span class="line">show_list</span><br></pre></td></tr></table></figure>
<ul>
<li>위의 show_list결과 중 몇가지 질문들을 살펴보자면, 아래와 같다.</li>
</ul>
<p><img src="/image/not_noun_score_with_show_list.png" alt="최종적으로 선택된 질문들"></p>
<ul>
<li>위에서 형태소가 <code>재입사</code>, <code>자</code>, <code>연말정산</code> 이렇게 3가지로 분리했던 것을 우리가 알 고 있듯이 <code>재입사자</code>, <code>연말정산</code> 2가지로 잘 분리하도록 명사 추출기 점수를 더한 점수를 통해서 다시 tokenize할 것이다.</li>
</ul>
<h3 id="명사-추출기를-통한-명사-점수를-합산한-score를-통한-tokenizer-활용"><a href="#명사-추출기를-통한-명사-점수를-합산한-score를-통한-tokenizer-활용" class="headerlink" title="명사 추출기를 통한 명사 점수를 합산한 score를 통한 tokenizer 활용"></a>명사 추출기를 통한 명사 점수를 합산한 score를 통한 tokenizer 활용</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import math</span><br><span class="line">from soynlp.word import WordExtractor</span><br><span class="line">from soynlp.noun import LRNounExtractor_v2</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line">from sklearn.decomposition import TruncatedSVD</span><br><span class="line">from sklearn.preprocessing import normalize</span><br><span class="line">from sklearn.metrics.pairwise import cosine_similarity</span><br><span class="line"></span><br><span class="line">noun_extractor = LRNounExtractor_v2(verbose=True)</span><br><span class="line">nouns = noun_extractor.train_extract(q_sentence)</span><br><span class="line"></span><br><span class="line">noun_scores = &#123;noun:score.score <span class="keyword">for</span> noun, score <span class="keyword">in</span> nouns.items()&#125;</span><br><span class="line">combined_scores = &#123;noun:score + cohesion_scores.get(noun, 0) <span class="keyword">for</span> noun, score <span class="keyword">in</span> noun_scores.items()&#125;</span><br><span class="line">combined_scores = combined_scores.update(</span><br><span class="line">    &#123;subword:cohesion <span class="keyword">for</span> subword, cohesion <span class="keyword">in</span> cohesion_scores.items()</span><br><span class="line">    <span class="keyword">if</span> not (subword <span class="keyword">in</span> combined_scores)&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tokenizer = LTokenizer(scores=combined_scores)</span><br><span class="line"></span><br><span class="line">tokens = []</span><br><span class="line"><span class="keyword">for</span> q_s <span class="keyword">in</span> q_sentence:</span><br><span class="line">    tokens.append(tokenizer.tokenize(q_s))</span><br><span class="line"></span><br><span class="line">sentence_by_tokens = [<span class="string">' '</span>.join(word) <span class="keyword">for</span> word <span class="keyword">in</span> tokens]</span><br><span class="line"></span><br><span class="line">vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1,1), lowercase=True, tokenizer=lambda x : x.split(<span class="string">" "</span>))</span><br><span class="line">input_matrix = vectorizer.fit_transform(sentence_by_tokens)</span><br><span class="line"></span><br><span class="line">vocab2id = &#123;token : vectorizer.vocabulary_[token] <span class="keyword">for</span> token <span class="keyword">in</span> vectorizer.vocabulary_.keys()&#125;</span><br><span class="line"></span><br><span class="line">id2vocab = &#123;vectorizer.vocabulary_[token]: token <span class="keyword">for</span> token <span class="keyword">in</span> vectorizer.vocabulary_.keys()&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">svd =  TruncatedSVD(n_components=100)</span><br><span class="line">vecs = svd.fit_transform(input_matrix)</span><br><span class="line"></span><br><span class="line">criterion_sentence = <span class="string">"재입사자 연말정산"</span></span><br><span class="line"></span><br><span class="line">criterion_tokens = tokenizer.tokenize(criterion_sentence)</span><br><span class="line">criterion_tokens</span><br></pre></td></tr></table></figure>
<ul>
<li><code>재입사자 연말정산</code>이라는 검색 키워드를 tokenizing한 결과 아래와 같이 <code>재입사자</code>, <code>연말정산</code>이라고 분류해냈다. 허나, 위에서와 같이</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'재입사자'</span>, <span class="string">'연말정산'</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>sorted_list에 포함된 질문들을 보면 대부분 연말정산이 들어가있는 질문들이 유사도가 높다는 것을 확인할 수 있었다. <code>이런 문제점은 필자의 개인적인 생각으로 input matrix로 TF-IDF matrix를 사용했기 때문에 전체 질문 건수에서 연말정산이 차지하는 비율이 높다보니 나타나는 현상</code>이라고 생각했다. 이를 해결하기 위해 먼저 필자는 <code>각 분야의 질문의 수를 맞추거나 다른 방법의 input matrix를 사용해서 문제를 해결해야 할 것이라고 생각</code>했다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">criterion_sentence_by_token = [<span class="string">" "</span>.join(criterion_tokens)]</span><br><span class="line">criterion_vec = vectorizer.transform(criterion_sentence_by_token)</span><br><span class="line"></span><br><span class="line">criterion_vec=svd.transform(criterion_vec)</span><br><span class="line"></span><br><span class="line">svd_l2norm_vectors = normalize(vecs, axis=1, norm=<span class="string">'l2'</span>)</span><br><span class="line">svd_l2norm_criterion_vectors = normalize(criterion_vec, axis=1, norm=<span class="string">'l2'</span>).reshape(100,1)</span><br><span class="line">cosine_similarity = np.dot(svd_l2norm_vectors, svd_l2norm_criterion_vectors)</span><br><span class="line"></span><br><span class="line">ls=[]</span><br><span class="line"><span class="keyword">for</span> idx, cosine_similarity <span class="keyword">in</span> enumerate(cosine_similarity.tolist()):</span><br><span class="line">    ls.append((idx, cosine_similarity))</span><br><span class="line">sorted_list = sorted(ls, key= lambda x: x[1], reverse=True)</span><br><span class="line"></span><br><span class="line">criterion_tokens_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.arange(len(sorted_list)):</span><br><span class="line">    criterion_tokens_list.append(criterion_tokens)</span><br><span class="line">show_list_noun = []</span><br><span class="line"><span class="keyword">for</span> sorted_lists, criterion_tokens <span class="keyword">in</span> zip(sorted_list, criterion_tokens_list):</span><br><span class="line">    idx=sorted_lists[0]</span><br><span class="line">    similarity=sorted_lists[1]</span><br><span class="line">    tf_list=[]</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> criterion_tokens:</span><br><span class="line">        tf_list.append(token <span class="keyword">in</span> raw_data[<span class="string">'question'</span>].loc[idx])</span><br><span class="line">    <span class="keyword">if</span> (np.array(tf_list) == True).all():</span><br><span class="line">        show_list_noun.append((idx, similarity))</span><br><span class="line">show_list_noun</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">show_list_index = []</span><br><span class="line"><span class="keyword">for</span> idx, score <span class="keyword">in</span> show_list:</span><br><span class="line">    show_list_index.append(idx)</span><br><span class="line"></span><br><span class="line">show_list_noun_index = []</span><br><span class="line"><span class="keyword">for</span> idx, score <span class="keyword">in</span> show_list_noun:</span><br><span class="line">    show_list_noun_index.append(idx)</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span>(show_list_noun_index) == <span class="built_in">set</span>(show_list_index)</span><br></pre></td></tr></table></figure>
<ul>
<li>결과는 False로 처음 명사추출기 점수를 더해서 tokenizing한 결과가 더 많고 좋은 질문들을 검색해 내었다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">False</span><br></pre></td></tr></table></figure>
<h3 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h3><ul>
<li><p>연말정산 카테고리의 문건이 전체 문건 중 다수를 포함하고 있기 때문에, 그에 따른 영향으로 검색 키워드에 연말정산이 포함되면 유사도가 큰 문건들은 대부분 연말정산의 내용만을 담고 있었기 때문에 추후에 tokenizing한 검색 키워드를 전부 포함하고 있는 문건들을 출력해주는 방식으로 바꾸었다. 처음의 model을 최종적으로 선택할 것이며, 현재의 검색어 시스템에서 <code>재입사자</code>와 <code>재입사자 연말정산</code>이라는 두 가지 키워드에 대한 검색이 아래 그림과 같이 <code>재입사자</code>는 11건 <code>재입사자 연말정산</code>는 5건으로 <code>재입사자</code> 키워드에서 대부분이 연말정산에 관한 내용임에도 불구하고 검색이 되지 않는 문제점은 해결할 수 있다는 것에 만족할 것이다. 게다가 기존의 <code>띄어쓰기에 취약한 문제점도 보완</code>할 수 있기에 이전보다는 더 나은 검색 시스템이라고 주장한다.</p>
</li>
<li><p>아래 그림은 더존 온라인 고객센터의 smart A 게시판에서 동일한 내용이지만 띄어쓰기만 다른 <code>재입사자 연말정산</code>(위)과 <code>재입사자 연말 정산</code>(아래)이라는 두 키워드를 검색한 결과이다.</p>
</li>
</ul>
<p><img src="/image/correct_sentence_keyword_thezone.png" alt="재입사자 연말정산 검색 결과"></p>
<p><img src="/image/wrong_sentence_keyword_thezone.png" alt="재입사자 연말 정산 검색 결과"></p>
<ul>
<li>위 같이 띄어쓰기가 달라도 검색어를 입력했을 때 동일한 결과를 얻을 수 있었다.</li>
</ul>
<p><img src="/image/wrong_sentence_tokenizing.png" alt="재입사자 연말 정산 키워드 토크나이징 결과"></p>
<p><img src="/image/result_thezone_search_system.png" alt="모델의 결과"></p>
<h3 id="보완점"><a href="#보완점" class="headerlink" title="보완점"></a>보완점</h3><ul>
<li><code>TF-IDF를 사용하였기 때문에 단어와 단어가 사용된 문건의 수에 의한 가중치에 의해 영향을 받는다는 점을 고려</code>했었야 한다는 판단을 내렸다. 또한, 검색 키워드를 나중에 <code>유사도를 계산한 리스트 중에 필터링 역할로 사용하기에 검색 키워드를 기반으로 하되 불필요한 부분을 제거하여 사용할 수 있는 알고리즘을 만들면 더 좋은 검색 시스템을 구성할 수 있을 것으로 기대</code> 된다. 또한, <code>검색 시스템 뿐만 아니라 자신이 질문을 작성한 후에 자신의 질문과 유사도가 높은 질문들의 리스트를 보여주는 페이지로 전환시켜 주는 서비스</code>도 좋을 것 같다. 이러한 생각이 들었던 이유는 더존 온라인 고객센터의 답변들 중 연말정산 같은 회계분야의 특정 시즌 때 질문들에 대한 답변이 조금 늦는 경우(물론 하루이상을 넘기지 않고 답변을 다 달아주신다)를 보았는데, 위와 같은 시스템을 도입하면 온라인 고객센터의 직원 분들도 덜 고생하시고, 고객님들께서도 조금 더 해결방안을 빨리 찾으실 수 있을 것 같다고 생각했기 때문이다.</li>
</ul>
<h3 id="토이-프로젝트를-하면서-느낀점"><a href="#토이-프로젝트를-하면서-느낀점" class="headerlink" title="토이 프로젝트를 하면서 느낀점"></a>토이 프로젝트를 하면서 느낀점</h3><ul>
<li>제일 많은 것을 느낀것은 전처리부분이었다. 데이터 분석에 있어서 전처리가 80%이상이라는 말은 매번 되새기게되지만, 이번에는 특히나 더 와 닿았던 토이 프로젝트 였던 것 같다. 다음 토이 프로젝트로 질문에 대한 답변을 작성해 주는 챗봇을 구현해 보려고하는데, 질문의 카테고리별로 모델을 따로 만들어야 될 것 같다는 생각이 들었다. 챗봇을 구현할 때 먼저 입,출력 벡터의 크기를 일정하게 정해서 부족하면 패딩처리하는 방식으로 사용하여야 하는데, 각 카테고리별로 답변을 주는 평균적인 답변과 질문의 sequence의 길이가 다를 것이라고 생각 했기 때문이다.</li>
</ul>

        </div>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 하단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="9861011486"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "HeungBae Lee"
        },
        "headline": "NLP 실습 유사도를 반영한 검색 키워드 최적화",
        "image": "https://heung-bae-lee.github.io/image/the_zone_online_center.png",
        "keywords": "",
        "genre": "NLP",
        "datePublished": "2020-02-11",
        "dateCreated": "2020-02-11",
        "dateModified": "2020-02-20",
        "url": "https://heung-bae-lee.github.io/2020/02/11/NLP_12/",
        "description": "
이번 실습의 소개는 프로젝트성으로 진행 할 것이다.

프로젝트 소개더존 ICT 온라인 고객센터 키워드 검색 최적화 및 챗봇 구현
프로젝트를 하게 된 계기

먼저, 더존 온라인 고객센터 페이지 중 smart A에 관한 페이지에서 전체 탭을 클릭한 후, 살펴본 QnA 페이지를 살펴보았다.


필자는 고객들의 입장에서 생각해보았을때, 자신이 작성하는 질문(물론"
        "wordCount": 4384
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/heungbae.lee" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HEUNG-BAE-LEE" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2020/02/20/NLP_13/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            NLP 실습 Chat bot 만들기
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2020/02/11/NLP_11/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">NLP 실습 텍스트 유사도 - 02 (XGBoost, 1D-CNN, MaLSTM)</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/20/NLP_13/" class="title">NLP 실습 Chat bot 만들기</a></p>
                            <p class="item-date"><time datetime="2020-02-20T07:01:42.000Z" itemprop="datePublished">2020-02-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/11/NLP_12/" class="title">NLP 실습 유사도를 반영한 검색 키워드 최적화</a></p>
                            <p class="item-date"><time datetime="2020-02-11T08:16:56.000Z" itemprop="datePublished">2020-02-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/11/NLP_11/" class="title">NLP 실습 텍스트 유사도 - 02 (XGBoost, 1D-CNN, MaLSTM)</a></p>
                            <p class="item-date"><time datetime="2020-02-10T16:36:58.000Z" itemprop="datePublished">2020-02-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/10/NLP_10/" class="title">NLP 실습 텍스트 유사도 - 01 (데이터 EDA 및 전처리)</a></p>
                            <p class="item-date"><time datetime="2020-02-09T17:34:30.000Z" itemprop="datePublished">2020-02-10</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/08/NLP_09/" class="title">NLP 문장 수준 임베딩 - 02</a></p>
                            <p class="item-date"><time datetime="2020-02-07T16:02:58.000Z" itemprop="datePublished">2020-02-08</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bayes/">Bayes</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n/">CS231n</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Front-end/">Front end</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/crawling/">crawling</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-engineering/">data engineering</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/growth-hacking/">growth hacking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">5</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crawling/">crawling</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CS231n/" style="font-size: 10px;">CS231n</a> <a href="/tags/crawling/" style="font-size: 20px;">crawling</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 사이드바 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="3275421833"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 HeungBae Lee</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://heung-bae-lee.github.io/2020/02/11/NLP_12/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</body>
</html>
