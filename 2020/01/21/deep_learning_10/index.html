<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    

    
    <title>Attention 기법 | DataLatte&#39;s IT Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    
    <meta name="description" content="Attention 기법Sequence-to-sequence 우선, Attention 기법이 가장 먼저 적용되었던 모델인 Sequence-to-sequence 모델을 살펴보면서 간략하게 conception적인 것을 살펴보겠다.  아래 그림의 왼쪽 부분은 Encoder 구조로 되어 있어, Input에 번역하고자 하는 문장을 단어 하나씩 받는 형태로 되어있다.">
<meta property="og:type" content="article">
<meta property="og:title" content="Attention 기법">
<meta property="og:url" content="https://heung-bae-lee.github.io/2020/01/21/deep_learning_10/index.html">
<meta property="og:site_name" content="DataLatte&#39;s IT Blog">
<meta property="og:description" content="Attention 기법Sequence-to-sequence 우선, Attention 기법이 가장 먼저 적용되었던 모델인 Sequence-to-sequence 모델을 살펴보면서 간략하게 conception적인 것을 살펴보겠다.  아래 그림의 왼쪽 부분은 Encoder 구조로 되어 있어, Input에 번역하고자 하는 문장을 단어 하나씩 받는 형태로 되어있다.">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://heung-bae-lee.github.io/image/Sequence_to_sequence.png">
<meta property="og:updated_time" content="2020-01-23T16:59:28.017Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Attention 기법">
<meta name="twitter:description" content="Attention 기법Sequence-to-sequence 우선, Attention 기법이 가장 먼저 적용되었던 모델인 Sequence-to-sequence 모델을 살펴보면서 간략하게 conception적인 것을 살펴보겠다.  아래 그림의 왼쪽 부분은 Encoder 구조로 되어 있어, Input에 번역하고자 하는 문장을 단어 하나씩 받는 형태로 되어있다.">
<meta name="twitter:image" content="https://heung-bae-lee.github.io/image/Sequence_to_sequence.png">
<meta property="fb:app_id" content="100003222637819">


    <link rel="canonical" href="https://heung-bae-lee.github.io/2020/01/21/deep_learning_10/">
   
    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-154199624-1', 'auto');
ga('send', 'pageview');

</script>

    
    


    <script data-ad-client="ca-pub-4604833066889492" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<link rel="alternate" href="/rss2.xml" title="DataLatte's IT Blog" type="application/rss+xml">
</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">DataLatte&#39;s IT Blog using Hexo</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Bayes/">Bayes</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/CS231n/">CS231n</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Front-end/">Front end</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/crawling/">crawling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/data-engineering/">data engineering</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/growth-hacking/">growth hacking</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/hexo/">hexo</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/linear-algebra/">linear algebra</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/machine-learning/">machine learning</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/deep-learning/">deep learning</a>
    </h1>
</div>

                        <div class="main-body-content">
			    <article id="post-deep_learning_10" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Attention 기법
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2020/01/21/deep_learning_10/" class="article-date">
            <time datetime="2020-01-21T08:10:39.000Z" itemprop="datePublished">2020-01-21</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h1 id="Attention-기법"><a href="#Attention-기법" class="headerlink" title="Attention 기법"></a>Attention 기법</h1><h3 id="Sequence-to-sequence"><a href="#Sequence-to-sequence" class="headerlink" title="Sequence-to-sequence"></a>Sequence-to-sequence</h3><ul>
<li><p>우선, Attention 기법이 가장 먼저 적용되었던 모델인 Sequence-to-sequence 모델을 살펴보면서 간략하게 conception적인 것을 살펴보겠다.</p>
</li>
<li><p>아래 그림의 왼쪽 부분은 <code>Encoder</code> 구조로 되어 있어, Input에 번역하고자 하는 문장을 단어 하나씩 받는 형태로 되어있다. 마지막 입력 단어에는 EOS(End-Of-Sequence)라는 특별한 단어(Token)를 받도록 되어있다. 마지막 EOS까지 받은 뒤의 Output을 Context라고 한다. 그렇게 나온 Context를 <code>Decoder</code> 구조에서 넘겨 받으며, 동시에 SOS(Start-Of-Sequence)라는 Token을 처음 Input에서 입력해주면 넘겨 받은 Context로 부터 첫번째 단어를 생성한다. 생성된 단어를 다음 입력으로 넣어주고 또 다음 단어를 생성하고 이런 작업을 EOS Token이 Output으로 나올때까지 반복해준다.</p>
</li>
<li><p>Encoder는 결국 Context를 만들기 위해서 RNN으로 동작하는 구조이고, Decoder는 한단어씩 출력하는데, 그 출력된 Output(단어)을 오른쪽으로 Shift해서 입력으로 받은 뒤 새로운 단어를 만들어주는 구조이다.</p>
</li>
</ul>
<p><img src="/image/Sequence_to_sequence.png" alt="Sequence-to-sequence"></p>
<h3 id="영어-문장의-데이터화"><a href="#영어-문장의-데이터화" class="headerlink" title="영어 문장의 데이터화"></a>영어 문장의 데이터화</h3><p><img src="/image/English_data.png" alt="영어 문장의 데이터화"></p>
<h3 id="한글-문장의-데이터화"><a href="#한글-문장의-데이터화" class="headerlink" title="한글 문장의 데이터화"></a>한글 문장의 데이터화</h3><p><img src="/image/Korean_data.png" alt="한들 문장의 데이터화"></p>
<ul>
<li>Seq2seq 모델같은 경우는 <code>입출력간의 step이 너무 멀리 떨어져 있으면 Gradient Vanishing이 일어나 잘 학습되지 않는다.</code> 예를 들어 아래와 같은 그림에서 처음 입력인 $x_{0}$가 $y_{1}$에 영향을 준다면(영어에서 한글로 번역할시 어순이 반대로 되어있는 경우를 예시로 생각하면 이해하기 쉽다.), BPTT로 펼쳐놓고 봤을때, 기본적으로 Encoder단과 Decoder단이 분리가 되어 있기 때문에, Ecoder단의 앞쪽과 Decoder 뒷쪽과은 거리가 멀다. 그렇다면 아무리 LSTM을 쓰고 GRU를 사용한다고 하더라도 한계가 있다.</li>
</ul>
<p><img src="/image/Gradient_vanishing_in_RNN.png" alt="RNN에서의  Gradient Vanishing"></p>
<ul>
<li>위에서 언급했던 것과 같이 그렇다면 Gradient Vanishing 문제를 해결할 수 있는 방법이 없을까? 그에 대한 답을 아래의 그림을 통해 설명하겠다. 이전에는 Encoder 부분에서 Context 하나(Feature vector 하나)만 넘겨줘서 그 Context를 통해 Decoder가 출력을 내주었어야 했는데, 직관적으로 볼때 Input들을 통해 만든 Feature vector가 Input들의 많은 부분을 커버할 수 있기도 힘들것이라는 생각이들지만, Decoder 부분의 RNN을 통해 지나면서 우리가 원하는 방향대로 넘어갈것이라는 보장 또한 없다. 그래서 이제는 <code>Encoder Hidden state를 모아서 Decoder로 각각 전달시켜 줌으로써 각 출력에 필요한 Context를 새로이 뽑을 수 있는 구조로 변경</code>해주어 기울기 소실 문제를 해결할 수 있을 것이다. 이런 구조를 어떻게 효율적으로 구성할 수 있을까에 대한 답이 <code>Attention 메커니즘</code>이다.</li>
</ul>
<p><img src="/image/No_more_Gradient_Vanishing.png" alt="Gradient Vanishing을 해결할 수 있는 방법"></p>
<ul>
<li>Attention 메커니즘에서는 예를 들어 Encoder 부분과 Decoder 부분의 Layer들이 아래 그림에서 처럼 색깔별로 연관되어 있다고 했을때, 각 연관되어 있는 부분을 알게 해주는 것이 Attention Mechanism의 기본 아이디어이다.</li>
</ul>
<p><img src="/image/Attention.png" alt="Attention 메커니즘"></p>
<h1 id="Attention-신경망"><a href="#Attention-신경망" class="headerlink" title="Attention 신경망"></a>Attention 신경망</h1><p><img src="/image/Query_key_value.png" alt="Query, Key-Value"></p>
<ul>
<li>질의-응답이 이루어지는 메커니즘을 살펴보면, query를 날려주게 되면, 우선 key들을 나열하여 동일한 것을 찾아낸다. 그 후에는 key-value쌍에서 동일한 부분의 value를 출력해준다.</li>
</ul>
<p><img src="/image/Querying.png" alt="Querying"></p>
<ul>
<li>Attention mechanism은 key-value 쌍이 있고, query를 날려서 query와 key를 유사한지 비교를 해준뒤, <code>유사도를 고려한 Value들을 섞어서 Aggregation(합성)을 해준것이 Attention value</code>이다.</li>
</ul>
<p><img src="/image/Attention_mechanism.png" alt="Attention mechanism"></p>
<p><img src="/image/Seq2seq.png" alt="Seq2seq에 Attention mechanism 적용은?"></p>
<ul>
<li><code>대부분의 Attention network에서는 key와 value를 같은 값을 사용</code>한다. <code>Seq2seq에서는 Encoder의 Hidden Layer들을 key와 value로 사용</code>한다. 직관적으로 생각을 해보면, Decoder에서 어떤것을 찾고자 한다면, 찾고자 하는 것에 대한 정보는 Encoder에서 찾을 수 있을 것이다. 그렇기에 Key-value가 Encoder의 Hidden Layer가 되는 것이다.</li>
</ul>
<p><img src="/image/Seq2seq_key_Value.png" alt="Seq2seq의 Key-Value"></p>
<ul>
<li><code>또한, Seq2seq에서는 Decoder의 Hidden Layer들을 Query로 사용</code>한다. 주의할 점은, <code>Encoder와 달리 하나 앞선 time-step의 Hidden Layer를 사용한다는 점</code>이다. 왜냐하면 현재의 출력을 내기 위해서는 현재의 출력이 사용될 수는 없기 때문에 즉, 미래(예측)를 가지고 현재 출력을 만들어낼 수는 없기 때문에 하나 앞선 Hidden Layer를 query로 사용하는 것이다.  </li>
</ul>
<p><img src="/image/Seq2seq_Querying.png" alt="Seq2seq의 Query"></p>
<ul>
<li>Key와 Value는 서로 동일한 Encoder의 Hidden Layer들이 사용되며, Query는 Decoder에 있는 각각의 Hidden Layer들이 될 것이며, i-번째 time step에 대한 Query를 날려서 Encoder에 있는 모든 Key와 유사도를 비교해서 최종적으로는 유사도를 고려한 Aggregation(종합)한 Attention Value를 출력해 준다.</li>
</ul>
<p><img src="/image/Seq2seq_Attention_mechanism.png" alt="Seq2seq에 Attention mechanism을 적용"></p>
<ul>
<li>이렇게 Attention Value($a_{0}$)를 입력으로 받아 $s_{0}$ Hidden Layer에서 LSTM 구조를 거쳐 $s_{1}$ Hidden Layer가 나올 것이다. 이 새롭게 얻어진 $s_{1}$ Hidden Layer에다가 $s_{0}$를 통해 얻어진 Attention Value($a_{0}$) Concatenate를 해서 출력을 내준다.($v_{1}$) 이전에는 Decoder에서 그대로 Hidden Layer가 나오던 것이 이제는 Encoder의 Hidden Layer들을 비교해서 만들어낸 Attention Value를 같이 출력으로 냄으로써, Encoder 부분의 value들을 잘 가져올 수 있도록 해주었다.</li>
</ul>
<p><img src="/image/Seq2seq_Application.png" alt="Seq2seq - Application"></p>
<h1 id="Attention-is-all-you-need-Transformer-모델"><a href="#Attention-is-all-you-need-Transformer-모델" class="headerlink" title="Attention is all you need - Transformer 모델"></a>Attention is all you need - Transformer 모델</h1><p><img src="/image/Attention_is_all_you_need.png" alt="Attention is all you need"></p>
<ul>
<li>RNN 같은 경우는 입력을 순서대로 넣어주기 때문에 입력된 단어의 위치를 따로 표시하지 않아도 되지만, <code>Transformer 구조</code> 같은 경우에는 병렬적으로 계산을 하기 때문에, 현재 계산하고 있는 단어가 어느 위치에 있는 단어인지를 표현을 해주어야 해서 <code>positional encoding</code>을 사용한다.</li>
</ul>
<p><img src="/image/Charateristics_of_Network.png" alt="네트워크의 특성"></p>
<ul>
<li>우선, Transformer와 Seq2seq 모델을 비교하자면, Seq2seq 모델은 Encoder와 Decoder가 있고 그 사이에 Context가 전달되는 구조를 가지고 있다. Transformer 모델의 경우는 Input쪽(왼쪽의 빨간색 박스)과 Output쪽(왼쪽의 파란색 박스)로 구성되며, Input쪽에서는 Input embedding이 들어가서 Encoding이 일어나고 Context가 전달이 되어 Output쪽의 Decoder부분에서 Decoding이 되서 출력이 나오게 된다. 전체적으로 구조는 비슷해보이지만, <code>Seq2seq 모델은 RNN로 구성되어 있어서 순차적으로 이루어지게 되어있고, Transformer 모델은 병렬적으로 계산되므로 Input쪽이 동시에 계산되고 Output쪽이 동시에 계산되는 형태로 학습이되는 점이 차이점이다.</code></li>
</ul>
<p><img src="/image/Transformer_vs_Seq2seq.png" alt="Transformer vs Seq2seq"></p>
<ul>
<li>Input을 먼저 보면, 아래의 노란색 Matrix 형태로 되어 있으며, 일반적으로는 입력 단어의 가짓수와 출력 단어의 가짓수는 동일할 것이다. 만약 기계번역처럼 2개의 언어가 다르다면, 다를 것이다! Output은 원래 Seq2seq의 구조에서 보았듯이 shift 시킨 입력을 넣어주었었던 것과 같이 SOS를 넣어주고 EOS를 빼준 형태로 Outputs에 넣어준다.</li>
</ul>
<p><img src="/image/Inputs_and_Outputs.png" alt="Inputs &amp; Output"></p>
<ul>
<li>One-hot encoding으로 되어있던 것들을 Embedding해서 각각의 Embedding에 넣어준다.</li>
</ul>
<p><img src="/image/Word_Embedding_in.png" alt="Word Embedding"></p>
<ul>
<li>Positional Encoding은 <code>시간적으로 위치가 따르때마다 고유의 코드를 생성해서 Input Embedding에 더해주는 형태로 구성</code>되어있다. 이렇게 해줌으로써, <code>전체 Sequence의 길이 중 상대적 위치에 따라서 고유의 벡터를 생성하여 Embedding된 벡터에 더해주게 된다.</code> 예를들면, 보통 Embedding된 벡터들은 0를 기준으로 분포가되어있는데 Input Embedding에 sin과 cosine을 조합해서 만들어진 feature 벡터를 더해주는 것이라고 보면된다. 위에서 말했듯, Embedding들은 0을 기준으로 분포하므로 여기에 sin과 cosine을 조합해 만든 Feature 벡터를 더해준다해도 크게 손상이 가지 않기 때문에 걱정하지 않아도된다.</li>
</ul>
<p><img src="/image/Related_in_Positional_Encoding.png" alt="Embedding의 분포 및 Positional Encoding의 원리"></p>
<p><img src="/image/Positional_Encoding.png" alt="Positional Encoding"></p>
<ul>
<li>Dot-Product는 우리가 알고있는 내적과 동일하다. 그리고 <code>Mask를 이용해서 Illegal connection의 Attention을 금지</code>한다는 의미는 self-attention에 대한 이야기인데,  일반적인 Attention 구조는 Decoder쪽에 Hidden Layer를 통해 Output을 내려면 Encoder 쪽에 Hidden Layer 전체와 비교해서 산출을해야하므로 이런 경우는 괜찮지만, <code>Self-attention</code>에서는 Decoder를 똑같은 Decoder 자기 자신과 Attention을 할 수가 있는데 여기서 Decoder 부분의 해당 Hidden Layer를 산출하려면 순차적으로 출력이 나온다고 했을때 해당 부분의 Decoder보다 이후 시점은 아직 결과가 산출되지 않았기 때문에 그보다 앞선 시점의 Decoder부분에서의 Hidden Layer들만을 사용할 수 있다는 이야기이다. 여기서 비교할 때 사용할 수 없는 Hidden Layer들을 <code>Illegal connection</code>이라고 한다. 이런 Illegal connection은 Mask를 통해 -inf로 보내버리면 Softmax에서 값이 0이되는 것을 이용하여 attention이 안되도록 구현하고 있다.</li>
</ul>
<p><img src="/image/Scaled_Dot_Product_Attention.png" alt="Scaled Dot-Product Attention"></p>
<p><img src="/image/Principal_of_self_attention.png" alt="Self Attention의 원리"></p>
<ul>
<li>Multi-Head Attention은 쉽게 말해 <code>Scaled Dot-Product Attention을 h개를 모아서 병렬적으로 연산을 할 수 있게끔하는 것</code>이다. h개를 사용함으로써 <code>같은 입력에 대해서 더 풍부한 출력이 나타날 수 있다.</code> 또한, 여기서 처음 Linear 연산(Matrix Mult)을 하는 것은 Query, Key, Value 각각 중 특정 차원만을 보겠다는 이야기이며, 차원을 줄여주어 병렬에 유리한 구조를 만드는 역할도 있다. 그러므로 이 연산을 한 후에 h가지로 병렬처리함으로써 풍부한 출력을 얻을 수 있는 것을 이해할 수 있다.</li>
</ul>
<p><img src="/image/Multi_Head_Attention.png" alt="Multi-Head Attention"></p>
<p><img src="/image/Masked_Multi_Head_Attention.png" alt="Masked Multi-Head Attention"></p>
<ul>
<li>Multi-Head Attention이 Transformer에 어떻게 적용되어 있는지 살펴보자. <code>Self-Attention은 Decoder와 동일한 Decoder를 참조하므로 Key와 Query와 Value는 모두 같은 것</code>이다. Encoding 같은 경우에는 causual system일 필요가 딱히 없기 때문에 Mask 없이 Key, Value, Query가 그대로 사용될 수 있지만, Decoder 부분같은 경우에는 현재 Query하려고 하는 것이 Key와 value가 Query보다 더 앞서서 나올수 없기 때문에 Mask를 활용한 Masked Multi-Head Attention을 사용한다. 이렇게 Encoder단의 Self-Attention을 통해서 Attention이 강조되어 있는 Feature들을 추출을 해주고 Decoder단에서는 Output Embedding(or 이전의 출력값)이 들어왔을 때 이것을 통해 Masked Multi-Head Attention을 통해 Feature 추출을 해주고, 그 다음에 붉은 색 박스 부분에서는 이 Decoder를 통해 추출된 Feature가 Query로 들어가고, 나머지 Key, Value는 Encoder를 통해 만들어진 출력을 가지고 입력을 받게된다. 결국에는 이런 구조는 <code>Seq2seq 모델의 Attention과 동일한 구조가 되게 될 것이다.</code></li>
</ul>
<p><img src="/image/Multi_Head_Attention_in_action.png" alt="Transformer에 적용된 Multi-Head Attention"></p>
<ul>
<li>Position-wise Feed-Forward는 특별한 것은 아니고 앞서서 말했던 것과 같이 아래 초록색 박스는 가로가 문장의 길이, 세로가 One-hot vector로 표현된 단어인데 단어 하나마다 입력으로 들어가서 출력으로 나온다라는 의미이다.</li>
</ul>
<p><img src="/image/Position_wise_Feed_Forward.png" alt="Position-wise Feed-Forward"></p>
<ul>
<li>Feed-Forward가 일어난 다음이나 Self-Attention이 일어난 다음에는 이전의 것(Skip connection)을 가져와서 더 해준 뒤 Layer Normalization을 수행해서 사용하고 있다. Layer Normalization은 Batch의 영향을 받지 않는 Normalization이라고 생각하면된다.</li>
</ul>
<p><img src="/image/Add_Norm.png" alt="Add &amp; Norm"></p>
<ul>
<li>마지막 Feed-Forward에 의해서 마지막 Feature 출력이 나오게 되면 Linear 연산(Matrix Mult)을 사용해서 출력 단어 종류의 수에 맞추게 One-hot vector로 만들어준다. 그런 다음 Softmax를 이용해서 어떤 단어인지 classification을 한다.</li>
</ul>
<p><img src="/image/Output_softmax.png" alt="Output Softmax"></p>
<p><img src="/image/Attention_is_really_all_you_need.png" alt="Attention is really all you need"></p>
<h1 id="Attention-신경망의-수식적-이해"><a href="#Attention-신경망의-수식적-이해" class="headerlink" title="Attention 신경망의 수식적 이해"></a>Attention 신경망의 수식적 이해</h1><ul>
<li><p>Attention mechanism은 Key와 Query를 비교하는 Comparison을 통해 그에 따른 유사도를 가중치처럼 사용하여 Key에 맞는 value들의 조합으로 Aggregation(가중합)을 통하여 Attention value를 만들어 주는 구조가 Attention mechanism이었다. 그러므로 결국 Query와 비슷하면 비슷할 수록 높은 가중치를 주어 출력을 주는 것이다.</p>
</li>
<li><p>compare 함수로는 Dot-Product가 많이 쓰이며, 저기서 k와 q가 각각 벡터의 norm이 1이라면 결국 코사인 유사도를 구하는 것과 동일해 질 것이다. 그러나 길이가 1이 아닐 경우를 생각해서 <code>Dot-product이후에 softmax를 사용하여 전체의 합을 1로 만들어 주게끔하여 각각의 가중치들을 하나의 확률로 사용할 수 있게끔 변환해 주어 사용</code>한다.</p>
</li>
</ul>
<p><img src="/image/attention_mechanism_01.png" alt="Attention mechanism"></p>
<ul>
<li>Seq2seq 모델은 Encoder구조를 통해 Feature들을 만들게 되고 최종적으로는 출력으로 Context를 생성하여 이 Context 하나에 의지해서 Decoder는 SOS(Start Of Sequence)를 시작으로 출력으로는 단어를 하나씩 내어주는 모델이다.</li>
</ul>
<p><img src="/image/seq2seq_01.png" alt="Seq2seq"></p>
<ul>
<li>Key-value쌍은 기존의 Context만을 보며 출력을 내주었던 것과 다르게 Decoder부분의 Hidden Layer에 대한 출력을 낼때, Encoder 부분에 중간중간 부분을 알게하기 위해서 사용되어진다.</li>
</ul>
<p><img src="/image/seq_key_value.png" alt="Seq2seq - Key-Value"></p>
<ul>
<li>Query는 Decoder의 Hidden Layer들을 사용하는데, <code>해당 출력을 해야하는 RNN구조의 하나 이전의 time-step의 Hidden Layer를 Query로 사용한다는 점을 기억</code>하자! 아래 그림에서는 $s_{0}, s_{1}, s_{2}$가 해당한다.</li>
</ul>
<p><img src="/image/seq2seq_query.png" alt="Seq2seq - Query"></p>
<ul>
<li>i-th query가 들어오게되면 각각 Key와 비교를 하게되고, 앞에서 말한것과 같이 내적한 뒤 Softmax를 해줘 가중치로 만든뒤에 각각에 해당하는 Value와 곱해 가중합을 한 것을 Attention value로 산출한다.</li>
</ul>
<p><img src="/image/seq2seq_attention_mechanism_01.png" alt="Seq2seq - Attention mechanism"></p>
<ul>
<li>아래 그림에서 출력과 RNN 구조사이에 실제로는 FC Layer가 하나 존재해서 출력을 One-hot vector로 만들어준다.</li>
</ul>
<p><img src="/image/seq2seq_application.png" alt="Seq2seq -  Application"></p>
<p><img src="/image/Attention_paractice.png" alt="Attention의 구현"></p>
<ul>
<li>$X\in R^{BXLXN}$에서 B:Batch size, L:문장의 길이, N:One-hot vetor나 embedding Feature의 길이를 의미하며, 여기서 Decode 쪽으로 Context를 넘길때는 LSTM이라면 Hidden State와 Cell State 둘다 넘겨주어야 하기에 Batch_size X Hidden state의 Feature 갯수인 M을 사이즈로 갖는 tensor를 넘겨줄 것이다.</li>
</ul>
<p><img src="/image/Encoder_inputs_and_outputs.png" alt="Encoder 입출력"></p>
<p><img src="/image/Decoder_inputs_and_outputs.png" alt="Decoder 입출력(학습 단계)"></p>
<ul>
<li>Encoder의 Hidden State인 H가 Attention mechanism에 Key와 Value로 입력이 되고, Query에는 Decoder의 한 step 앞선 Hidden State를 사용하게 된다.</li>
</ul>
<p><img src="/image/Output_w_attention.png" alt="Output w/ Attention(학습 단계)"></p>
<p><img src="/image/attention_is_all_you_need_01.png" alt="Attention is all you need"></p>
<ul>
<li><code>만약에 Input의 언어와 Output의 언어가 다르다면, 단어의 가짓수나 길이가 달라질 수있다는 점을 주의</code>하자!</li>
</ul>
<p><img src="/image/INPUTS_AND_OUTPUTS_01.png" alt="Input &amp; Output"></p>
<ul>
<li>sin법칙과 cosine법칙에 의해 각각 분리해서 쓸수 있는데 결국 덧셈과 뺄셈으로 이 Positional Encoding이 달라지기 때문에 FC Layer에서 학습하는데 용이하게 될 것이다.</li>
</ul>
<p><img src="/image/POSITIONAL_ENCODING_01.png" alt="Positional Encoding"></p>
<ul>
<li>전체적인 구조는 Attention mechanism을 적용한 Seq2seq 모델과 유사하지만 <code>Scale이 되는 부분과 Mask를 사용하는 부분이 다르다.</code> 또한, <code>가장 중요한 점은 아래 수식 중 Query와 key, value 부분을 모아서 하나의 metrics로 만들어 줌으로써 우리가 처음 배웠던 shallow NN과 같이 병렬적으로 처리할 수 있게끔 해주었다는 것이 가장 큰 Transformer 모델의 요소</code>일 것이다. <code>scale 처리를 해줌으로써 내적의 값이 너무 커져서 saturation되서 Softmax값이 차이가 많이나는 것을 방지</code>할 수 있다.</li>
</ul>
<p><img src="/image/SCALED_DOT_PRODUCT_ATTENTION_01.png" alt="Scaled Dot-Product Attention"></p>
<ul>
<li><code>Q,K,V의 차원을 감소시킨다는 것이 중요</code>하다. 또한 아래 수식에서 가중치 $W_{V,i}, W_{K,i}, W_{Q,i}$의 각각의 Dimension보다 더 작은 값으로 모델의 Dimension($d_{model}$)을 해준다.</li>
</ul>
<p><img src="/image/MULTI_HEAD_ATTENTION_01.png" alt="Multi-Head Attention"></p>
<p><img src="/image/TRANSFORMER_MODEL_REVIEW.png" alt="Transformer Model Review"></p>

        </div>
        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "HeungBae Lee"
        },
        "headline": "Attention 기법",
        "image": "https://heung-bae-lee.github.io/image/Sequence_to_sequence.png",
        "keywords": "",
        "genre": "deep learning",
        "datePublished": "2020-01-21",
        "dateCreated": "2020-01-21",
        "dateModified": "2020-01-24",
        "url": "https://heung-bae-lee.github.io/2020/01/21/deep_learning_10/",
        "description": "Attention 기법Sequence-to-sequence
우선, Attention 기법이 가장 먼저 적용되었던 모델인 Sequence-to-sequence 모델을 살펴보면서 간략하게 conception적인 것을 살펴보겠다.

아래 그림의 왼쪽 부분은 Encoder 구조로 되어 있어, Input에 번역하고자 하는 문장을 단어 하나씩 받는 형태로 되어있다. "
        "wordCount": 1676
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/heungbae.lee" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HEUNG-BAE-LEE" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2020/01/22/deep_learning_11/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            Attention mechanism을 사용한 Seq2seq 구현
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2020/01/21/deep_learning_09/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">순환신경망(Vanilla RNN 및 LSTM 구현)</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/01/29/NLP_03/" class="title">텍스트 분류</a></p>
                            <p class="item-date"><time datetime="2020-01-29T14:40:09.000Z" itemprop="datePublished">2020-01-29</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/crawling/">crawling</a></p>
                            <p class="item-title"><a href="/2020/01/28/Crawling_03/" class="title">Scrapy 웹 크롤링 04 - 실습</a></p>
                            <p class="item-date"><time datetime="2020-01-28T05:55:17.000Z" itemprop="datePublished">2020-01-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/crawling/">crawling</a></p>
                            <p class="item-title"><a href="/2020/01/24/Crawling_02/" class="title">Scrapy 웹 크롤링 03 - Exports, Settings, pipeline</a></p>
                            <p class="item-date"><time datetime="2020-01-23T16:56:11.000Z" itemprop="datePublished">2020-01-24</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/deep-learning/">deep learning</a></p>
                            <p class="item-title"><a href="/2020/01/22/deep_learning_11/" class="title">Attention mechanism을 사용한 Seq2seq 구현</a></p>
                            <p class="item-date"><time datetime="2020-01-21T20:15:09.000Z" itemprop="datePublished">2020-01-22</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/deep-learning/">deep learning</a></p>
                            <p class="item-title"><a href="/2020/01/21/deep_learning_10/" class="title">Attention 기법</a></p>
                            <p class="item-date"><time datetime="2020-01-21T08:10:39.000Z" itemprop="datePublished">2020-01-21</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bayes/">Bayes</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n/">CS231n</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Front-end/">Front end</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/crawling/">crawling</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-engineering/">data engineering</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/growth-hacking/">growth hacking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">5</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">18</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crawling/">crawling</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CS231n/" style="font-size: 10px;">CS231n</a> <a href="/tags/crawling/" style="font-size: 20px;">crawling</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 HeungBae Lee</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://heung-bae-lee.github.io/2020/01/21/deep_learning_10/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</body>
</html>
