<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    

    
    <title>Scrapy 웹 크롤링 04 - 실습 | DataLatte&#39;s IT Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    
    <meta name="description" content="Scrapy PracticeDaum 크롤링하기 다음 디지털 뉴스 페이지에서 현재 URL, 기사 타이틀에 걸려있는 href URL, 기사 페이지로 이동한 후 기사 제목, 기사 내용을 크롤링하는 것을 목표로 크롤러를 만들것  items.py 먼저, 크롤링 대상을 items를 활용하기 위해 items.py에 Field를 생성한다. 위에서 언급했던 사항뿐만 아니라">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy 웹 크롤링 04 - 실습">
<meta property="og:url" content="https://heung-bae-lee.github.io/2020/01/28/Crawling_03/index.html">
<meta property="og:site_name" content="DataLatte&#39;s IT Blog">
<meta property="og:description" content="Scrapy PracticeDaum 크롤링하기 다음 디지털 뉴스 페이지에서 현재 URL, 기사 타이틀에 걸려있는 href URL, 기사 페이지로 이동한 후 기사 제목, 기사 내용을 크롤링하는 것을 목표로 크롤러를 만들것  items.py 먼저, 크롤링 대상을 items를 활용하기 위해 items.py에 Field를 생성한다. 위에서 언급했던 사항뿐만 아니라">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2020-01-28T15:50:27.205Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scrapy 웹 크롤링 04 - 실습">
<meta name="twitter:description" content="Scrapy PracticeDaum 크롤링하기 다음 디지털 뉴스 페이지에서 현재 URL, 기사 타이틀에 걸려있는 href URL, 기사 페이지로 이동한 후 기사 제목, 기사 내용을 크롤링하는 것을 목표로 크롤러를 만들것  items.py 먼저, 크롤링 대상을 items를 활용하기 위해 items.py에 Field를 생성한다. 위에서 언급했던 사항뿐만 아니라">
<meta property="fb:app_id" content="100003222637819">


    <link rel="canonical" href="https://heung-bae-lee.github.io/2020/01/28/crawling_03/">

    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-154199624-1', 'auto');
ga('send', 'pageview');

</script>

    
    


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4604833066889492" data-ad-slot="4588503508" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<link rel="alternate" href="/rss2.xml" title="DataLatte's IT Blog" type="application/rss+xml">
</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">DataLatte&#39;s IT Blog using Hexo</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Bayes/">Bayes</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/CS231n/">CS231n</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Front-end/">Front end</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/">Python</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/crawling/">crawling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/data-engineering/">data engineering</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/growth-hacking/">growth hacking</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/hexo/">hexo</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/linear-algebra/">linear algebra</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/machine-learning/">machine learning</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/crawling/">crawling</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="4588503508"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

			    <article id="post-Crawling_03" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Scrapy 웹 크롤링 04 - 실습
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2020/01/28/Crawling_03/" class="article-date">
            <time datetime="2020-01-28T05:55:17.000Z" itemprop="datePublished">2020-01-28</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h1 id="Scrapy-Practice"><a href="#Scrapy-Practice" class="headerlink" title="Scrapy Practice"></a>Scrapy Practice</h1><h3 id="Daum-크롤링하기"><a href="#Daum-크롤링하기" class="headerlink" title="Daum 크롤링하기"></a>Daum 크롤링하기</h3><ul>
<li><a href="https://news.daum.net/breakingnews/digital" target="_blank" rel="noopener">다음 디지털 뉴스</a> 페이지에서 <code>현재 URL</code>, <code>기사 타이틀에 걸려있는 href URL</code>, 기사 페이지로 이동한 후 <code>기사 제목</code>, <code>기사 내용</code>을 크롤링하는 것을 목표로 크롤러를 만들것</li>
</ul>
<h2 id="items-py"><a href="#items-py" class="headerlink" title="items.py"></a>items.py</h2><ul>
<li>먼저, 크롤링 대상을 items를 활용하기 위해 items.py에 Field를 생성한다. 위에서 언급했던 사항뿐만 아니라 SQLite에 저장할때, 수집된 시간을 로그로 남겨 놓기 위한 Field도 생성시켜 준다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line">class PracticeItem(scrapy.Item):</span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 기사 제목</span></span><br><span class="line">    headline = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 기사 본문</span></span><br><span class="line">    contents = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 요청 리스트 페이지</span></span><br><span class="line">    parent_link = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 기사 페이지</span></span><br><span class="line">    article_link = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 수집된 시간</span></span><br><span class="line">    crawled_time = scrapy.Field()</span><br></pre></td></tr></table></figure>
<h2 id="setting-py"><a href="#setting-py" class="headerlink" title="setting.py"></a>setting.py</h2><h3 id="Middlware"><a href="#Middlware" class="headerlink" title="Middlware"></a>Middlware</h3><ul>
<li><p>개인이 만든 기능을 추가해서 사용가능하게 하는것, 즉, <code>Pipeline은 Item이 Export되어 파일에 저장되기 직전에 작업을 수행한다면, Middleware는 요청하기 직전, 응답 후에, 어떤함수가 실행전에, 이런 중간에서 작업을 수행하는 것</code>이라고 비교해볼 수 있다.</p>
</li>
<li><p>다른 크롤링할때와 마찬가지로 동일한 User-agent를 가지고 한다면, 서버에 지속적인 부하를 주게되어서 벤을 당한다거나 할 수 있으므로 <code>Fake User-agent</code>를 활용하여 크롤링을 할 것이다. Middlware의 장점은 커스터마이징할 수 있으므로 다른 사람들이 이미 개발해 놓은 것들이 많다. 특히 Github에서 검색한다면 star가 많은 것을 사용하는 것이 좋다는 것은 누구나 알고 있는 사실!!</p>
</li>
<li><p><a href="https://pypi.org/project/scrapy-fake-useragent/" target="_blank" rel="noopener">필자가 사용한 Middleware</a>의 사이트를 보면 scrapy 1.0이상과 1.0미만 버전에 따라 사용방법이 다른 것을 확인할 수 있다. 필자의 경우 1.8이므로 1.0이상의 방법을 사용할 것이다.</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy-fake-useragent</span><br></pre></td></tr></table></figure>
<ul>
<li>아래 주석 처리된 USER_AGENT 변수는 실제 자신의 user-agent를 사용해야하며, 주석처리한 이유는 추후에는 서버에 과부하주어 벤당하는 것을 방지하기 위해 fake-agent를 사용할 것이기 때문이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">BOT_NAME = <span class="string">'practice'</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">'practice.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'practice.spiders'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># User-agent 설정(개발자도구에서 Network창에서 찾아서 자신의 정보를 복사</span></span><br><span class="line"><span class="comment">#USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = False</span><br><span class="line"></span><br><span class="line"><span class="comment"># 다운로드 간격</span></span><br><span class="line">DOWNLOAD_DELAY = 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 쿠키사용</span></span><br><span class="line">COOKIES_ENABLED = True</span><br><span class="line"></span><br><span class="line"><span class="comment"># Referer 삽입</span></span><br><span class="line"><span class="comment"># daum은 보안이 엄격하기에 referer속성을 주어야 한다.</span></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;<span class="string">'Referer'</span> : <span class="string">'https://news.daum.net/breakingnews/digital?page=2'</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 재시도 횟수</span></span><br><span class="line">RETRY_ENABLED = True</span><br><span class="line">RETRY_TIME = 2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 한글 쓰기(출력 인코딩)</span></span><br><span class="line">FEED_EXPORT_ENCODING = <span class="string">'utf-8'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># User-agent 미들웨어 사용</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span>: None,</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span>: None,</span><br><span class="line">    <span class="string">'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware'</span>: 400,</span><br><span class="line">    <span class="string">'scrapy_fake_useragent.middleware.RetryUserAgentMiddleware'</span>: 401,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 파이프 라인 활성화</span></span><br><span class="line"><span class="comment"># 숫자가 작을수록 우선순위 상위</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'practice.pipelines.PracticePipeline'</span>: 300,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 캐시 사용</span></span><br><span class="line"><span class="comment">#HTTPCACHE_ENABLED = True</span></span><br><span class="line"><span class="comment">#HTTPCACHE_EXPIRATION_SECS = 0</span></span><br><span class="line"><span class="comment">#HTTPCACHE_DIR = 'httpcache'</span></span><br><span class="line"><span class="comment">#HTTPCACHE_IGNORE_HTTP_CODES = []</span></span><br><span class="line"><span class="comment">#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'</span></span><br></pre></td></tr></table></figure>
<h2 id="pipelines-py"><a href="#pipelines-py" class="headerlink" title="pipelines.py"></a>pipelines.py</h2><ul>
<li>크롤링으로 수집된 시간의 로그를 남기기 위해 datetime 라이브러리를, DB에 저장하기 위해 sqlite3, 마지막으로 예외적인 처리를 위해 DropItem 라이브러리를 사용할 것이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">import datetime</span><br><span class="line">import sqlite3</span><br><span class="line">from scrapy.exceptions import DropItem</span><br><span class="line"></span><br><span class="line">class PracticePipeline(object):</span><br><span class="line">    <span class="comment"># 초기화 메소드</span></span><br><span class="line">    def __init__(self):</span><br><span class="line">        <span class="comment"># DB 설정(자동 커밋)</span></span><br><span class="line">        <span class="comment"># isolation_level=None =&gt; Auto Commit</span></span><br><span class="line">        self.conn = sqlite3.connect(<span class="string">'저장할 위치에 대한 path/저장할 파일명.db'</span>, isolation_level=None)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># DB 연결</span></span><br><span class="line">        self.c = self.conn.cursor()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 최초 1회 실행</span></span><br><span class="line">    def open_spider(self, spider):</span><br><span class="line">        spider.logger.info(<span class="string">'NewsSpider Pipeline Started.'</span>)</span><br><span class="line">        self.c.execute(<span class="string">"CREATE TABLE IF NOT EXISTS NEWS_DATA(id INTEGER PRIMARY KEY AUTOINCREMENT, headline text, contents text, parent_link text, article_link text, crawled_time text)"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Item 건수 별 실행</span></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        <span class="keyword">if</span> not item.get(<span class="string">'contents'</span>) is None:</span><br><span class="line">            <span class="comment"># 삽입 시간</span></span><br><span class="line">            crawled_time = datetime.datetime.now().strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 크롤링 시간 필드 추가</span></span><br><span class="line">            item[<span class="string">'crawled_time'</span>] = crawled_time</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 데이터 -&gt; DB 삽입</span></span><br><span class="line">            <span class="comment"># tuple(item[k] for k in item.keys()) 로 대신해도 된다.</span></span><br><span class="line">            self.c.execute(<span class="string">'INSERT INTO NEWS_DATA(headline, contents, parent_link, article_link, crawled_time) VALUES(?, ?, ?, ?, ?);'</span>, (item.get(<span class="string">'headline'</span>), item.get(<span class="string">'contents'</span>), item.get(<span class="string">'parent_link'</span>), item.get(<span class="string">'article_link'</span>), item.get(<span class="string">'crawled_time'</span>))) <span class="comment"># tuple(item[k] for k in item.keys())</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 로그</span></span><br><span class="line">            spider.logger.info(<span class="string">'Item to DB inserted.'</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 결과 리턴</span></span><br><span class="line">            <span class="built_in">return</span> item</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            raise DropItem(<span class="string">'Dropped Item. Because This Contents is Empty.'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 마지막 1회 실행</span></span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        spider.logger.info(<span class="string">'NewsSpider Pipeline Stopped.'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># commit(auto commit으로 설정했지만 혹시 모르니)</span></span><br><span class="line">        self.conn.commit()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 연결 해제</span></span><br><span class="line">        self.conn.close()</span><br></pre></td></tr></table></figure>
<h2 id="Spider-py"><a href="#Spider-py" class="headerlink" title="Spider.py"></a>Spider.py</h2><ul>
<li>먼저 도메인과 시작하는 URL을 정하고나서 페이지의 규칙을 찾아본다. 규칙을 정해주면 LinkExtractor로 반복되는 URL을 보내줄 수 있다. 단, 1자리수 이외의 2자리수부터의 반복은 Rule함수에 follow=True로 주어야한다. 또한 <code>변수명 rules로 Rule객체를 받아야 사용가능함을 기억</code>하자. parent page에서 해당 기사들에 대한 url을 parse_child 함수로 넘겨주는데, 이때 그냥 넘겨주지 않고 <code>parent page에서 얻은 정보 또한 meta parameter를 통해 같이 넘겨 줄수 있다</code>.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">from scrapy.linkextractors import LinkExtractor</span><br><span class="line">from scrapy.spiders import CrawlSpider, Rule</span><br><span class="line">import sys</span><br><span class="line">sys.path.insert(0, <span class="string">'items.py가 있는 절대 path'</span>)</span><br><span class="line">from items import PracticeItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class NewcralSpider(CrawlSpider):</span><br><span class="line">    name = <span class="string">'newcral'</span></span><br><span class="line">    allowed_domains = [<span class="string">'news.daum.net'</span>]</span><br><span class="line">    start_urls = [<span class="string">'https://news.daum.net/breakingnews/digital'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 링크 크롤링 규칙(정규표현식 사용 추천)</span></span><br><span class="line">    <span class="comment"># page=\d$ : 1자리 수</span></span><br><span class="line">    <span class="comment"># page=\d+ : 연속, follow=True</span></span><br><span class="line">    rules = [</span><br><span class="line">        Rule(LinkExtractor(allow=r<span class="string">'/breakingnews/digital\?page=\d+'</span>), callback=<span class="string">'parse_parent'</span>, follow=True),</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse_parent(self, response):</span><br><span class="line">        <span class="comment"># 부모 URL 로깅</span></span><br><span class="line">        self.logger.info(<span class="string">'Parent Response URL : %s'</span> % response.url)</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> response.css(<span class="string">'ul.list_news2.list_allnews &gt; li &gt; div'</span>):</span><br><span class="line">            <span class="comment"># URL 신문 기사 URL</span></span><br><span class="line">            article_link = url.css(<span class="string">'strong &gt; a::attr(href)'</span>).extract_first().strip()</span><br><span class="line">            yield scrapy.Request(article_link, self.parse_child, meta=&#123;<span class="string">'parent_url'</span>: response.url&#125;)</span><br><span class="line"></span><br><span class="line">                def parse_child(self, response):</span><br><span class="line">                    <span class="comment"># 부모, 자식 수신 정보 로깅</span></span><br><span class="line">                    self.logger.info(<span class="string">'----------------------------------------'</span>)</span><br><span class="line">                    self.logger.info(<span class="string">'Response From Parent URL : %s'</span> % response.meta[<span class="string">'parent_url'</span>])</span><br><span class="line">                    self.logger.info(<span class="string">'Child Response URL : %s'</span> % response.url)</span><br><span class="line">                    self.logger.info(<span class="string">'Child Response Status ; %s'</span> % reponse.status)</span><br><span class="line">                    self.logger.info(<span class="string">'----------------------------------------'</span>)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 요청 리스트 페이지</span></span><br><span class="line">                    parent_link = response.meta[<span class="string">'parent_url'</span>]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 기사 페이지</span></span><br><span class="line">                    article_link = response.url</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 헤드라인</span></span><br><span class="line">                    headline = response.css(<span class="string">'h3.tit_view::text'</span>).extract_first().strip()</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 본문</span></span><br><span class="line">                    c_list = response.css(<span class="string">'div.article_view &gt; section &gt; p::text'</span>).extract()</span><br><span class="line">                    contents = <span class="string">''</span>.join(c_list).strip()</span><br><span class="line"></span><br><span class="line">                    yield PracticeItem(headline=headline, contents=contents, article_link=article_link, parent_link=parent_link)</span><br></pre></td></tr></table></figure>
<h3 id="도움이-되는-학습"><a href="#도움이-되는-학습" class="headerlink" title="도움이 되는 학습"></a>도움이 되는 학습</h3><ul>
<li><p>비동기(asyncio), 병렬프로그래밍, 스레드, 멀티 프로세싱등 routine 개념을 학습해야 네트워크상의 블록 또는 논블럭 io로 인해 지연시간이 발생되는데, 제어권을 넘겨주면서 좀 더 성능을 올릴 수 있다.</p>
</li>
<li><p><code>scrapy twisted</code>는 예를 들어, 위의 실습에서와 같이 데이터를 크롤링한 후 pipeline을 통해 DB에 insert 할 때 이 작업이 다 끝나지 않으면, 다음 데이터에 대한 작업으로 넘어 갈 수 없어 시간적으로 성능이 떨어질수 있는데, 이런 경우 비동기식으로 처리를 해줌으로써 성능을 올릴수 있게끔 하는 framework이다.</p>
</li>
</ul>

        </div>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 하단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="9861011486"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "HeungBae Lee"
        },
        "headline": "Scrapy 웹 크롤링 04 - 실습",
        "image": "https://heung-bae-lee.github.io",
        "keywords": "",
        "genre": "crawling",
        "datePublished": "2020-01-28",
        "dateCreated": "2020-01-28",
        "dateModified": "2020-01-29",
        "url": "https://heung-bae-lee.github.io/2020/01/28/Crawling_03/",
        "description": "Scrapy PracticeDaum 크롤링하기
다음 디지털 뉴스 페이지에서 현재 URL, 기사 타이틀에 걸려있는 href URL, 기사 페이지로 이동한 후 기사 제목, 기사 내용을 크롤링하는 것을 목표로 크롤러를 만들것

items.py
먼저, 크롤링 대상을 items를 활용하기 위해 items.py에 Field를 생성한다. 위에서 언급했던 사항뿐만 아니라"
        "wordCount": 1983
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/heungbae.lee" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HEUNG-BAE-LEE" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2020/01/29/NLP_03/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            NLP 실습 텍스트 분류 -01
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2020/01/24/Crawling_02/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">Scrapy 웹 크롤링 03 - Exports, Settings, pipeline</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python/">Python</a></p>
                            <p class="item-title"><a href="/2020/03/20/Python_00/" class="title">Python - 00 (Python의 장점 및 자료형)</a></p>
                            <p class="item-date"><time datetime="2020-03-20T12:02:48.000Z" itemprop="datePublished">2020-03-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></p>
                            <p class="item-title"><a href="/2020/03/19/data_structure_01/" class="title">내가 정리하는 자료구조 00 (Node, List, Queue)</a></p>
                            <p class="item-date"><time datetime="2020-03-19T09:46:30.000Z" itemprop="datePublished">2020-03-19</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/data-engineering/">data engineering</a></p>
                            <p class="item-title"><a href="/2020/03/03/data_engineering_10/" class="title">data engineering (데이터 모델링 및 챗봇 만들기)</a></p>
                            <p class="item-date"><time datetime="2020-03-03T14:29:20.000Z" itemprop="datePublished">2020-03-03</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/data-engineering/">data engineering</a></p>
                            <p class="item-title"><a href="/2020/03/01/data_engineering_09/" class="title">data engineering (데이터 파이프라인 자동화)</a></p>
                            <p class="item-date"><time datetime="2020-03-01T04:49:06.000Z" itemprop="datePublished">2020-03-01</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/data-engineering/">data engineering</a></p>
                            <p class="item-title"><a href="/2020/02/24/data_engineering_08/" class="title">data engineering (Presto란?)</a></p>
                            <p class="item-date"><time datetime="2020-02-24T13:11:09.000Z" itemprop="datePublished">2020-02-24</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bayes/">Bayes</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n/">CS231n</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Front-end/">Front end</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/crawling/">crawling</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-engineering/">data engineering</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/growth-hacking/">growth hacking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">5</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crawling/">crawling</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CS231n/" style="font-size: 10px;">CS231n</a> <a href="/tags/crawling/" style="font-size: 20px;">crawling</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 사이드바 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="3275421833"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 HeungBae Lee</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://heung-bae-lee.github.io/2020/01/28/Crawling_03/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</body>
</html>
