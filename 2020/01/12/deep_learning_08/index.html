<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    

    
    <title>순환 신경망(RNN) - 순차 데이터의 이해 | DataLatte&#39;s IT Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    
    <meta name="description" content="순차 데이터의 이해 우리가 순환 신경망을 사용하는 이유는 입력을 순환 신경망으로 받거나 출력을 순환 신경망으로 내기 위해서이다.    일정한 시간차을 갖는 Time Series라면, x축이 특정 시간을 의미하는 Temporal Sequence와는 다르게 하나하나의 Step으로 간주한다.    일반적으로는 위에서 보는 것과 같이 Temporal Sequenc">
<meta property="og:type" content="article">
<meta property="og:title" content="순환 신경망(RNN) - 순차 데이터의 이해">
<meta property="og:url" content="https://heung-bae-lee.github.io/2020/01/12/deep_learning_08/index.html">
<meta property="og:site_name" content="DataLatte&#39;s IT Blog">
<meta property="og:description" content="순차 데이터의 이해 우리가 순환 신경망을 사용하는 이유는 입력을 순환 신경망으로 받거나 출력을 순환 신경망으로 내기 위해서이다.    일정한 시간차을 갖는 Time Series라면, x축이 특정 시간을 의미하는 Temporal Sequence와는 다르게 하나하나의 Step으로 간주한다.    일반적으로는 위에서 보는 것과 같이 Temporal Sequenc">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://heung-bae-lee.github.io/image/Sequential_Data.png">
<meta property="og:updated_time" content="2020-01-21T08:10:54.577Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="순환 신경망(RNN) - 순차 데이터의 이해">
<meta name="twitter:description" content="순차 데이터의 이해 우리가 순환 신경망을 사용하는 이유는 입력을 순환 신경망으로 받거나 출력을 순환 신경망으로 내기 위해서이다.    일정한 시간차을 갖는 Time Series라면, x축이 특정 시간을 의미하는 Temporal Sequence와는 다르게 하나하나의 Step으로 간주한다.    일반적으로는 위에서 보는 것과 같이 Temporal Sequenc">
<meta name="twitter:image" content="https://heung-bae-lee.github.io/image/Sequential_Data.png">
<meta property="fb:app_id" content="100003222637819">


    <link rel="canonical" href="https://heung-bae-lee.github.io/2020/01/12/deep_learning_08/">

    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-154199624-1', 'auto');
ga('send', 'pageview');

</script>

    
    


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4604833066889492" data-ad-slot="4588503508" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<link rel="alternate" href="/rss2.xml" title="DataLatte's IT Blog" type="application/rss+xml">
</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">DataLatte&#39;s IT Blog using Hexo</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Bayes/">Bayes</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/CS231n/">CS231n</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Front-end/">Front end</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/crawling/">crawling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/data-engineering/">data engineering</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/growth-hacking/">growth hacking</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/hexo/">hexo</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/linear-algebra/">linear algebra</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/machine-learning/">machine learning</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/deep-learning/">deep learning</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="4588503508"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

			    <article id="post-deep_learning_08" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        순환 신경망(RNN) - 순차 데이터의 이해
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2020/01/12/deep_learning_08/" class="article-date">
            <time datetime="2020-01-12T06:25:39.000Z" itemprop="datePublished">2020-01-12</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h1 id="순차-데이터의-이해"><a href="#순차-데이터의-이해" class="headerlink" title="순차 데이터의 이해"></a>순차 데이터의 이해</h1><ul>
<li>우리가 <code>순환 신경망을 사용하는 이유</code>는 <code>입력을 순환 신경망으로 받거나 출력을 순환 신경망으로 내기 위해서</code>이다.</li>
</ul>
<p><img src="/image/Sequential_Data.png" alt="순차 데이터(Sequential Data)"></p>
<ul>
<li>일정한 시간차을 갖는 Time Series라면, x축이 특정 시간을 의미하는 Temporal Sequence와는 다르게 하나하나의 Step으로 간주한다.</li>
</ul>
<p><img src="/image/Resampling.png" alt="Resampling"></p>
<ul>
<li>일반적으로는 위에서 보는 것과 같이 Temporal Sequence를 보간하여 Time Series로 변환해 준 뒤에 사용한다.</li>
</ul>
<p><img src="/image/DNN_and_Sequential_Data.png" alt="심층 신경망과 순차 데이터"></p>
<p><img src="/image/many_one.png" alt="다중 입력, 단일 출력"></p>
<ul>
<li>개인 비서 서비스는 예를 들어, siri나 구글의 okay google 같은 서비스이다.</li>
</ul>
<p><img src="/image/many_to_many.png" alt="다중 입력, 다중 출력"></p>
<p><img src="/image/one_to_may.png" alt="단일 입력, 다중 출력"></p>
<h1 id="기본-적인-순환-신경망-Vanilla-RNN"><a href="#기본-적인-순환-신경망-Vanilla-RNN" class="headerlink" title="기본 적인 순환 신경망(Vanilla RNN)"></a>기본 적인 순환 신경망(Vanilla RNN)</h1><p><img src="/image/processing_with_Sequence_Data.png" alt="순차 데이터의 처리"></p>
<ul>
<li>앞서 말한 순차데이터를 입력받아 원하는 출력을 하려면, <code>기억시스템</code>이 전제되어야 한다. <code>CNN이나 Deep Neural Network, shallow NN은 Memoryless System이다.</code></li>
</ul>
<p><img src="/image/Memory_System.png" alt="기억 시스템(Memory System)"></p>
<p><img src="/image/shallow_Neural_Network_related_in_RNN.png" alt="얕은 신경망(Shallow Neural Network)"></p>
<ul>
<li>다음 그림에서 볼 수 있듯이, RNN은 이전의 Network 구조와는 다르게 <code>입력층에 n-1번째 step의 hidden layer를 n번째 데이터와 concatenation을 하여 사용</code>하는 것이다. 이렇게 함으로써 <code>이전의 모든 입력에 영향을 받는다.</code></li>
</ul>
<p><img src="/image/vanilla_RNN.png" alt="기본적인 순환 신경망(Vanilla Recurrent Network)"></p>
<ul>
<li>shallow Neural Network를 Deep Neural Network로 만들어 주었듯이, 동일하게 하여 Multi-Layer RNN을 만들 수 있다. 왼쪽의 노드들만 본다면 <code>다음 Layer들의 이전 step의 hidden Layer를 가져온 것을 확인</code> 할 수 있다. <code>하지만, 이런 구조는 Vanilla RNN과 다르게 Hidden Layer의 길이도 2배이상으로 늘어나기 때문에, 복잡도가 높아지게 되며, 현실적으로 학습이 잘 되지 않아 권장되지 않는다.</code> 그 이유는 간단하게만 말하자면, 일반적인 Neural Network는 depth 방향으로만 gradient가 잘 학습되면 되지만, 이 구조는 input까지 Gradient의 영향을 주도록 해야하기 때문이다.</li>
</ul>
<p><img src="/image/Multi_Layer_RNN.png" alt="다중 계층 순환 신경망(Multi-Layer RNN)"></p>
<h1 id="심화-순환-신경망"><a href="#심화-순환-신경망" class="headerlink" title="심화 순환 신경망"></a>심화 순환 신경망</h1><ul>
<li>그렇다면 <code>&#39;Vanilla RNN이 왜 잘 쓰이지 않는가?&#39;</code>에 대한 가장 큰 이유를 앞서 언급했던 것과 같이 Gradient가 Input까지 타고 가서 학습을 잘 못하기 때문이라고 언급했다. 즉, <code>Gradient Vanishing 문제</code>라는 것이다.</li>
</ul>
<p><img src="/image/Gradient_Vanishing_problem_with_vanilla_RNN.png" alt="기울기 소실 문제"></p>
<p><img src="/image/LSTM.png" alt="LSTM(Long Short-Term Memory)"></p>
<p><img src="/image/Cell_State_and_Hidden_State.png" alt="Cell State, Hidden State"></p>
<p><img src="/image/Forget_Gate.png" alt="Forget Gate"></p>
<ul>
<li>검정색 선이 Input Gate이다. 빨간색 선은 Vanilla RNN에서의 Hidden State와 동일하다. 입력이 들어오고 이전 Hidden State를 받아서 같이 tanh activation function을 FC(Fully connected) Layer를 통과시켜 출력을 내주면 RNN의 Hidden Layer이기 때문이다.</li>
</ul>
<p><img src="/image/Input_Gate.png" alt="Input Gate"></p>
<ul>
<li>해당 Layer에서 필요한 정보만을 출력층으로 내주고, 필요하지 않은 정보는 계속 기억하게끔 다음 time step으로 넘겨주어서 이전에 어떤 출력을 내주었었나를 Cell State와는 별개로 또 넘겨주어 기억하게끔 한다. 아래 그림에서 출력을 내보내기 위해 Cell State에서 tanh를 거쳐 주는데 이 작업은 <code>다른 activation function들이 존재하는 노드들과 달리 FC layer로 이루어져 있지 않고 그냥 activation function만 거치게 된다.</code> 그 이유는 <code>Cell State가 Forget gate를 지나면서는 0~1사이의 값이 곱해지므로 크게 문제가 없지만 Input Gate를 지나면서 Feature가 추가적으로 더해질때 tanh를 지나면 -1~1사이의 값이 되므로 범위 -2~2로 늘어나게 되어 추후에 Gradient Explode가 일어날 수 있어 예방차원에서 tanh을 사용</code>하는 것이기 때문이다.</li>
</ul>
<p><img src="/image/Output_Gate.png" alt="Output Gate"></p>
<p><img src="/image/GRU.png" alt="GRU(Gated Recurrent Unit)"></p>
<p><img src="/image/GRU_structure.png" alt="GRU의 구조"></p>
<ul>
<li>아래 그림에서 $1 - Forget Gate$를 Input Gate로 사용하는 것은 Forget Gate에서 잊어버린 만큼만 Input Gate를 통해 채워 주는 의미로 해석할 수 있다.</li>
</ul>
<p><img src="/image/Forget_gate_and_Input_gate.png" alt="Forget Gate &amp; Input Gate"></p>
<ul>
<li>Input Gate를 통해 새로운 Feature가 추가되기에 앞서서 이전 Hidden State 정보를 얼마나 잊게 하느냐의 의미인데, 예를 들어 앞의 문장이 .을 통해 마쳐졌다면, 그 뒤의 문장은 다른 문장 구조를 띄게 되므로 0에 가깝게 하여 Reset을 시켜줄 것이다.</li>
</ul>
<p><img src="/image/Reset_gate.png" alt="Reset Gate"></p>
<h1 id="시간펼침-역전파-학습법-BPTT-Back-Propagation-Through-Time"><a href="#시간펼침-역전파-학습법-BPTT-Back-Propagation-Through-Time" class="headerlink" title="시간펼침 역전파 학습법(BPTT: Back Propagation Through Time)"></a>시간펼침 역전파 학습법(BPTT: Back Propagation Through Time)</h1><ul>
<li><code>순환신경망은 기존의 기본적인 역전파 학습법으로는 학습할 수 없다. 그렇다면, 어떻게 해야할까?</code></li>
</ul>
<p><img src="/image/Sequence_data_instructure.png" alt="순차 데이터 셋의 구조"></p>
<p><img src="/image/many_to_one_inference.png" alt="다중 입력, 단일 출력의 학습"></p>
<ul>
<li>물론, <code>모델이 학습할때 언제 입력이 끝날지 모르기에 마지막 입력 같은 경우는 EOS(End Of Sequence)라는 특별한 미리정해준 하나의 토큰을 날려주는 경우가 많다.</code></li>
</ul>
<p><img src="/image/RNN_inference.png" alt="순환 신경망의 순방향 추론"></p>
<ul>
<li>아래의 그림은 Input의 시점에 따라 펼쳐져있다는 것을 이해하기 쉽게 펼쳐 놓은 것인데, 여기서 주의할 점은 <code>아래의 RNN안의 Hyper parameter들은 모두 동일하다는 것이다. 즉 아래의 그림은 재귀적형태를 시간의 흐름상으로 나열해 놓은 것이라고 생각하면 된다.</code></li>
</ul>
<p><img src="/image/Back_Propagation_Through_Time.png" alt="시간 펼침 역전파(Back Propagation Trough Time)"></p>
<ul>
<li>위에서 언급했던 것과 같이 출력(또는 입력)의 길이가 정해져있지 않은 RNN의 경우, 아래는 마지막 출력에 EOS 출력을 내게끔 학습시켜야 모든 출력이 나왔다는 것을 알 수가 있다. 또한, Back propagation도 마찬가지로 각각의 출력에 대한 Loss값 부터 시작해서 Input지점까지 해주면 된다. 단일 입력, 다중 출력의 실제 모델에서는 입력이 없는 다른 층에서는 0을 입력하거나 미리 정해놓은 입력을 넣어주어 학습을 시키는 것이 일반적이다.</li>
</ul>
<p><img src="/image/one_to_many_inference.png" alt="단일 입력, 다중 출력"></p>
<ul>
<li><code>다중 입력에 대해서 다중 출력</code>이 나오려면 2가지 상황이 있을 수 있다. 하나는 아래 그림에서와 같이 <code>입력에 대해서 출력이 나오고 입력이 끝나면 출력도 끝나는 것이 있을 수 있다.</code><br>이런 경우는 대표적으로, <code>동영상의 프레임 분류</code>가 있다. 예를 들면, CF의 한 프레임이 입력으로 들어와 각 장면이 어떤 장면인지 서술하는 식으로의 분류를 들 수 있을 것이다.</li>
</ul>
<p><img src="/image/many_to_many_inference.png" alt="다중 입력, 다중 출력 - 01"></p>
<ul>
<li>또 다른 한 상황은 <code>모든 입력을 받고 그 다음에 출력이 나오는 경우</code>가 있다. 이 경우도 마찬가지로 입력의 길이가 언제 끝날지 모르므로 마지막 입력에 EOS를 날려 주어야 한다.</li>
</ul>
<p><img src="/image/many_to_many_inference_01.png" alt="다중 입력, 다중 출력 - 02"></p>
<h1 id="심화-순환-신경망의-수식적-이해"><a href="#심화-순환-신경망의-수식적-이해" class="headerlink" title="심화 순환 신경망의 수식적 이해"></a>심화 순환 신경망의 수식적 이해</h1><ul>
<li>Vanilla RNN의 수식은 이전에 간단히 다루었다. 이제 LSTM과 GRU도 수식으로 접근해 보자.</li>
</ul>
<p><img src="/image/LSTM_equation.png" alt="LSTM 수식"></p>
<ul>
<li><code>특징이 여러차원으로 되어있는데, 이 Forget gate 또한 여러 차원으로 되어있어 특징별로 기억할지 말지를 결정</code>할 수 있다.</li>
</ul>
<p><img src="/image/Forget_gate_equation.png" alt="Forget gate"></p>
<p><img src="/image/Input_gate_equation.png" alt="Input gate"></p>
<p><img src="/image/LSTM_Cell_State_equation.png" alt="Cell state"></p>
<p><img src="/image/LSTM_Output_gate_equation.png" alt="Output gate"></p>
<p><img src="/image/LSTM_Hidden_state_equation.png" alt="Hidden state"></p>
<p><img src="/image/GRU_equation.png" alt="GRU"></p>
<ul>
<li><code>Reset gate</code>는 Hidden state에서 바로 잊는 Forget gate와는 다르게 <code>현재 Feature를 뽑을 때 얼만큼 잊어줄 것인가를 결정하는 부분</code>이다. <code>큰 맥락에서는 기억하고 있어야 하지만, 현재 Feature를 뽑을 때는 방해가 될 수 있는 정보를 잊게하는 역할</code>이다.</li>
</ul>
<p><img src="/image/GRU_Reset_gate_equation.png" alt="Reset gate"></p>
<ul>
<li>예를 들어 아래와 같은 상황일때, 마지막 박 아무개의 답을 추론하고자 한다면, 먼저 “나는 사과가 좋다.”, “너는 과일을 싫어한다.”라는 문장 2개는 분리가 된 문장이지만 “나는 사과가 좋다” 내에서는 ‘나’하고 ‘사과’는 잘 기억이 되어야 하지만 “너는 과일을 싫어한다”라는 문장은 다른 문장이므로 기억이 안되어야 할 것이다. 하지만, “나는 어떤 과일이 먹고 싶을까?”에 답을 하려면, 최근에 문장인 “너는 과일을 싫어한다”에서는 추론할 때 필요한 정보가 없기 때문에 그 이전 문장인 “나는 사과가 좋다.”는 context를 계속해서 가지고 있어야한다. 이 정보가 Hidden state를 타고 움직여야 하는 정보이고, 여기서 “나는 사과가 좋다.”와 “너는 과일을 싫어한다.”라는 문장을 구분하여 단계적으로 활용하지 않기 위한 작업이 Reset gate를 통한 작업이다.</li>
</ul>
<p><img src="/image/GRU_Forget_gate_equation_example.png" alt="Reset gate 예시"></p>
<ul>
<li>Reset gate와 다르게 Hidden state에 직접적으로 곱해져서 이전 time step Hidden State에서 기억을 잊어버리게 하는 역할을 한다. 잊어버린 부분만큼을 다시 새로운 정보로 보충하기 위해 1에서 뺀 만큼을 새로운 입력의 결과에 곱해준다.  </li>
</ul>
<p><img src="/image/GRU_Forget_gate_equation.png" alt="Forget gate"></p>
<ul>
<li>이전 time step의 Hidden state가 들어왔을 때 reset gate를 통해 제어가 된 것을 가지고 현재 Feature들을 뽑아주게 되고, Forget gate에서 의해서 제어가 된 만큼 넘어오고 Forget gate에 의해서 상보적인 만큼 다시 새로 뽑은 Feature를 입력을 받아서 다음 출력으로 나가게 된다. 그렇기에 값이 -1~1로 bound되어있어 LSTM과 다르게 tanh함수가 필요하지 않다.</li>
</ul>
<p><img src="/image/GRU_Hidden_state_equation.png" alt="Hidden state"></p>
<h1 id="순차-신경망에서-Tensor의-이해"><a href="#순차-신경망에서-Tensor의-이해" class="headerlink" title="순차 신경망에서 Tensor의 이해"></a>순차 신경망에서 Tensor의 이해</h1><p><img src="/image/Sequence_data_for_Tensor.png" alt="순차 데이터셋"></p>
<p><img src="/image/FC_Layer_Tensor.png" alt="전결합 계층의 입출력 텐서"></p>
<ul>
<li>데이터가 Feature같은 경우에는 항상 꽉차게 되는데, <code>순차데이터 같은 경우에는 길이가 L보다 짧을 수 있다. 그런 경우에는 앞을 0으로 채워준다.(pre-padding)</code></li>
</ul>
<p><img src="/image/RNN_Input_Tensor.png" alt="RNN의 입력 텐서 - 01"></p>
<p><img src="/image/RNN_Input_Tensor_why.png" alt="RNN의 입력 텐서 - 02"></p>
<p><img src="/image/RNN_Output_Tensor.png" alt="RNN의 출력 텐서 - 01"></p>
<ul>
<li>출력이 나오는 시점은 고정되므로 일관되게 앞쪽으로 정렬된 출력이 나올 수 있게 하기 위해서 뒷부분을 0으로 채운다.</li>
</ul>
<p><img src="/image/RNN_Output_Tensor_why.png" alt="RNN의 출력 텐서 - 02"></p>
<h1 id="순환-신경망의-학습법"><a href="#순환-신경망의-학습법" class="headerlink" title="순환 신경망의 학습법"></a>순환 신경망의 학습법</h1><p><img src="/image/BPTT_with_backpropagation.png" alt="BPTT"></p>
<p><img src="/image/BPTT_data_input.png" alt="BPTT 데이터 입력"></p>
<ul>
<li>시간에 대해서 펼쳐있고, 추가적으로 Batch로도 펼쳐 주어야 하는데, 즉, 아래와 같은 구조가 Batch size만큼 더 있어주어야 한다는 의미이다. 그래서 <code>시간적으로 펼칠 때 역전파를 위한 추가적인 메모리가 필요</code>하다. 일반적인 CNN이나 DNN은 시간적으로 펼치는 것이 없기 때문에 Batch에 대해서 크게 엄격하지 않다. 하지만 <code>RNN은 아래와 같이 시간적으로 펼치기 때문에 Batch size를 늘리는데 엄격하다.</code></li>
</ul>
<p><img src="/image/BPTT_batch_training.png" alt="BPTT의 배치 학습법"></p>
<ul>
<li>순차 데이터의 길이 L이 매우 클 경우, 시간 펼침이 늘어나면서 필요 메모리가 L배 증가한다. 그 이유는 길이가 1개 씩 늘어날 때마다 펼침을 하나씩 더 해야하기 때문이다. <code>이 때 B(Batch)를 한번에 계산하므로, 얕은 신경망에 비해 훨씬 큰 메모리가 필요.</code></li>
</ul>
<p><img src="/image/problem_with_BPTT.png" alt="BPTT의 문제점"></p>
<p><img src="/image/many_to_many_solving_problem_with_Truncated_BPTT.png" alt="다중 입력, 다중 출력"></p>
<p><img src="/image/Truncated_BPTT_data_input.png" alt="Truncated BPTT 데이터 입력"></p>
<ul>
<li><p><code>길이 L의 입력을 길이 T로 쪼개어 순서대로 학습</code>한다.<br><img src="/image/Truncated_BPTT.png" alt="Truncated BPTT"></p>
</li>
<li><p>즉, <code>Time step이 T 이상 떨어진 입-출력 관계는 학습되지 않는다.</code> Hidden state와 Cell state를 통해 Forward propagation에서는 잘 추론 할 수 있도록 넘겨 주지만, Back propagation에서는 그 관계를 서로 넘겨주지 못한다. 만약 전부다 연결시킨 관계를 학습시켜야 한다면 Truncated BPTT가 아닌 길이가 L인 모든 데이터를 학습시켜야 한다. 그러므로 <code>Truncated BPTT를 사용할 시 반드시 영향을 주는 데이터 사이의 관계를 침해하지 않게 T로 적절하게 나누어졌는지, 우리가 학습하고자 하는 것이 어느 정도의 시간차이까지 우리가 연관성을 봐야 하는지를 염두해 두고 학습을 시켜야 한다.</code></p>
</li>
<li><p><code>만약 연관성이 있는 데이터의 주기(데이터간의 시점 차이)가 크고 Gradient가 끊기지 않고 연결되어 업데이트가 이루어져야 한다면, 최대한 Batch Size를 극단적 낮추고, 최대한 Memory가 큰 GPU를 사용해서 최대한 긴 길이를 학습해 주는 방법을 사용해야 할 것이다.</code><br><img src="/image/Back_Propagation_of_Truncated_BPTT.png" alt="Truncated BPTT의 역전파 흐름"></p>
</li>
</ul>

        </div>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 하단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="9861011486"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "HeungBae Lee"
        },
        "headline": "순환 신경망(RNN) - 순차 데이터의 이해",
        "image": "https://heung-bae-lee.github.io/image/Sequential_Data.png",
        "keywords": "",
        "genre": "deep learning",
        "datePublished": "2020-01-12",
        "dateCreated": "2020-01-12",
        "dateModified": "2020-01-21",
        "url": "https://heung-bae-lee.github.io/2020/01/12/deep_learning_08/",
        "description": "순차 데이터의 이해
우리가 순환 신경망을 사용하는 이유는 입력을 순환 신경망으로 받거나 출력을 순환 신경망으로 내기 위해서이다.



일정한 시간차을 갖는 Time Series라면, x축이 특정 시간을 의미하는 Temporal Sequence와는 다르게 하나하나의 Step으로 간주한다.



일반적으로는 위에서 보는 것과 같이 Temporal Sequenc"
        "wordCount": 1343
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/heungbae.lee" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HEUNG-BAE-LEE" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2020/01/15/NLP_07/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            NLP란?
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2020/01/12/deep_learning_07/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">DenseNet 구현 및 학습</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/data-engineering/">data engineering</a></p>
                            <p class="item-title"><a href="/2020/03/01/data_engineering_09/" class="title">data engineering (데이터 파이프라인 자동화)</a></p>
                            <p class="item-date"><time datetime="2020-03-01T04:49:06.000Z" itemprop="datePublished">2020-03-01</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/data-engineering/">data engineering</a></p>
                            <p class="item-title"><a href="/2020/02/24/data_engineering_08/" class="title">data engineering (Presto란?)</a></p>
                            <p class="item-date"><time datetime="2020-02-24T13:11:09.000Z" itemprop="datePublished">2020-02-24</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/data-engineering/">data engineering</a></p>
                            <p class="item-title"><a href="/2020/02/22/data_engineering_07/" class="title">data engineering (데이터 웨어하우스 vs 데이터 레이크)</a></p>
                            <p class="item-date"><time datetime="2020-02-21T16:14:31.000Z" itemprop="datePublished">2020-02-22</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/data-engineering/">data engineering</a></p>
                            <p class="item-title"><a href="/2020/02/20/data_engineering_06/" class="title">data engineering (AWS DynamoDB 사용해서 오디오 feature 활용하기)</a></p>
                            <p class="item-date"><time datetime="2020-02-20T09:25:18.000Z" itemprop="datePublished">2020-02-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/20/NLP_13/" class="title">NLP 실습 Chat bot 만들기</a></p>
                            <p class="item-date"><time datetime="2020-02-20T07:01:42.000Z" itemprop="datePublished">2020-02-20</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bayes/">Bayes</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n/">CS231n</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Front-end/">Front end</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/crawling/">crawling</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-engineering/">data engineering</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/growth-hacking/">growth hacking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">5</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crawling/">crawling</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CS231n/" style="font-size: 10px;">CS231n</a> <a href="/tags/crawling/" style="font-size: 20px;">crawling</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 사이드바 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="3275421833"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 HeungBae Lee</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://heung-bae-lee.github.io/2020/01/12/deep_learning_08/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</body>
</html>
