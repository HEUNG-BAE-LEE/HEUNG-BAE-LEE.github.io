<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    

    
    <title>Residual Network 구현 및 학습 | DataLatte&#39;s IT Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    
    <meta name="description" content="Residual Network GoogLeNet 이후에 나온 모델로 Residual 구조를 Skip connection 구조를 갖으며, pre-activation을 갖는 Residual unit을 먼저 만든 후에서 Resnet Unit을 연결하야 만들 ResnetLayer를 만들어 Residual Layer를 구현할 것이다. 그 후 전체적인 ResNet M">
<meta property="og:type" content="article">
<meta property="og:title" content="Residual Network 구현 및 학습">
<meta property="og:url" content="https://heung-bae-lee.github.io/2020/01/12/deep_learning_06/index.html">
<meta property="og:site_name" content="DataLatte&#39;s IT Blog">
<meta property="og:description" content="Residual Network GoogLeNet 이후에 나온 모델로 Residual 구조를 Skip connection 구조를 갖으며, pre-activation을 갖는 Residual unit을 먼저 만든 후에서 Resnet Unit을 연결하야 만들 ResnetLayer를 만들어 Residual Layer를 구현할 것이다. 그 후 전체적인 ResNet M">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://heung-bae-lee.github.io/image/Resnet_result.png">
<meta property="og:updated_time" content="2020-01-20T15:58:35.374Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Residual Network 구현 및 학습">
<meta name="twitter:description" content="Residual Network GoogLeNet 이후에 나온 모델로 Residual 구조를 Skip connection 구조를 갖으며, pre-activation을 갖는 Residual unit을 먼저 만든 후에서 Resnet Unit을 연결하야 만들 ResnetLayer를 만들어 Residual Layer를 구현할 것이다. 그 후 전체적인 ResNet M">
<meta name="twitter:image" content="https://heung-bae-lee.github.io/image/Resnet_result.png">
<meta property="fb:app_id" content="100003222637819">


    <link rel="canonical" href="https://heung-bae-lee.github.io/2020/01/12/deep_learning_06/">

    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-154199624-1', 'auto');
ga('send', 'pageview');

</script>

    
    


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4604833066889492" data-ad-slot="4588503508" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<link rel="alternate" href="/rss2.xml" title="DataLatte's IT Blog" type="application/rss+xml">
</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">DataLatte&#39;s IT Blog using Hexo</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Bayes/">Bayes</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/CS231n/">CS231n</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Front-end/">Front end</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/crawling/">crawling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/data-engineering/">data engineering</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/growth-hacking/">growth hacking</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/hexo/">hexo</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/linear-algebra/">linear algebra</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/machine-learning/">machine learning</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/deep-learning/">deep learning</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="4588503508"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

			    <article id="post-deep_learning_06" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Residual Network 구현 및 학습
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2020/01/12/deep_learning_06/" class="article-date">
            <time datetime="2020-01-12T06:17:16.000Z" itemprop="datePublished">2020-01-12</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h1 id="Residual-Network"><a href="#Residual-Network" class="headerlink" title="Residual Network"></a>Residual Network</h1><ul>
<li>GoogLeNet 이후에 나온 모델로 Residual 구조를 Skip connection 구조를 갖으며, pre-activation을 갖는 Residual unit을 먼저 만든 후에서 Resnet Unit을 연결하야 만들 ResnetLayer를 만들어 Residual Layer를 구현할 것이다. 그 후 전체적인 ResNet Model를 생성하여 앞서 구현해본 VGG-16과 성능을 비교하기 위해 동일한 mnist 데이터를 통해 학습과 검증을 해볼 것이다.</li>
</ul>
<h1 id="DenseNetwork-구현-및-학습"><a href="#DenseNetwork-구현-및-학습" class="headerlink" title="DenseNetwork 구현 및 학습"></a>DenseNetwork 구현 및 학습</h1><ul>
<li>필자는 구글 colab을 통해 학습시켰으며, @tf.function을 사용하기위해 tensorflow 2.0 버젼을 시용하였다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install tensorflow==2.0.0-beta1</span><br></pre></td></tr></table></figure>
<ul>
<li>사용할 라이브러리 import</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br></pre></td></tr></table></figure>
<ul>
<li>위에서 설치한 tensorflow의 버전이 2.0인지 확인</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(tf.__version__)</span><br></pre></td></tr></table></figure>
<ul>
<li>Hyper parameter를 설정</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EPOCHS = 10</span><br></pre></td></tr></table></figure>
<h3 id="Residual-Unit-구현"><a href="#Residual-Unit-구현" class="headerlink" title="Residual Unit 구현"></a>Residual Unit 구현</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">class ResidualUnit(tf.keras.Model):</span><br><span class="line">  def __init__(self, filter_in, filter_out, kernel_size):</span><br><span class="line">    super(ResidualUnit, self).__init__()</span><br><span class="line">    <span class="comment"># batch normalization -&gt; ReLu -&gt; Conv Layer</span></span><br><span class="line">    <span class="comment"># 여기서 ReLu 같은 경우는 변수가 없는 Layer이므로 여기서 굳이 initialize 해주지 않는다. (call쪽에서 사용하면 되므로)</span></span><br><span class="line"></span><br><span class="line">    self.bn1 = tf.keras.layers.BatchNormalization()</span><br><span class="line">    self.conv1 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding=<span class="string">"same"</span>)</span><br><span class="line"></span><br><span class="line">    self.bn2 = tf.keras.layers.BatchNormalization()</span><br><span class="line">    self.conv2 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding=<span class="string">"same"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># identity를 어떻게 할지 정의</span></span><br><span class="line">    <span class="comment"># 원래 Residual Unit을 하려면 위의 순서로 진행한 뒤, 바로 X를 더해서 내보내면 되는데,</span></span><br><span class="line">    <span class="comment"># 이 X와 위의 과정을 통해 얻은 Feature map과 차원이 동일해야 더하기 연산이 가능할 것이므로</span></span><br><span class="line">    <span class="comment"># 즉, 위에서 filter_in과 filter_out이 같아야 한다는 의미이다.</span></span><br><span class="line">    <span class="comment"># 하지만, 다를 수 있으므로 아래와 같은 작업을 거친다.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> filter_in == filter_out:</span><br><span class="line">      self.identity = lambda x: x</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      self.identity = tf.keras.layers.Conv2D(filter_out, (1,1), padding=<span class="string">"same"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 아래에서 batch normalization은 train할때와 inference할 때 사용하는 것이 달라지므로 옵션을 줄것이다.</span></span><br><span class="line">  def call(self, x, training=False, mask=None):</span><br><span class="line">    h = self.bn1(x, training=training)</span><br><span class="line">    h = tf.nn.relu(h)</span><br><span class="line">    h = self.conv1(h)</span><br><span class="line"></span><br><span class="line">    h = self.bn2(h, training=training)</span><br><span class="line">    h = tf.nn.relu(h)</span><br><span class="line">    h = self.conv2(h)</span><br><span class="line">    <span class="built_in">return</span> self.identity(x) + h</span><br></pre></td></tr></table></figure>
<h3 id="Residual-Layer-구현"><a href="#Residual-Layer-구현" class="headerlink" title="Residual Layer 구현"></a>Residual Layer 구현</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">class ResnetLayer(tf.keras.Model):</span><br><span class="line">  <span class="comment"># 아래 arg 중 filter_in : 처음 입력되는 filter 개수를 의미</span></span><br><span class="line">  <span class="comment"># Resnet Layer는 Residual unit이 여러개가 있게끔해주는것이므로</span></span><br><span class="line">  <span class="comment"># filters : [32, 32, 32, 32]는 32에서 32로 Residual unit이 연결되는 형태</span></span><br><span class="line">  def __init__(self, filter_in, filters, kernel_size):</span><br><span class="line">    super(ResnetLayer, self).__init__()</span><br><span class="line">    self.sequnce = list()</span><br><span class="line">    <span class="comment"># [16] + [32, 32, 32]</span></span><br><span class="line">    <span class="comment"># 아래는 list의 length가 더 작은 것을 기준으로 zip이 되어서 돌아가기 때문에</span></span><br><span class="line">    <span class="comment"># 앞의 list의 마지막 element 32는 무시된다.</span></span><br><span class="line">    <span class="comment"># zip([16, 32, 32, 32], [32, 32, 32])</span></span><br><span class="line">    <span class="keyword">for</span> f_in, f_out <span class="keyword">in</span> zip([filter_in] + list(filters), filters):</span><br><span class="line">      self.sequnce.append(ResidualUnit(f_in, f_out, kernel_size))</span><br><span class="line"></span><br><span class="line">  def call(self, x, training=False, mask=None):</span><br><span class="line">    <span class="keyword">for</span> unit <span class="keyword">in</span> self.sequnce:</span><br><span class="line">      <span class="comment"># 위의 batch normalization에서 training이 쓰였기에 여기서 넘겨 주어야 한다.</span></span><br><span class="line">      x = unit(x, training=training)</span><br><span class="line">    <span class="built_in">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="모델-정의"><a href="#모델-정의" class="headerlink" title="모델 정의"></a>모델 정의</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">class ResNet(tf.keras.Model):</span><br><span class="line">  def __init__(self):</span><br><span class="line">    super(ResNet, self).__init__()</span><br><span class="line">    self.conv1 = tf.keras.layers.Conv2D(8, (3,3), padding=<span class="string">"same"</span>, activation=<span class="string">"relu"</span>) <span class="comment"># 28X28X8</span></span><br><span class="line"></span><br><span class="line">    self.res1 = ResnetLayer(8, (16, 16), (3, 3)) <span class="comment"># 28X28X16</span></span><br><span class="line">    self.pool1 = tf.keras.layers.MaxPool2D((2,2)) <span class="comment"># 14X14X16</span></span><br><span class="line"></span><br><span class="line">    self.res2 = ResnetLayer(16, (32, 32), (3, 3)) <span class="comment"># 14X14X32</span></span><br><span class="line">    self.pool2 = tf.keras.layers.MaxPool2D((2,2)) <span class="comment"># 7X7X32</span></span><br><span class="line"></span><br><span class="line">    self.res3 = ResnetLayer(32, (64, 64), (3, 3)) <span class="comment"># 7X7X64</span></span><br><span class="line"></span><br><span class="line">    self.flatten = tf.keras.layers.Flatten()</span><br><span class="line">    self.dense1 = tf.keras.layers.Dense(128, activation=<span class="string">"relu"</span>)</span><br><span class="line">    self.dense2 = tf.keras.layers.Dense(10, activation=<span class="string">"softmax"</span>)</span><br><span class="line"></span><br><span class="line">  def call(self, x, training=False, mask=None):</span><br><span class="line">    x = self.conv1(x)</span><br><span class="line"></span><br><span class="line">    x = self.res1(x, training=training)</span><br><span class="line">    x = self.pool1(x)</span><br><span class="line">    x = self.res2(x, training=training)</span><br><span class="line">    x = self.pool2(x)</span><br><span class="line">    x = self.res3(x, training=training)</span><br><span class="line"></span><br><span class="line">    x = self.flatten(x)</span><br><span class="line">    x = self.dense1(x)</span><br><span class="line">    <span class="built_in">return</span> self.dense2(x)</span><br></pre></td></tr></table></figure>
<h3 id="학습-테스트-루프-정의"><a href="#학습-테스트-루프-정의" class="headerlink" title="학습,테스트 루프 정의"></a>학습,테스트 루프 정의</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Implement training loop</span></span><br><span class="line">@tf.function</span><br><span class="line">def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):</span><br><span class="line">  with tf.GradientTape() as tape:</span><br><span class="line">    <span class="comment"># training=True 꼭 넣어주기!!</span></span><br><span class="line">    predictions = model(images, training=True)</span><br><span class="line">    loss = loss_object(labels, predictions)</span><br><span class="line">  gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class="line"></span><br><span class="line">  optimizer.apply_gradients(zip(gradients, model.trainable_variables))</span><br><span class="line">  train_loss(loss)</span><br><span class="line">  train_accuracy(labels, predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Implement algorithm test</span></span><br><span class="line">@tf.function</span><br><span class="line">def test_step(model, images, labels, loss_object, test_loss, test_accuracy):</span><br><span class="line">  <span class="comment"># training=False 꼭 넣어주기!!</span></span><br><span class="line">  predictions = model(images, training=False)</span><br><span class="line"></span><br><span class="line">  t_loss = loss_object(labels, predictions)</span><br><span class="line">  test_loss(t_loss)</span><br><span class="line">  test_accuracy(labels, predictions)</span><br></pre></td></tr></table></figure>
<h3 id="데이터셋-준비"><a href="#데이터셋-준비" class="headerlink" title="데이터셋 준비"></a>데이터셋 준비</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / 255.0, x_test / 255.0</span><br><span class="line"></span><br><span class="line">x_train = x_train[..., tf.newaxis].astype(np.float32)</span><br><span class="line">x_test = x_test[..., tf.newaxis].astype(np.float32)</span><br><span class="line"></span><br><span class="line">train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)</span><br><span class="line">test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)</span><br></pre></td></tr></table></figure>
<h3 id="학습-환경-정의"><a href="#학습-환경-정의" class="headerlink" title="학습 환경 정의"></a>학습 환경 정의</h3><h4 id="모델-생성-손실-함수-최적화-알고리즘-평가지표-정의"><a href="#모델-생성-손실-함수-최적화-알고리즘-평가지표-정의" class="headerlink" title="모델 생성, 손실 함수, 최적화 알고리즘, 평가지표 정의"></a>모델 생성, 손실 함수, 최적화 알고리즘, 평가지표 정의</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모델 생성</span></span><br><span class="line">model = ResNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 손실함수 정의 및 최적화 기법 정의</span></span><br><span class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class="line">optimizer = tf.keras.optimizers.Adam()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 평가지표 정의</span></span><br><span class="line">train_loss = tf.keras.metrics.Mean(name=<span class="string">'train_loss'</span>)</span><br><span class="line">train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">'train_accuracy'</span>)</span><br><span class="line"></span><br><span class="line">test_loss = tf.keras.metrics.Mean(name=<span class="string">'test_loss'</span>)</span><br><span class="line">test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">'test_accuracy'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="학습-루프-동작"><a href="#학습-루프-동작" class="headerlink" title="학습 루프 동작"></a>학습 루프 동작</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCHS):</span><br><span class="line">  <span class="keyword">for</span> images, labels <span class="keyword">in</span> train_ds:</span><br><span class="line">    train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> test_images, test_labels <span class="keyword">in</span> test_ds:</span><br><span class="line">    test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)</span><br><span class="line"></span><br><span class="line">  template = <span class="string">"Epoch &#123;&#125;, Loss: &#123;&#125;, Accuracy: &#123;&#125;, Test Loss: &#123;&#125;, Test Accuracy: &#123;&#125;"</span></span><br><span class="line">  <span class="built_in">print</span>(template.format(epoch+1,</span><br><span class="line">                        train_loss.result(),</span><br><span class="line">                        train_accuracy.result() * 100,</span><br><span class="line">                        test_loss.result(),</span><br><span class="line">                        test_accuracy.result() * 100))</span><br></pre></td></tr></table></figure>
<p><img src="/image/Resnet_result.png" alt="ResNet 성능 결과"></p>

        </div>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 하단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="9861011486"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "HeungBae Lee"
        },
        "headline": "Residual Network 구현 및 학습",
        "image": "https://heung-bae-lee.github.io/image/Resnet_result.png",
        "keywords": "",
        "genre": "deep learning",
        "datePublished": "2020-01-12",
        "dateCreated": "2020-01-12",
        "dateModified": "2020-01-21",
        "url": "https://heung-bae-lee.github.io/2020/01/12/deep_learning_06/",
        "description": "Residual Network
GoogLeNet 이후에 나온 모델로 Residual 구조를 Skip connection 구조를 갖으며, pre-activation을 갖는 Residual unit을 먼저 만든 후에서 Resnet Unit을 연결하야 만들 ResnetLayer를 만들어 Residual Layer를 구현할 것이다. 그 후 전체적인 ResNet M"
        "wordCount": 1379
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/heungbae.lee" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HEUNG-BAE-LEE" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2020/01/12/deep_learning_07/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            DenseNet 구현 및 학습
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2020/01/11/Crawling_01/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">Scrapy 웹 크롤링 02 - Spider, Scrapy selectors, Items</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/data-engineering/">data engineering</a></p>
                            <p class="item-title"><a href="/2020/02/20/data_engineering_06/" class="title">data engineering (AWS DynamoDB 사용해서 오디오 feature 활용하기)</a></p>
                            <p class="item-date"><time datetime="2020-02-20T09:25:18.000Z" itemprop="datePublished">2020-02-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/20/NLP_13/" class="title">NLP 실습 Chat bot 만들기</a></p>
                            <p class="item-date"><time datetime="2020-02-20T07:01:42.000Z" itemprop="datePublished">2020-02-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/11/NLP_12/" class="title">NLP 실습 유사도를 반영한 검색 키워드 최적화</a></p>
                            <p class="item-date"><time datetime="2020-02-11T08:16:56.000Z" itemprop="datePublished">2020-02-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/11/NLP_11/" class="title">NLP 실습 텍스트 유사도 - 02 (XGBoost, 1D-CNN, MaLSTM)</a></p>
                            <p class="item-date"><time datetime="2020-02-10T16:36:58.000Z" itemprop="datePublished">2020-02-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2020/02/10/NLP_10/" class="title">NLP 실습 텍스트 유사도 - 01 (데이터 EDA 및 전처리)</a></p>
                            <p class="item-date"><time datetime="2020-02-09T17:34:30.000Z" itemprop="datePublished">2020-02-10</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bayes/">Bayes</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n/">CS231n</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Front-end/">Front end</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/crawling/">crawling</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-engineering/">data engineering</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/growth-hacking/">growth hacking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">5</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crawling/">crawling</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CS231n/" style="font-size: 10px;">CS231n</a> <a href="/tags/crawling/" style="font-size: 20px;">crawling</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 사이드바 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="3275421833"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 HeungBae Lee</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://heung-bae-lee.github.io/2020/01/12/deep_learning_06/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>
