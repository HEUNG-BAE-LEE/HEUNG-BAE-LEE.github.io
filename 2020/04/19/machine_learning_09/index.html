<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    

    
    <title>LDA, QDA | DataLatte&#39;s IT Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    
    <meta name="description" content="LDA(선형판별분석법), QDA(이차판별분석법) 선형판별 분석법(Linear discriminant analysis, LDA)과 이차판별 분석법(quadratic discriminant analysis, QDA)는 대표적인 확률론적 생성모형이다. 가능도 y의 클래스값에 따른 x의 분포에 대한 정보를 먼저 알아낸 후, 베이즈 정리를 사용하여 주어진 x에 대한">
<meta property="og:type" content="article">
<meta property="og:title" content="LDA, QDA">
<meta property="og:url" content="https://heung-bae-lee.github.io/2020/04/19/machine_learning_09/index.html">
<meta property="og:site_name" content="DataLatte&#39;s IT Blog">
<meta property="og:description" content="LDA(선형판별분석법), QDA(이차판별분석법) 선형판별 분석법(Linear discriminant analysis, LDA)과 이차판별 분석법(quadratic discriminant analysis, QDA)는 대표적인 확률론적 생성모형이다. 가능도 y의 클래스값에 따른 x의 분포에 대한 정보를 먼저 알아낸 후, 베이즈 정리를 사용하여 주어진 x에 대한">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://heung-bae-lee.github.io/image/Linear_discriminant_analysis_method_how_to_cal.png">
<meta property="og:updated_time" content="2020-04-20T15:06:02.754Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LDA, QDA">
<meta name="twitter:description" content="LDA(선형판별분석법), QDA(이차판별분석법) 선형판별 분석법(Linear discriminant analysis, LDA)과 이차판별 분석법(quadratic discriminant analysis, QDA)는 대표적인 확률론적 생성모형이다. 가능도 y의 클래스값에 따른 x의 분포에 대한 정보를 먼저 알아낸 후, 베이즈 정리를 사용하여 주어진 x에 대한">
<meta name="twitter:image" content="https://heung-bae-lee.github.io/image/Linear_discriminant_analysis_method_how_to_cal.png">
<meta property="fb:app_id" content="100003222637819">


    <link rel="canonical" href="https://heung-bae-lee.github.io/2020/04/19/machine_learning_09/">

    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-154199624-1', 'auto');
ga('send', 'pageview');

</script>

    
    


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4604833066889492" data-ad-slot="4588503508" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<link rel="alternate" href="/rss2.xml" title="DataLatte's IT Blog" type="application/rss+xml">
</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">DataLatte&#39;s IT Blog using Hexo</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Bayes/">Bayes</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/CS231n/">CS231n</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Front-end/">Front end</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/">Python</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/crawling/">crawling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/data-engineering/">data engineering</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/growth-hacking/">growth hacking</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/hexo/">hexo</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/linear-algebra/">linear algebra</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/machine-learning/">machine learning</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/machine-learning/">machine learning</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="4588503508"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

			    <article id="post-machine_learning_09" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        LDA, QDA
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2020/04/19/machine_learning_09/" class="article-date">
            <time datetime="2020-04-19T13:26:35.000Z" itemprop="datePublished">2020-04-19</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h1 id="LDA-선형판별분석법-QDA-이차판별분석법"><a href="#LDA-선형판별분석법-QDA-이차판별분석법" class="headerlink" title="LDA(선형판별분석법), QDA(이차판별분석법)"></a>LDA(선형판별분석법), QDA(이차판별분석법)</h1><ul>
<li>선형판별 분석법(Linear discriminant analysis, LDA)과 이차판별 분석법(quadratic discriminant analysis, QDA)는 대표적인 확률론적 생성모형이다. 가능도 y의 클래스값에 따른 x의 분포에 대한 정보를 먼저 알아낸 후, 베이즈 정리를 사용하여 주어진 x에 대한 y의 확률분포를 찾아낸다.</li>
</ul>
<h3 id="생성모형"><a href="#생성모형" class="headerlink" title="생성모형"></a>생성모형</h3><ul>
<li>생성모형에서는 베이즈 정리를 사용하여 조건부 확률 $p(y = k \mid x)$를 계산한다.</li>
</ul>
<script type="math/tex; mode=display">P(y = k \mid x) = \dfrac{P(x \mid y = k)\; P(y = k)}{P(x)}</script><ul>
<li>분류 문제를 풀기 위해서는 각 클래스 $k$에 대한 확률을 비교하여 가장 큰 값을 선택한다. 따라서 모든 클래스에 대해 값이 같은 분모 $P(x)$은 굳이 계산하지 않아도 괜찮다.</li>
</ul>
<script type="math/tex; mode=display">P(y = k \mid x) \;\; \propto \;\; P(x \mid y = k) \; P(y = k)</script><ul>
<li>여기에서 사전확률 $P(y=k)$는 특별한 정보가 없는 경우, 다음처럼 계산한다.</li>
</ul>
<script type="math/tex; mode=display">P(y = k) \approx \frac{ y = k \;\;인\;데이터\;수\;}{모든\;데이터의\;수}</script><ul>
<li><p><code>만약 다른 지식이나 정보로 알고있는 사전확률 값이 있다면 그 값을 사용하면 된다.</code></p>
</li>
<li><p>$y$에 대한 $x$의 조건부확률인 가능도는 다음과 같이 계산한다.</p>
<ul>
<li>1) $P(x \mid y = k)$가 특정한 확률분포 모형을 따른다고 가정한다. 즉, 확률밀도 함수의 형태를 가정한다.</li>
<li>2) $k$번째 클래스에 속하는 학습 데이터 $\{x_1, \cdots, x_N\}$을 사용하여 이 모형의 모수값을 구한다.</li>
<li>3) 모수값을 알고 있으므로 $P(x \mid y = k)$의 확률 밀도 함수를 구한 것이다. 즉, 새로운 독립변수 값 x이 어떤 값이 되더라도 $P(x \mid y = k)$의 값을 계산할 수 있다.</li>
</ul>
</li>
</ul>
<h3 id="LDA-Linear-Discriminant-Analysis"><a href="#LDA-Linear-Discriminant-Analysis" class="headerlink" title="LDA(Linear Discriminant Analysis)"></a>LDA(Linear Discriminant Analysis)</h3><ul>
<li>3가지(1,2,3) 범주의 클래스를 가지고 있는 데이터가 아래와 같을 때, 그림을 보면 <code>중심을 기점으로 마치 정규분포와 비슷하게 중심과의 거리가 멀어질수록 분포의 밀도가 떨어지는 듯해 보인다</code>면 LDA로 문제를 풀 수 있을 것 같다는 생각이 들어야 한다.</li>
</ul>
<p><img src="/image/Linear_discriminant_analysis_method_how_to_cal.png" alt="Linear Discriminant Analysis 배경"></p>
<ul>
<li>먼저, LDA도 이전의 나이브 베이지안 모형과 같이 특정 가정이 존재한다.<ul>
<li>클래스 집단별로 동일한 공분산 구조를 지녔다는 가정</li>
<li>클래스 집단별로 정규분포를 따른다는 가정</li>
</ul>
</li>
</ul>
<ul>
<li>아래 그림에서 가정을 적용한 후의 그림을 보면 3가지 영역으로 나누어져 있는데, 이러한 영역은 어떻게 나뉠수 있는지를 설명할 것이다.</li>
</ul>
<p><img src="/image/backgroud_with_LDA.png" alt="LDA의 가정"></p>
<ul>
<li>아래 그림과 같이 2차원(두가지 독립변수)의 두 가지 범주를 갖는 데이터를 분류하는 문제에서 LDA는 먼저 하나의 차원에 projection을 하여 차원을 축소시킨다. 그 후에 <code>클래스별 분포의 분산 대비 평균의 차이가 크게 나는 지점(즉, 두 집단의 평균의 평균점)을 decision boundary로 설정</code>한다.</li>
</ul>
<ul>
<li>아래 두 그림 중 어떠한 decision boundary를 갖는 것이 더 분류를 잘 한다고 생각이드는가? 아무래도 오른쪽을 선택하는 분들이 많을 것이다. <code>이렇게 데이터가 동일하여도 projection되는 축에 따라 decision boundary가 달라진다.</code>그러므로 <code>projection되는 축을 정하는 것이 중요</code>하다.</li>
</ul>
<p><img src="/image/LDA_decision_boundary_features.png" alt="LDA decision boundary"></p>
<ul>
<li>우선 분류를 하려면 각 클래스 집단의 평균의 차이가 큰 지점을 decision boundary로 찾는다면 쉽게 분류가 가능할 것이므로 아래 그림과 같이 두 평균 벡터의 차이에 평행한 축에 projection을 하여 두 클래스를 비교하게 된다. 그러나, 두 집단간의 분산은 크기 때문에(분산이 크다는 것은 변동성이 크다는 얘기이므로 데이터의 분포를 두 집단으로 나누기에 무리가 있다.) 아직까진 분류의 모형으로 부족해 보인다.</li>
</ul>
<p><img src="/image/how_to_decide_decision_boundary.png" alt="LDA decision boundary 결정 방법 - 01"></p>
<ul>
<li>위에서와 같이 각 클래스 집단의 평균의 차이만을 고려하는 것이 아니라, 각 클래스 집단의 분산은 작게끔하는 방향으로 projection을 시켜야 할 것이다. 분산이 작다면 그만큼 데이터의 분포가 밀집되어있으므로 분류의 예측 성능 또한 높아질 가능성이 커지기 때문이다.</li>
</ul>
<p><img src="/image/consider_with_variance_on_distribution_LDA.png" alt="LDA decision boundary 결정 방법 - 02"></p>
<h3 id="LDA의-수학적-개념-이해-다변량-정규분포"><a href="#LDA의-수학적-개념-이해-다변량-정규분포" class="headerlink" title="LDA의 수학적 개념 이해 - 다변량 정규분포"></a>LDA의 수학적 개념 이해 - 다변량 정규분포</h3><ul>
<li>이변량 정규 분포는 두 변수간의 상관계수 $\rho$가 0이라면 두 변수는 독립이므로 결국 위의 정규분포의 식을 곱한 값이 될 것이다. 그러나, 상관계수 $\rho$가 0이 아닌 값으로 존재한다. 아래 수식과 같은 jointed probability distribution을 갖는다. 3D 이미지로 살펴본다면 $\rho$의 절대값이 높아질수록 더 강한 선형성을 갖으며 전체 feature 공간에 대해서는 비대칭적이게 되어진다. 즉, 각 축의 방향에서 보았을 경우 분포의 이미지가 달라지게 된다.</li>
</ul>
<p><img src="/image/bivariate_normal_dist_formular.png" alt="이변량 정규 분포"></p>
<ul>
<li>다변량 정규 분포로 확장하기에 앞서서, 먼저 이변량 정규분포에 대해 정리한 후 그 개념을 확장시킬 것이다. 이변량 정규분포의 수식은 아래 그림과 같다. 만약 $\rho$가 0이 라면 위에서 언급했던 것과 같이 두 정규분포 수식을 단순한 곱한 것과 동일하다는 것을 확인 할 수 있다. 다변량 정규분포의 식에 $2X2$ 공분산행렬을 대입하여 계산한다면, 이변량 정규분포식이 나오게 된다.</li>
</ul>
<p><img src="/image/mutivariate_normal_dist_formular_01.png" alt="다변량 정규 분포"></p>
<ul>
<li>먼저 LDA는 확률적 생성모형이므로 확률값을 계산해본다면, 다음과 같이 k번째 범주 집단의 분포함수는 정의 될 수 있다.</li>
</ul>
<p><img src="/image/mutivariate_normal_dist_formular_02.png" alt="로그 다변량 정규 분포 - 01"></p>
<ul>
<li>그렇다면, 새롭게 들어오는 관측치에 대해 클래스를 분류할 경우 어떻게 확률값을 계산해야 할까? 다음과 같이 범주에서 2개를 한 쌍으로 뽑는 경우의 가지수$_{4}C_{2}$ 만큼의 계산을 통해 비교하여 최종적으로 확률값이 가장 높은 클래스로 분류를 할 것이다. 아래 수식에서 가장 마지막 수식은 이차식 처럼 모양이 나오게 되는데, 그 이유는 두 벡터의 내적이 되기 때문에 어떤 벡터를 먼저 곱하는지는 상관이 없기 때문이다. 즉, $x^{T} \sum^{-1} \mu_{k} = \mu_{k}^{T} \sum^{-1} x $이기 때문이다.</li>
</ul>
<p><img src="/image/mutivariate_normal_dist_formular_03.png" alt="로그 다변량 정규 분포 - 02"></p>
<ul>
<li><code>Linear Discriminant Analysis로 불리는 이유는 아래와 같이 feature x에 대한 1차식의 형태(선형구조)이기 때문</code>이다. 여기서 유추할 수 있는 점은 위의 식을 얻기 위해선 <code>LDA의 중요한 가정 중 하나인 클래스 집단 별 동일한 공분산 구조를 갖고있는다는 가정 때문</code>이었다. 만약, 클래스 집단 별 동일하지 않은 공분산 구조를 갖는다면 위의 식에서 공분산 행렬을 기준으로 곱해지는 2차형식(Quadratic form)이 없어지지 않을 것이다. <code>클래스 집단 별 다른 공분산 구조를 갖는다는 가정</code>을 한다면 <code>QDA</code>가 된다.</li>
</ul>
<p><img src="/image/mutivariate_normal_dist_formular_04.png" alt="LDA 확률 계산"></p>
<ul>
<li>LDA(Linear Discriminant Analysis)에서는 각 $Y$ 클래스에 대한 독립변수 $X$의 조건부 확률 분포가 공통된 공분산 행렬을 가지는 다변수 정규분포(multivariate Gaussian normal distribution)이라고 가정한다.</li>
</ul>
<script type="math/tex; mode=display">\Sigma_k = \Sigma \;\;\; \text{ for all } k</script><ul>
<li>이 때는 조건부확률분포를 다음과 같이 정리할 수 있다.</li>
</ul>
<script type="math/tex; mode=display">\begin{eqnarray} \log p(x \mid y = k) &=& \log \dfrac{1}{(2\pi)^{D/2} |\Sigma|^{1/2}} -  \dfrac{1}{2} (x-\mu_k)^T \Sigma^{-1} (x-\mu_k) \\ &=& C_0 - \dfrac{1}{2} (x-\mu_k)^T \Sigma^{-1} (x-\mu_k) \\ &=& C_0 - \dfrac{1}{2} \left( x^T\Sigma^{-1}x - 2\mu_k^T \Sigma^{-1}x + \mu_k^T \Sigma^{-1}\mu_k \right) \\ &=& C(x)  + \mu_k^T \Sigma^{-1}x - \dfrac{1}{2} \mu_k^T \Sigma^{-1}\mu_k \\ \end{eqnarray}</script><script type="math/tex; mode=display">\begin{eqnarray} p(x \mid y = k) &=& C'(x)\exp(w_k^Tx + w_{k0}) \\ \end{eqnarray}</script><ul>
<li>이 식에서 $C’(x)=exp C(x)$이다.</li>
</ul>
<script type="math/tex; mode=display">\begin{eqnarray} P(y=k \mid x) &=& \dfrac{p(x \mid y = k)P(y=k)}{\sum_l p(x \mid y = l)P(y=l) } \\ &=& \dfrac{C'(x)\exp(w_k^Tx + w_{k0}) P(y=k)}{\sum_l C'(x)\exp(w_l^Tx + w_{l0})P(y=l) } \\ &=& \dfrac{C'(x)\exp(w_k^Tx + w_{k0}) P(y=k)}{C'(x)\sum_l \exp(w_l^Tx + w_{l0})P(y=l) } \\ &=& \dfrac{P(y=k) \exp(w_k^Tx + w_{k0}) }{\sum_l P(y=l) \exp(w_l^Tx + w_{k0})} \\ &=& \dfrac{P(y=k) \exp(w_k^Tx + w_{k0}) }{P(x)} \\ \end{eqnarray}</script><ul>
<li>이 식에서 $P(x)$는 $y$클래스값에 영향을 받지 않는다. 따라서</li>
</ul>
<script type="math/tex; mode=display">\log P(y=k \mid x) = \log P(y=k) + w_k^Tx + w_{k0} - \log{P(x)} = w_k^Tx + C''_k</script><ul>
<li>모든 클래스 k에 대해 위와 같은 식이 성립하므로 클래스 $k_{l}$과 클래스 $k_{m}$의 경계선, 즉 두 클래스에 대한 확률값이 같아지는 $x$의 위치를 찾으면 다음과 같다.</li>
</ul>
<script type="math/tex; mode=display">w_{k_1}^Tx + C''_{k_1} = w_{k_2}^Tx + C''_{k_2}</script><script type="math/tex; mode=display">(w_{k_1} - w_{k_2})^Tx + (C''_{k_1} - C''_{k_2}) = 0</script><script type="math/tex; mode=display">w^Tx + C = 0</script><ul>
<li>즉, <code>판별함수가 x에 대한 선형방정식이 되고 경계선의 모양이 직선</code>이 된다.</li>
</ul>
<p><img src="/image/LDA_important_assumptions.png" alt="정리 - LDA의 가정"></p>
<p><img src="/image/how_to_calculate_probability_of_prediction_calss_on_LDA.png" alt="정리 - LDA의 추정"></p>
<p><img src="/image/LDA_estimation_course.png" alt="정리 - LDA의 확률 추정"></p>
<h2 id="LDA와-eigen-value와-eigen-vector와의-연관성"><a href="#LDA와-eigen-value와-eigen-vector와의-연관성" class="headerlink" title="LDA와 eigen value와 eigen vector와의 연관성"></a>LDA와 eigen value와 eigen vector와의 연관성</h2><ul>
<li>벡터 $a$를 다른 벡터 $b$에 직교하는 성분과 벡터 $b$에 평행한 성분으로 분해할 수 있는데, 평행한 성분을 벡터 $b$에 대한 투영성분(projection), 벡터  $b$에 대한 직교성분(rejection)이라고 하며 각각을 다음과 같이 표기한다.</li>
</ul>
<script type="math/tex; mode=display">\begin{align} a^{\Vert b} \tag{3.1.37} \end{align}</script><script type="math/tex; mode=display">\begin{align} a^{\perp b} \tag{3.1.38} \end{align}</script><ul>
<li><code>투영성분의 길이</code>는 다음처럼 구할 수 있다.</li>
</ul>
<script type="math/tex; mode=display">\begin{align} \| a^{\Vert b} \| = \|a\|\cos\theta = \dfrac{\|a\|\|b\|\cos\theta}{\|b\|}  = \dfrac{a^Tb}{\|b\|} = \dfrac{b^Ta}{\|b\|} = a^T\dfrac{b}{\|b\|} \end{align}</script><ul>
<li>만약 벡터 $b$자체가 이미 단위벡터(Unit vector)이면 <code>단위벡터에 대한 투영길이는 내적</code>이 된다.</li>
</ul>
<script type="math/tex; mode=display">\begin{align} \| a^{\Vert b} \| = a^Tb \end{align}</script><ul>
<li><code>투영성분 성분 벡터</code>는 투영성분 길이와 벡터 $b$방향의 단위벡터의 곱이다.</li>
</ul>
<script type="math/tex; mode=display">\begin{align} a^{\Vert b} = \dfrac{a^Tb}{\|b\|} \dfrac{b}{\|b\|}= \dfrac{a^Tb}{\|b\|^2}b  \end{align}</script><ul>
<li>직교성분 벡터는 원래의 벡터에서 투영성분 성분 벡터를 뺸 나머지이다.</li>
</ul>
<script type="math/tex; mode=display">\begin{align} a^{\perp b} = a - a^{\Vert b} \end{align}</script><p><a href="https://datascienceschool.net/view-notebook/dd1680bfbaab414a8d54dc978c6e883a/" target="_blank" rel="noopener">참고 : projection과 rejection</a><br><a href="https://playground10.tistory.com/74" target="_blank" rel="noopener">참고 : 제2 코사인법칙을 사용한 내적과의 연관성</a></p>
<p><img src="/image/projeciton_related_with_LDA.png" alt="Projection"></p>
<ul>
<li>이러한 Projection이 LDA와의 관계를 설명하면 먼저, LDA의 목표인 클래스 집단 간의 평균은 크게하고 분산은 작게하는 decision boundary가 존재하는 Projection 공간을 말 할 수 있을 것이다.</li>
</ul>
<p><img src="/image/purpose_of_LDA.png" alt="LDA의 목표에 연관된 투영의 개념"></p>
<ul>
<li>아래 그림에서 말하는 사영시킬 벡터 $a$라는 것은 <code>decision boundary를 찾기위해 해당 데이터들을 투영시킨 벡터라는 의미</code>이다. 위의 그림에서는 분포로 존재하는 공간의 축을 의미한다. 단 아래 그림의 수식들이 정확하기 위해선 먼저 각 데이터의 feature 벡터들이 Unit vector이고 사영된 벡터도 Unit vector인 경우에 한해서 아래의 수식이 정확하다고 할 수 있다.</li>
</ul>
<p><img src="/image/purpose_of_LDA_01.png" alt="LDA의 decision boundary를 찾기 위한 projection - 01"></p>
<ul>
<li>LDA의 목표에 맞게 클래스 집단의 평균의 차이는 크게하면서 분산은 최소화 시키는 사영을 찾는것이므로 아래와 같은 분수식을 사용할 수 있다. 각 평균과 분산은 projection된 성분을 가리킨다. 행렬표현으로 묶어서 다르게 표현한다면 맨 마직막의 수식들로 표현 가능하다.</li>
</ul>
<p><img src="/image/purpose_of_LDA_02.png" alt="LDA의 decision boundary를 찾기 위한 projection - 02"></p>
<ul>
<li>행렬식에 대해 가장 큰 a값을 찾기 위해서는 미분을 해야 할 것이다. 미분을 통해 아래 그림과 같은 형태로 변형시킬 수 있다. 맨 마지막 수식을 살펴보면 eigen value와 eigen vector의 정의와 동일하게 볼 수 있음을 확인 할 수 있다.</li>
</ul>
<p><img src="/image/purpose_of_LDA_03.png" alt="LDA의 decision boundary를 찾기 위한 projection - 02"></p>
<ul>
<li>위의 식을 다시한번 정리하면 eigen vector와 eigen value를 구할 수 있는데, <code>해당 데이터를 축소하는데 방향은 변하지 않고 길이만 변하는 벡터인 eigen vector를 찾으면 LDA의 decision boundary가 존재하는 공간인 벡터</code>이다.</li>
</ul>
<p><img src="/image/eigen_vector_eigen_value_related_with_LDA.png" alt="LDA의 decision boundary를 찾기 위한 projection - 03"></p>
<p><img src="/image/eigen_vector_eigen_value_related_with_LDA_01.png" alt="LDA의 decision boundary에서 eigen vector의 역할"></p>
<p><img src="/image/eigen_vector_eigen_value_related_with_LDA_02.png" alt="LDA의 수학적 개념 총 정리"></p>

        </div>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 하단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="9861011486"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "HeungBae Lee"
        },
        "headline": "LDA, QDA",
        "image": "https://heung-bae-lee.github.io/image/Linear_discriminant_analysis_method_how_to_cal.png",
        "keywords": "",
        "genre": "machine learning",
        "datePublished": "2020-04-19",
        "dateCreated": "2020-04-19",
        "dateModified": "2020-04-21",
        "url": "https://heung-bae-lee.github.io/2020/04/19/machine_learning_09/",
        "description": "LDA(선형판별분석법), QDA(이차판별분석법)
선형판별 분석법(Linear discriminant analysis, LDA)과 이차판별 분석법(quadratic discriminant analysis, QDA)는 대표적인 확률론적 생성모형이다. 가능도 y의 클래스값에 따른 x의 분포에 대한 정보를 먼저 알아낸 후, 베이즈 정리를 사용하여 주어진 x에 대한"
        "wordCount": 1399
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/heungbae.lee" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HEUNG-BAE-LEE" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
    
        <a href="/2020/04/17/machine_learning_08/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">K-Nearest Neighbors(KNN)</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/04/19/machine_learning_09/" class="title">LDA, QDA</a></p>
                            <p class="item-date"><time datetime="2020-04-19T13:26:35.000Z" itemprop="datePublished">2020-04-19</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/04/17/machine_learning_08/" class="title">K-Nearest Neighbors(KNN)</a></p>
                            <p class="item-date"><time datetime="2020-04-17T09:11:42.000Z" itemprop="datePublished">2020-04-17</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/04/14/machine_learning_07/" class="title">나이브 베이즈 분류모형</a></p>
                            <p class="item-date"><time datetime="2020-04-14T05:59:44.000Z" itemprop="datePublished">2020-04-14</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/04/03/machine_learning_06/" class="title">PCA를 이해하기 위한 기본적 선형대수</a></p>
                            <p class="item-date"><time datetime="2020-04-03T06:40:52.000Z" itemprop="datePublished">2020-04-03</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/04/03/machine_learning_05/" class="title">로지스틱 회귀분석</a></p>
                            <p class="item-date"><time datetime="2020-04-03T04:58:10.000Z" itemprop="datePublished">2020-04-03</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bayes/">Bayes</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n/">CS231n</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Front-end/">Front end</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/crawling/">crawling</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-engineering/">data engineering</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/growth-hacking/">growth hacking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">10</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crawling/">crawling</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CS231n/" style="font-size: 10px;">CS231n</a> <a href="/tags/crawling/" style="font-size: 20px;">crawling</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 사이드바 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="3275421833"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 HeungBae Lee</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://heung-bae-lee.github.io/2020/04/19/machine_learning_09/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</body>
</html>
