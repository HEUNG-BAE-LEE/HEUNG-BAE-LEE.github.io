<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">

    

    
    <title>Support Vector Machine(SVM) - 02 | DataLatte&#39;s IT Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content>
    
    
    <meta name="description" content="커널 서포트 벡터 머신 - SVM의 심화적 이해 12345678910111213np.random.seed(0)X_xor = np.random.randn(200, 2)y_xor = np.logical_xor(X_xor[:, 0] &amp;gt; 0, X_xor[:, 1] &amp;gt; 0)y_xor = np.where(y_xor, 1, 0)plt.scatter(X_xor">
<meta property="og:type" content="article">
<meta property="og:title" content="Support Vector Machine(SVM) - 02">
<meta property="og:url" content="https://heung-bae-lee.github.io/2020/04/25/machine_learning_12/index.html">
<meta property="og:site_name" content="DataLatte&#39;s IT Blog">
<meta property="og:description" content="커널 서포트 벡터 머신 - SVM의 심화적 이해 12345678910111213np.random.seed(0)X_xor = np.random.randn(200, 2)y_xor = np.logical_xor(X_xor[:, 0] &amp;gt; 0, X_xor[:, 1] &amp;gt; 0)y_xor = np.where(y_xor, 1, 0)plt.scatter(X_xor">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://heung-bae-lee.github.io/image/svm_deep_mind.png">
<meta property="og:updated_time" content="2020-04-26T09:34:55.872Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Support Vector Machine(SVM) - 02">
<meta name="twitter:description" content="커널 서포트 벡터 머신 - SVM의 심화적 이해 12345678910111213np.random.seed(0)X_xor = np.random.randn(200, 2)y_xor = np.logical_xor(X_xor[:, 0] &amp;gt; 0, X_xor[:, 1] &amp;gt; 0)y_xor = np.where(y_xor, 1, 0)plt.scatter(X_xor">
<meta name="twitter:image" content="https://heung-bae-lee.github.io/image/svm_deep_mind.png">
<meta property="fb:app_id" content="100003222637819">


    <link rel="canonical" href="https://heung-bae-lee.github.io/2020/04/25/machine_learning_12/">

    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-154199624-1', 'auto');
ga('send', 'pageview');

</script>

    
    


    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4604833066889492" data-ad-slot="4588503508" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<link rel="alternate" href="/rss2.xml" title="DataLatte's IT Blog" type="application/rss+xml">
</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">DataLatte&#39;s IT Blog using Hexo</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Bayes/">Bayes</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/CS231n/">CS231n</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Front-end/">Front end</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/NLP/">NLP</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Python/">Python</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Recommendation-System/">Recommendation System</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/crawling/">crawling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/data-engineering/">data engineering</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/growth-hacking/">growth hacking</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/hexo/">hexo</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/linear-algebra/">linear algebra</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/machine-learning/">machine learning</a></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/machine-learning/">machine learning</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 상단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="4588503508"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

			    <article id="post-machine_learning_12" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Support Vector Machine(SVM) - 02
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2020/04/25/machine_learning_12/" class="article-date">
            <time datetime="2020-04-25T11:03:51.000Z" itemprop="datePublished">2020-04-25</time>
        </a>
    </div>

		

                
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <h1 id="커널-서포트-벡터-머신-SVM의-심화적-이해"><a href="#커널-서포트-벡터-머신-SVM의-심화적-이해" class="headerlink" title="커널 서포트 벡터 머신 - SVM의 심화적 이해"></a>커널 서포트 벡터 머신 - SVM의 심화적 이해</h1><p><img src="/image/svm_deep_mind.png" alt="SVM 심화적 이해"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(0)</span><br><span class="line">X_xor = np.random.randn(200, 2)</span><br><span class="line">y_xor = np.logical_xor(X_xor[:, 0] &gt; 0, X_xor[:, 1] &gt; 0)</span><br><span class="line">y_xor = np.where(y_xor, 1, 0)</span><br><span class="line">plt.scatter(X_xor[y_xor == 1, 0], X_xor[y_xor == 1, 1],</span><br><span class="line">            c=<span class="string">'b'</span>, marker=<span class="string">'o'</span>, label=<span class="string">'클래스 1'</span>, s=50)</span><br><span class="line">plt.scatter(X_xor[y_xor == 0, 0], X_xor[y_xor == 0, 1],</span><br><span class="line">            c=<span class="string">'r'</span>, marker=<span class="string">'s'</span>, label=<span class="string">'클래스 0'</span>, s=50)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">"x1"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"x2"</span>)</span><br><span class="line">plt.title(<span class="string">"XOR 문제"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/XOR_problem_with_svm.png" alt="XOR 문제"></p>
<h3 id="XOR-문제"><a href="#XOR-문제" class="headerlink" title="XOR 문제"></a>XOR 문제</h3><ul>
<li>위의 그림과같이 퍼셉트론이나 서포트 벡터 머신과 같은 선형판별함수 분류 모형은 다음과 같은 XOR(exclusive OR) 문제를 풀지 못한다는 단점이 있다. 이러한 경우에는 위의 그림에서 볼 수 있듯이 선형 판별평면(decision hyperplane)으로 영역을 나눌 수 없기 때문이다. 따라서 일반적인 SVM을 사용하면 XOR문제를 풀 수 없다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def plot_xor(X, y, model, title, xmin=-3, xmax=3, ymin=-3, ymax=3):</span><br><span class="line">    XX, YY = np.meshgrid(np.arange(xmin, xmax, (xmax-xmin)/1000),</span><br><span class="line">                         np.arange(ymin, ymax, (ymax-ymin)/1000))</span><br><span class="line">    ZZ = np.reshape(model.predict(</span><br><span class="line">        np.array([XX.ravel(), YY.ravel()]).T), XX.shape)</span><br><span class="line">    plt.contourf(XX, YY, ZZ, cmap=mpl.cm.Paired_r, alpha=0.5)</span><br><span class="line">    plt.scatter(X[y == 1, 0], X[y == 1, 1], c=<span class="string">'b'</span>,</span><br><span class="line">                marker=<span class="string">'o'</span>, label=<span class="string">'클래스 1'</span>, s=50)</span><br><span class="line">    plt.scatter(X[y == 0, 0], X[y == 0, 1], c=<span class="string">'r'</span>,</span><br><span class="line">                marker=<span class="string">'s'</span>, label=<span class="string">'클래스 0'</span>, s=50)</span><br><span class="line">    plt.xlim(xmin, xmax)</span><br><span class="line">    plt.ylim(ymin, ymax)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.xlabel(<span class="string">"x1"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"x2"</span>)</span><br><span class="line"></span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line"></span><br><span class="line">svc = SVC(kernel=<span class="string">"linear"</span>).fit(X_xor, y_xor)</span><br><span class="line">plot_xor(X_xor, y_xor, svc, <span class="string">"선형 SVC 모형을 사용한 XOR 분류 결과"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/XOR_problem_with_svm_not_solved.png" alt="선형 SVC 모형을 사용한 XOR 분류 결과"></p>
<h3 id="변환함수를-사용한-비선형-판별-모형"><a href="#변환함수를-사용한-비선형-판별-모형" class="headerlink" title="변환함수를 사용한 비선형 판별 모형"></a>변환함수를 사용한 비선형 판별 모형</h3><ul>
<li>이러한 경우 도움이 되는 것이 원래의 $D$차원 독립 변수 벡터 $x$ 대신 비선형 함수로 변환한 $M$차원 벡터 $\phi(x)$를 독립 변수로 사용하는 방법이다.</li>
</ul>
<script type="math/tex; mode=display">\phi(\cdot): {R}^D \rightarrow {R}^M</script><script type="math/tex; mode=display">x=(x_1, x_2, \cdots, x_D) \;\;\; \rightarrow \;\;\; \phi(x) = (\phi_1(x), \phi_2(x), \cdots, \phi_M(x))</script><ul>
<li>앞서 XOR 문제를 풀기 위해 다음과 같이 상호 곱 (cross-multiplication) 항을 추가한 변환함수를 사용해 보자.</li>
</ul>
<script type="math/tex; mode=display">(x_1, x_2) \;\;\; \rightarrow \;\;\; \phi(x) = (x_1^2, \sqrt{2}x_1x_2, x_2^2)</script><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = np.arange(6).reshape(3, 2)</span><br><span class="line">X</span><br></pre></td></tr></table></figure>
<h5 id="결과"><a href="#결과" class="headerlink" title="결과"></a>결과</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[0, 1],</span><br><span class="line">       [2, 3],</span><br><span class="line">       [4, 5]])</span><br></pre></td></tr></table></figure>
<ul>
<li><code>FunctionTransformer</code> 전처리 클래스로 위와 변환함수를 이용한 변환을 할 수 있다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import FunctionTransformer</span><br><span class="line"></span><br><span class="line">def basis(X):</span><br><span class="line">    <span class="built_in">return</span> np.vstack([X[:, 0]**2, np.sqrt(2)*X[:, 0]*X[:, 1], X[:, 1]**2]).T</span><br><span class="line"></span><br><span class="line">FunctionTransformer(basis).fit_transform(X)</span><br></pre></td></tr></table></figure>
<h5 id="결과-1"><a href="#결과-1" class="headerlink" title="결과"></a>결과</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0.        ,  0.        ,  1.        ],</span><br><span class="line">       [ 4.        ,  8.48528137,  9.        ],</span><br><span class="line">       [16.        , 28.28427125, 25.        ]])</span><br></pre></td></tr></table></figure>
<ul>
<li>위와 같은 변환함수를 써서 XOR 문제의 데이터를 변환하면 특성 $\phi_2$를 사용하여 클래스 분류를 할 수 있다는 것을 알 수 있다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X_xor2 = FunctionTransformer(basis).fit_transform(X_xor)</span><br><span class="line">plt.scatter(X_xor2[y_xor == 1, 0], X_xor2[y_xor == 1, 1], c=<span class="string">"b"</span>, marker=<span class="string">'o'</span>, s=50)</span><br><span class="line">plt.scatter(X_xor2[y_xor == 0, 0], X_xor2[y_xor == 0, 1], c=<span class="string">"r"</span>, marker=<span class="string">'s'</span>, s=50)</span><br><span class="line">plt.ylim(-6, 6)</span><br><span class="line">plt.title(<span class="string">"변환 공간에서의 데이터 분포"</span>)</span><br><span class="line">plt.xlabel(r<span class="string">"$\phi_1$"</span>)</span><br><span class="line">plt.ylabel(r<span class="string">"$\phi_2$"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/transformation_space_dist_data_plot.png" alt="변환 공간에서의 데이터 분포"></p>
<ul>
<li>다음 코드는 <code>Pipeline</code>클래스로 변환함수 전처리기와 <code>SVC</code> 클래스를 합친 모형의 분류 결과이다.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line"></span><br><span class="line">basismodel = Pipeline([(<span class="string">"basis"</span>, FunctionTransformer(basis)),</span><br><span class="line">                       (<span class="string">"svc"</span>, SVC(kernel=<span class="string">"linear"</span>))]).fit(X_xor, y_xor)</span><br><span class="line">plot_xor(X_xor, y_xor, basismodel, <span class="string">"변환함수 SVC 모형을 사용한 XOR 분류 결과"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/SVC_model_using_transformation_function_xor_problem_result.png" alt="변환함수 SVC 모형을 사용한 XOR 분류 결과"></p>
<h3 id="커널-트릭"><a href="#커널-트릭" class="headerlink" title="커널 트릭"></a>커널 트릭</h3><p><img src="/image/svm_deep_mind_01.png" alt="커널 도입"></p>
<ul>
<li>서포트 벡터 머신의 경우 목적 함수(비용 함수)와 예측 모형은 다음과 같이 dual form으로 표현할 수 있다.</li>
</ul>
<script type="math/tex; mode=display">L =  \sum_{n=1}^N a_n - \dfrac{1}{2}\sum_{n=1}^N\sum_{m=1}^N a_n a_m y_n y_m x_n^T x_m</script><script type="math/tex; mode=display">y = w^T x - w_0 = \sum_{n=1}^N a_n y_n x_n^T x - w_0</script><ul>
<li>이 수식에서 $x$를 변환함수 변환으로 $\phi(x)$로 바꾸면 아래와 같이 된다. 즉, 모든 변환함수는 $\phi(x_i)^T\phi(x_j)$의 형태로만 사용되며 독립적으로 사용되지 않는다. 따라서 두 개의 변환된 독립 변수 벡터를 내적(inner product)한 값 $\phi(x_i)^T\phi(x_j)$를 하나의 함수로 나타낼 수 있다.</li>
</ul>
<script type="math/tex; mode=display">L =  \sum_{n=1}^N a_n - \dfrac{1}{2}\sum_{n=1}^N\sum_{m=1}^N a_n a_m y_n y_m \phi(x_n)^T \phi(x_m)</script><script type="math/tex; mode=display">y = w^T x - w_0 = \sum_{n=1}^N a_n y_n \phi(x_n)^T \phi(x) - w_0</script><ul>
<li><p>이렇게 하나의 함수로 나타낸 것을 커널(kernel)이라고 한다. 대응하는 변환함수가 존재할 수만 있다면 변환함수를 먼저 정의하고 커널을 정의하는 것이 아니라 커널을 먼저 정의해도 상관없다.</p>
</li>
<li><p>커널이 제 역할을 하려면 $x_i$와 $x_j$의 유사도를 측정하는 함수여야한다. 또한 커널함수에서 도로 기저함수 포맷으로 만들어질수도 있어야한다.</p>
</li>
</ul>
<h3 id="커널의-의미"><a href="#커널의-의미" class="headerlink" title="커널의 의미"></a>커널의 의미</h3><ul>
<li>서포트 벡터 머신의 목적 함수와 예측 모형은 커널을 사용하여 표현하면 다음과 같다.</li>
</ul>
<script type="math/tex; mode=display">L =  \sum_{n=1}^N a_n - \dfrac{1}{2}\sum_{n=1}^N\sum_{m=1}^N a_n a_m y_n y_m k(x_n, x_m)</script><script type="math/tex; mode=display">y = w^T x - w_0 = \sum_{n=1}^N a_n y_n k(x_n, x) - w_0</script><ul>
<li><p>커널을 사용하지 않는 경우 $k(x,y) = x^{T}y$라는 점을 고려하면 커널은 다음과 같은 특징을 보인다.</p>
<ul>
<li>$x$와 $y$가 동일한 벡터일 때 가장 크고</li>
<li>두 벡터간의 거리가 멀어질수록 작아진다.</li>
</ul>
</li>
<li><p><code>즉, 두 표본 데이터간의 유사도(similarity)를 측정하는 기준으로 볼 수도 있다.</code></p>
</li>
</ul>
<h3 id="커널-사용의-장점"><a href="#커널-사용의-장점" class="headerlink" title="커널 사용의 장점"></a>커널 사용의 장점</h3><ul>
<li><p>커널을 사용하면 basis 함수를 하나씩 정의하는 수고를 덜 수 있을뿐더러 변환과 내적에 들어가는 계산량이 줄어든다. 예를 들어, 다음과 같은 변환함수의 경우 커널방법을 쓰지 않을 경우에 $\phi(x_i)^T \phi(x_j)$를 계산하려면 $4\;+\;4\;+\;3 \;=\;11$번의 곱셈을 해야 한다.</p>
<ul>
<li>$\phi(x_1)$ 계산 : 곱셈 4회</li>
<li>$\phi(x_2)$ 계산 : 곱셈 4회</li>
<li>내적 계산 : 곱셈 3회</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">\phi(x_i) = \phi([x_{i,1}, x_{i,2}]) = (x_{i,1}^2, \sqrt{2}x_{i,1}x_{i,2}, x_{i,2}^2)</script><ul>
<li>그런데 이 변환함수는 다음과 같은 커널로 대체가능하다.</li>
</ul>
<script type="math/tex; mode=display">\begin{eqnarray} k(x_1, x_2) &=& (x_1^Tx_2)^2 \\ &=& (x_{1,1}x_{2,1} + x_{1,2}x_{2,2})^2 \\ &=& x_{1,1}^2x_{2,1}^2 + 2x_{1,1}x_{2,1}x_{1,2}x_{2,2} + x_{1,2}^2y_{2,2}^2 \\ &=& (x_{1,1}^2, \sqrt{2}x_{1,1}x_{1,2}, x_{1,2}^2)  (x_{2,1}^2, \sqrt{2}x_{2,1}x_{2,2}, x_{2,2}^2)^T \\ &=& \phi(x_1)^T \phi(x_2) \end{eqnarray}</script><ul>
<li><p>커널을 사용하면 $\phi(x_1)^T \phi(x_2)$을 계산하는데 $2\;+\;1\;=\;3$ 번의 곱셈이면 된다.</p>
<ul>
<li>$x_1^Tx_2$: 곱셈 2회</li>
<li>제곱 : 곱셈 1회</li>
</ul>
</li>
</ul>
<h3 id="커널의-확장-생성"><a href="#커널의-확장-생성" class="headerlink" title="커널의 확장 생성"></a>커널의 확장 생성</h3><ul>
<li><p><code>어떤 함수가 커널함수가 된다는 것을 증명하기 위해서는 변환함수를 하나 하나 정의할 필요없이 변환함수의 내적으로 표현할 수 있다는 것만 증명</code>하면 된다. 하지만 실제로는 다음 규칙을 이용하면 이미 만들어진 커널 $k_1(x_1, x_2), k_2(x_1, x_2)$로 부터 새로운 커널을 쉽게 만들 수 있다.</p>
</li>
<li><ol>
<li>커널함수를 양수배한 함수는 커널함수이다.</li>
</ol>
</li>
</ul>
<script type="math/tex; mode=display">k(x_1, x_2) = ck_1(x_1, x_2)\;\;(c > 0)</script><ul>
<li><ol>
<li>커널함수에 양수인 상수를 더한 함수는 커널 함수이다.</li>
</ol>
</li>
</ul>
<script type="math/tex; mode=display">k(x_1, x_2) = k_1(x_1, x_2) + c\;\;(c > 0)</script><ul>
<li><ol>
<li>두 커널함수를 더한 함수는 커널함수이다.</li>
</ol>
</li>
</ul>
<script type="math/tex; mode=display">k(x_1, x_2) = k_1(x_1, x_2) + k_2(x_1, x_2)</script><ul>
<li><ol>
<li>두 커널함수를 곱한 함수는 커널함수이다.</li>
</ol>
</li>
</ul>
<script type="math/tex; mode=display">k(x_1, x_2) = k_1(x_1, x_2)k_2(x_1, x_2)</script><ul>
<li><ol>
<li>커널함수를 $x\geq0$에서 단조증가(monotonically increasing)하는 함수에 적용하면 커널함수이다.</li>
</ol>
</li>
</ul>
<script type="math/tex; mode=display">k(x_1, x_2) = (k_1(x_1, x_2))^n \;\; (n=1, 2, \cdots)</script><script type="math/tex; mode=display">k(x_1, x_2) = \exp(k_1(x_1, x_2))</script><script type="math/tex; mode=display">k(x_1, x_2) = \text{sigmoid}(k_1(x_1, x_2))</script><ul>
<li><ol>
<li>$x_{1}, x_{2}$ 각각의 커널함수값의 곱도 커널함수이다.</li>
</ol>
</li>
</ul>
<script type="math/tex; mode=display">k(x_1, x_2) = k_1(x_1, x_1)k_2(x_2, x_2)</script><h3 id="많이-사용되는-커널"><a href="#많이-사용되는-커널" class="headerlink" title="많이 사용되는 커널"></a>많이 사용되는 커널</h3><p><img src="/image/svm_deep_mind_02.png" alt="커널의 종류"></p>
<ul>
<li>다음과 같은 커널들이 많이 사용되는 커널들이다. 이 커널들은 대부분 변환함수로 변환하였을 때 무한대의 차원을 가지는 변환함수가 된다. 따라서 대부분의 비선형성을 처리할 수 있다. 비교를 위해 선형 서포트 벡터 머신의 경우도 추가하였다.</li>
</ul>
<blockquote>
<p>선형 서포트 벡터 머신</p>
</blockquote>
<script type="math/tex; mode=display">k(x_1, x_2) = x_1^Tx_2</script><blockquote>
<p>다항 커널 (Polynomial Kernel)</p>
</blockquote>
<script type="math/tex; mode=display">k(x_1, x_2) = (\gamma (x_1^Tx_2) + \theta)^d</script><blockquote>
<p>RBF(Radial Basis Function) 또는 가우시안 커널(Gaussian Kernel)</p>
<pre><code>- $\gamma = \frac{1}{2\sigma^{2}}$인 경우 가우시안 분포를 따르게 된다.
</code></pre></blockquote>
<script type="math/tex; mode=display">k(x_1, x_2) = \exp \left( -\gamma ||x_1-x_2||^2 \right)</script><blockquote>
<p>시그모이드 커널 (Sigmoid Kernel)</p>
</blockquote>
<script type="math/tex; mode=display">k(x_1, x_2) = \tanh(\gamma (x_1^Tx_2) + \theta)</script><ul>
<li>앞에서 사용한 변환함수는 $\gamma \;=\;1,,\; \theta\;=\;0, \;d\;=\;2$인 다항 커널임을 알 수 있다.</li>
</ul>
<h3 id="다항-커널"><a href="#다항-커널" class="headerlink" title="다항 커널"></a>다항 커널</h3><ul>
<li>다항 커널은 벡터의 내적으로 정의된 커널을 확장하여 만든 커널이다. 아래에서 다항 커널이 어떤 변환함수로 되어 있는지 알아볼 것이다.</li>
</ul>
<ul>
<li>간단한 경우로 $\gamma \;=\;1,,\; \theta\;=\;1, \;d\;=\;4$이고 $x$가 스칼라인 경우에는 아래와 같으며, 마지막 수식에서 볼 수 있듯이 변환함수의 내적이 된다.</li>
</ul>
<script type="math/tex; mode=display">\begin{eqnarray} k(x_1, x_2) &=& (x_1^Tx_2 + 1)^4 \\ &=& x_1^4x_2^4 + 4x_1^3x_2^3 + 6x_1^2x_2^2 + 4x_1x_2 + 1 \\ &=& (x_1^4, 2x_1^3, \sqrt{6}x_1, 2x_1, 1)^T (x_2^4, 2x_2^3, \sqrt{6}x_2, 2x_2, 1) \ \\ \end{eqnarray}</script><ul>
<li>즉, 변환함수는 다음 5개가 된다.</li>
</ul>
<script type="math/tex; mode=display">\begin{eqnarray} \phi_1(x) &=& x^4 \\ \phi_2(x) &=& 2x^3 \\ \phi_3(x) &=& \sqrt{6}x^2 \\ \phi_4(x) &=& 2x \\ \phi_5(x) &=& 1 \\ \end{eqnarray}</script><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">x1 = 1</span><br><span class="line">x2 = np.linspace(-3, 3, 100)</span><br><span class="line"></span><br><span class="line">def poly4(x1, x2):</span><br><span class="line">    <span class="built_in">return</span> (x1 * x2 + 1) ** 4</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(8, 4))</span><br><span class="line">plt.subplot(121)</span><br><span class="line">plt.plot(x2, poly4(x1, x2), ls=<span class="string">"-"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x2"</span>)</span><br><span class="line">plt.title(<span class="string">"4차 다항커널의 예"</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(122)</span><br><span class="line">plt.plot(x2, x2 ** 4)</span><br><span class="line">plt.plot(x2, 2 * x2 ** 3)</span><br><span class="line">plt.plot(x2, np.sqrt(6) * x2 ** 2)</span><br><span class="line">plt.plot(x2, 2 * x2)</span><br><span class="line">plt.plot(x2, np.ones_like(x2))</span><br><span class="line">plt.xlabel(<span class="string">"x2"</span>)</span><br><span class="line">plt.title(<span class="string">"4차 다항커널의 변환함수들"</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/4th_polynomial_function_kernel_and_transformation_functions.png" alt="4차 다항 커널과 그에 따른 변환함수들"></p>
<h3 id="RBF-커널"><a href="#RBF-커널" class="headerlink" title="RBF 커널"></a>RBF 커널</h3><ul>
<li>RBF 커널은 가우시안 커널이라고도 한다. 문제를 간단하게 하기 위해 다음과 같이 가정할 것이다.</li>
</ul>
<script type="math/tex; mode=display">\gamma=\frac{1}{2}</script><script type="math/tex; mode=display">\|x_1\| = \|x_2\| = 1</script><ul>
<li>그러면 RBF 커널은 아래와 같은 차수가 무한대인 다항커널과 같아진다.</li>
</ul>
<script type="math/tex; mode=display">\begin{eqnarray} k(x_1, x_2) &=& \exp{\left(-\frac{||x_1 - x_2||^2}{2}\right)} \\ &=& \exp{\left(-\frac{x_1^Tx_1}{2} - \frac{x_2^Tx_2}{2} + 2x_1^Tx_2 \right)} \\ &=& \exp{\left(-\frac{x_1^Tx_1}{2}\right)}\exp{\left(-\frac{x_2^Tx_2}{2}\right)}\exp{(x_1^Tx_2)} \\ &=& C \exp{(x_1^Tx_2)} \\ &\approx& C \left( 1 + (x_1^Tx_2) + \dfrac{1}{2!}(x_1^Tx_2)^2 +  \dfrac{1}{3!}(x_1^Tx_2)^3 + \cdots \right) \\ \end{eqnarray}</script><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">x1 = 0.0</span><br><span class="line">x2 = np.linspace(-7, 7, 100)</span><br><span class="line"></span><br><span class="line">def rbf(x1, x2, gamma):</span><br><span class="line">    <span class="built_in">return</span> np.exp(-gamma * np.abs(x2 - x1) ** 2)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(8, 4))</span><br><span class="line">plt.subplot(121)</span><br><span class="line">plt.plot(x2, rbf(x1, x2, 1), ls=<span class="string">"-"</span>, label=<span class="string">"gamma = 1"</span>)</span><br><span class="line">plt.plot(x2, rbf(x1, x2, 0.5), ls=<span class="string">":"</span>, label=<span class="string">"gamma = 0.5"</span>)</span><br><span class="line">plt.plot(x2, rbf(x1, x2, 5), ls=<span class="string">"--"</span>, label=<span class="string">"gamma = 5"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x2 - x1"</span>)</span><br><span class="line">plt.xlim(-3, 7)</span><br><span class="line">plt.legend(loc=1)</span><br><span class="line">plt.title(<span class="string">"RBF 커널"</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(122)</span><br><span class="line">plt.plot(x2, rbf(-4, x2, 1))</span><br><span class="line">plt.plot(x2, rbf(-2, x2, 1))</span><br><span class="line">plt.plot(x2, rbf(0, x2, 1))</span><br><span class="line">plt.plot(x2, rbf(2, x2, 1))</span><br><span class="line">plt.plot(x2, rbf(4, x2, 1))</span><br><span class="line">plt.xlabel(<span class="string">"x2"</span>)</span><br><span class="line">plt.title(<span class="string">"RBF 커널의 변환함수들"</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/RBF_kernel_function_for_many_parameters.png" alt="RBF 커널과 그에따른 변환함수들"></p>
<h3 id="scikit-learn의-커널-SVM"><a href="#scikit-learn의-커널-SVM" class="headerlink" title="scikit-learn의 커널 SVM"></a>scikit-learn의 커널 SVM</h3><ul>
<li>scikit-learn의 <code>SVM</code> 클래스는 <code>kernel</code>인수를 지정하여 커널을 설정할 수 있다.<ul>
<li><code>kernel = &quot;linear&quot;</code> : 선형 SVM. $k(x_{1},\;x_{2})\;=\;x_{1}^{T}x_{2}$  </li>
<li><code>kernel = &quot;poly&quot;</code> : 다항 커널. $k(x_{1},\;x_{2})\;=\;(\gamma \;(x_{1}^{T} x_{2})\; +\; \theta)^{d}$<ul>
<li><code>gamma</code>: $\gamma$</li>
<li><code>coef0</code>: $\theta$</li>
<li><code>degree</code>: $d$</li>
</ul>
</li>
<li><code>kernel = &quot;rbf&quot;</code> 또는 <code>kernel = None</code>: RBF 커널. $k(x_1, x_2) = \exp \left( -\gamma ||x_1-x_2||^2 \right)$<ul>
<li><code>\gamma</code></li>
</ul>
</li>
<li><code>kernel = &quot;sigmoid&quot;</code> 시그모이드 커널. $k(x_1, x_2) = \tanh(\gamma (x_1^Tx_2) + \theta)$<ul>
<li><code>gamma</code> : $\gamma$</li>
<li><code>coef0</code> : $\theta$</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">polysvc = SVC(kernel=<span class="string">"poly"</span>, degree=2, gamma=1, coef0=0).fit(X_xor, y_xor)</span><br><span class="line">rbfsvc = SVC(kernel=<span class="string">"rbf"</span>).fit(X_xor, y_xor)</span><br><span class="line">sigmoidsvc = SVC(kernel=<span class="string">"sigmoid"</span>, gamma=2, coef0=2).fit(X_xor, y_xor)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(8, 12))</span><br><span class="line">plt.subplot(311)</span><br><span class="line">plot_xor(X_xor, y_xor, polysvc, <span class="string">"다항커널 SVC를 사용한 분류 결과"</span>)</span><br><span class="line">plt.subplot(312)</span><br><span class="line">plot_xor(X_xor, y_xor, rbfsvc, <span class="string">"RBF커널 SVC를 사용한 분류 결과"</span>)</span><br><span class="line">plt.subplot(313)</span><br><span class="line">plot_xor(X_xor, y_xor, sigmoidsvc, <span class="string">"시그모이드커널 SVC를 사용한 분류 결과"</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/XOR_problem_result_of_using_polynomial_kernel.png" alt="다항커널 SVC를 사용한 분류 결과"></p>
<p><img src="/image/XOR_problem_result_of_using_RBF_kernel.png" alt="RBF커널 SVC를 사용한 분류 결과"></p>
<p><img src="/image/XOR_problem_result_of_using_sigmoid_kernel.png" alt="Sigmoid 커널 SVC를 사용한 분류 결과"></p>
<h3 id="커널-파라미터의-영향"><a href="#커널-파라미터의-영향" class="headerlink" title="커널 파라미터의 영향"></a>커널 파라미터의 영향</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(8, 8))</span><br><span class="line">plt.subplot(221)</span><br><span class="line">plot_xor(X_xor, y_xor, SVC(kernel=<span class="string">"rbf"</span>, gamma=2).fit(X_xor, y_xor), <span class="string">"RBF SVM (gamma=2)"</span>)</span><br><span class="line">plt.subplot(222)</span><br><span class="line">plot_xor(X_xor, y_xor, SVC(kernel=<span class="string">"rbf"</span>, gamma=10).fit(X_xor, y_xor), <span class="string">"RBF SVM (gamma=10)"</span>)</span><br><span class="line">plt.subplot(223)</span><br><span class="line">plot_xor(X_xor, y_xor, SVC(kernel=<span class="string">"rbf"</span>, gamma=50).fit(X_xor, y_xor), <span class="string">"RBF SVM (gamma=50)"</span>)</span><br><span class="line">plt.subplot(224)</span><br><span class="line">plot_xor(X_xor, y_xor, SVC(kernel=<span class="string">"rbf"</span>, gamma=100).fit(X_xor, y_xor), <span class="string">"RBF SVM (gamma=100)"</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<ul>
<li>$\gamma$의 값이 커질수록 hyperplane의 경계가 더 둥글어지면서, 그 값이 너무 높아지면 overfitting이 되게 된다.</li>
</ul>
<p><img src="/image/RBF_kernel_parameters_difference_plot.png" alt="RBF 커널의 감마값의 비교"></p>
<h3 id="iris-데이터에-적용"><a href="#iris-데이터에-적용" class="headerlink" title="iris 데이터에 적용"></a>iris 데이터에 적용</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, [2, 3]]</span><br><span class="line">y = iris.target</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)</span><br><span class="line">sc = StandardScaler()</span><br><span class="line">sc.fit(X_train)</span><br><span class="line">X_train_std = sc.transform(X_train)</span><br><span class="line">X_test_std = sc.transform(X_test)</span><br><span class="line">X_combined_std = np.vstack((X_train_std, X_test_std))</span><br><span class="line">y_combined = np.hstack((y_train, y_test))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot_iris(X, y, model, title, xmin=-2.5, xmax=2.5, ymin=-2.5, ymax=2.5):</span><br><span class="line">    XX, YY = np.meshgrid(np.arange(xmin, xmax, (xmax-xmin)/1000),</span><br><span class="line">                         np.arange(ymin, ymax, (ymax-ymin)/1000))</span><br><span class="line">    ZZ = np.reshape(model.predict(np.array([XX.ravel(), YY.ravel()]).T), XX.shape)</span><br><span class="line">    plt.contourf(XX, YY, ZZ, cmap=mpl.cm.Paired_r, alpha=0.5)</span><br><span class="line">    plt.scatter(X[y == 0, 0], X[y == 0, 1], c=<span class="string">'r'</span>, marker=<span class="string">'^'</span>, label=<span class="string">'0'</span>, s=100)</span><br><span class="line">    plt.scatter(X[y == 1, 0], X[y == 1, 1], c=<span class="string">'g'</span>, marker=<span class="string">'o'</span>, label=<span class="string">'1'</span>, s=100)</span><br><span class="line">    plt.scatter(X[y == 2, 0], X[y == 2, 1], c=<span class="string">'b'</span>, marker=<span class="string">'s'</span>, label=<span class="string">'2'</span>, s=100)</span><br><span class="line">    plt.xlim(xmin, xmax)</span><br><span class="line">    plt.ylim(ymin, ymax)</span><br><span class="line">    plt.xlabel(<span class="string">"꽃잎의 길이"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"꽃잎의 폭"</span>)</span><br><span class="line">    plt.title(title)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model1 = SVC(kernel=<span class="string">'linear'</span>).fit(X_test_std, y_test)</span><br><span class="line">model2 = SVC(kernel=<span class="string">'poly'</span>, random_state=0,</span><br><span class="line">             gamma=10, C=1.0).fit(X_test_std, y_test)</span><br><span class="line">model3 = SVC(kernel=<span class="string">'rbf'</span>, random_state=0, gamma=1,</span><br><span class="line">             C=1.0).fit(X_test_std, y_test)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(8, 12))</span><br><span class="line">plt.subplot(311)</span><br><span class="line">plot_iris(X_test_std, y_test, model1, <span class="string">"선형 SVC"</span>)</span><br><span class="line">plt.subplot(312)</span><br><span class="line">plot_iris(X_test_std, y_test, model2, <span class="string">"다항커널 SVC"</span>)</span><br><span class="line">plt.subplot(313)</span><br><span class="line">plot_iris(X_test_std, y_test, model3, <span class="string">"RBF커널 SVM"</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/iris_problem_result_of_using_linear_SVC.png" alt="선형 SVC를 사용한 분류 결과"></p>
<p><img src="/image/iris_problem_result_of_using_polynomial_kernel.png" alt="다항커널 SVC를 사용한 분류 결과"></p>
<p><img src="/image/iris_problem_result_of_using_RBF_kernel.png" alt="RBF커널 SVC를 사용한 분류 결과"></p>
<p><img src="/image/svm_deep_mind_03.png" alt="커널 사용시 유의할 점"></p>
<p><img src="/image/svm_deep_mind_04.png" alt="SVM과 LDA 비교"></p>
<h3 id="One-Class-Support-Vector-Machine"><a href="#One-Class-Support-Vector-Machine" class="headerlink" title="One Class Support Vector Machine"></a>One Class Support Vector Machine</h3><ul>
<li>종속변수가 없다는 의미이다. 고로 다 같은 범주이므로 classifying 정보가 없다는 것과 동일한 의미를 갖는다. <code>One Class SVM은 우리가 가진 자료들을 요약하는데 사용</code>한다. 마치 Unsupervised learning의 clustering 처럼 활용하는 방법이다. 기본적으로 원을 활용한 모델을 사용한다. 간단히 말해서 원안에는 자료가 있고, 원 바깥은 자료가 없다는 식으로 활용한다는 의미이다.  </li>
</ul>
<p><img src="/image/one_class_svm_concept.png" alt="one class svm 개념 - 01"></p>
<ul>
<li>SVM에서 서포트 벡터를 통해 $\beta$를 구해 hyperplane을 구했듯이 해당 원에 가장 가까운 $x_{k}$ 서포트 벡터를 통해 $R^{2}$ (반지를)을 계산한다.</li>
</ul>
<p><img src="/image/one_class_svm_concept_01.png" alt="one class svm 개념 - 02"></p>
<ul>
<li>아래의 그림처럼 바나나모양으로 데이터가 있는 경우에 임의의 반지름을 갖는 원안에 데이터를 모두 넣고 싶은데, 최소한의 반지름 값을 갖는 원을 찾는 문제가 된다.</li>
</ul>
<p><img src="/image/one_class_svm_concept_02.png" alt="one class svm 개념 - 03"></p>
<ul>
<li>내적을 kernel로 바꾼 후 polynomial kernel을 사용한 경우 차원이 높아 질수록 자유도도 높아짐(원보다는 데이터 하나하나에 영향을 더 많이 받음)을 확인할 수 있다.</li>
</ul>
<p><img src="/image/one_class_svm_concept_03.png" alt="one class svm 개념 - 04"></p>
<ul>
<li>또한, RBF 커널에서도 마찬가지로 C값이 높아질수록 허용하는 error가 낮아져 support vector안에 데이터들이 존재하게되며, 감마를 낮출수록($\sigma$를 높일수록) 두 벡터 $x_{i}$와 $x_{j}$간의 차이의 정도에 덜 민감해 지기 때문에 모양이 단순해 지게 된다.</li>
</ul>
<p><img src="/image/one_class_svm_concept_04.png" alt="one class svm 개념 - 05"></p>
<h3 id="SVR"><a href="#SVR" class="headerlink" title="SVR"></a>SVR</h3><ul>
<li>종속변수가 범주형이 아닌 연속형인 경우에는 SVR을 사용해야 한다. 아래 수식과 같이 margin과 hyperplane을 정의하는 것은 동일하다. 이번에는 <code>margin 밖에 존재하는 데이터들과 decision boundary와의 차이(error)를 최소화 하도록하는 방식</code>으로 동작한다. 그러므로 margin 안에 많은 데이터를 포함하고 있을 수록 error가 최소화 될 것이다. 결과적으론 아래와 같은 목적함수를 최소화하는데 마지막 수식과 같이 직관적으로 margin과의 차이만을 error로 보는 함수를 사용할 수 있다.</li>
</ul>
<p><img src="/image/svr_conception.png" alt="SVR의 정의"></p>
<ul>
<li>허나, 이전 그림에서의 error를 정의하는데 수학적인 계산에 용이성을 더하기 위해 아래와 같은 수식으로 error를 계산한다. 앞에서와 같이 미분불가능한 점이 없고 계산하기 편하기 때문에 아래와 같은 수식으로 사용한다.</li>
</ul>
<p><img src="/image/svr_conception_01.png" alt="SVR의 정의"></p>
<p><img src="/image/svr_conception_02.png" alt="SVR의 정의"></p>
<ul>
<li>SVM과 마찬가지로 SVR도 커널을 사용하여 다음과 같은 곡선의 형태로 fitting할 수 있다. 기본적으로 linear model을 사용했을 때는 전반적인 패턴을 잡아주고 다른 커널들에 대해서는 각 커널의 특성에 맞게 적합시켜 준다.</li>
</ul>
<p><img src="/image/svr_conception_03.png" alt="SVR의 정의"></p>

        </div>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 하단형 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="9861011486"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

        <footer class="article-footer">
            


    <div class="a2a_kit a2a_default_style">
    <a class="a2a_dd" href="https://www.addtoany.com/share">Share</a>
    <span class="a2a_divider"></span>
    <a class="a2a_button_facebook"></a>
    <a class="a2a_button_twitter"></a>
    <a class="a2a_button_google_plus"></a>
    <a class="a2a_button_pinterest"></a>
    <a class="a2a_button_tumblr"></a>
</div>
<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>


        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "HeungBae Lee"
        },
        "headline": "Support Vector Machine(SVM) - 02",
        "image": "https://heung-bae-lee.github.io/image/svm_deep_mind.png",
        "keywords": "",
        "genre": "machine learning",
        "datePublished": "2020-04-25",
        "dateCreated": "2020-04-25",
        "dateModified": "2020-04-26",
        "url": "https://heung-bae-lee.github.io/2020/04/25/machine_learning_12/",
        "description": "커널 서포트 벡터 머신 - SVM의 심화적 이해
12345678910111213np.random.seed(0)X_xor = np.random.randn(200, 2)y_xor = np.logical_xor(X_xor[:, 0] &gt; 0, X_xor[:, 1] &gt; 0)y_xor = np.where(y_xor, 1, 0)plt.scatter(X_xor"
        "wordCount": 2741
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/heungbae.lee" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HEUNG-BAE-LEE" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2020/04/26/machine_learning_13/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            의사결정나무
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2020/04/22/machine_learning_11/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">Support Vector Machine(SVM) - 01</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></p>
                            <p class="item-title"><a href="/2020/04/30/data_structure_04/" class="title">내가 정리하는 자료구조 03 - 시간복잡도</a></p>
                            <p class="item-date"><time datetime="2020-04-30T09:12:50.000Z" itemprop="datePublished">2020-04-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></p>
                            <p class="item-title"><a href="/2020/04/28/data_structure_03/" class="title">내가 정리하는 자료구조 02 Linked List</a></p>
                            <p class="item-date"><time datetime="2020-04-27T19:41:46.000Z" itemprop="datePublished">2020-04-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a></p>
                            <p class="item-title"><a href="/2020/04/27/data_structure_02/" class="title">내가 정리하는 자료구조 01 Stack</a></p>
                            <p class="item-date"><time datetime="2020-04-27T12:38:39.000Z" itemprop="datePublished">2020-04-27</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/04/26/machine_learning_13/" class="title">의사결정나무</a></p>
                            <p class="item-date"><time datetime="2020-04-25T18:27:27.000Z" itemprop="datePublished">2020-04-26</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
                            <p class="item-title"><a href="/2020/04/25/machine_learning_12/" class="title">Support Vector Machine(SVM) - 02</a></p>
                            <p class="item-date"><time datetime="2020-04-25T11:03:51.000Z" itemprop="datePublished">2020-04-25</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bayes/">Bayes</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C-자료구조/">C/C++/자료구조</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n/">CS231n</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Front-end/">Front end</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Recommendation-System/">Recommendation System</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics-Mathematical-Statistics/">Statistics - Mathematical Statistics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/crawling/">crawling</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-engineering/">data engineering</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/growth-hacking/">growth hacking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">14</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crawling/">crawling</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/CS231n/" style="font-size: 10px;">CS231n</a> <a href="/tags/crawling/" style="font-size: 20px;">crawling</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 사이드바 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4604833066889492"
     data-ad-slot="3275421833"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 HeungBae Lee</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://heung-bae-lee.github.io/2020/04/25/machine_learning_12/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</body>
</html>
